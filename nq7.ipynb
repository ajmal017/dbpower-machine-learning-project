{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import talib as talib\n",
    "import numpy as np\n",
    "import data as ds\n",
    "import common as common\n",
    "import os as os\n",
    "import math as math\n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "import itertools  as itertools\n",
    "import multiprocessing as mp\n",
    "import joblib\n",
    "from os import listdir, walk\n",
    "from itertools import repeat\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "from datetime import datetime, timedelta, date\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, pairwise, mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 环境设定\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# 0.2 不让程序占满 GPU 内存\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "No file /home/user/PycharmProjects/JupyterLab01/data/nq/data/nq-20-01.csv\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "No file /home/user/PycharmProjects/JupyterLab01/data/nq/data/nq-20-10.csv\n",
      "Volume obtains 0\n",
      "No file /home/user/PycharmProjects/JupyterLab01/data/nq/data/nq-20-12.csv\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n"
     ]
    }
   ],
   "source": [
    "# 1.0 重構數據集\n",
    "def reshape_dataframe(df0, year0):\n",
    "    df0.fillna(0, inplace=True)\n",
    "    df0.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df0.columns = ['udate', 'High', 'Low', 'Open', 'Close', 'Volume']\n",
    "    types2 = {'udate': 'object', 'High': 'float64', 'Low': 'float64', 'Open': 'float64', 'Close': 'float64', 'Volume': 'int64'}\n",
    "    df0.astype(types2).dtypes\n",
    "    df0_1 = df0.copy(deep=True)\n",
    "    error_row = []\n",
    "    for k, v in df0.iterrows():\n",
    "        if not pd.isnull(df0['udate'].iloc[k]) and df0['udate'].iloc[k] > 0:\n",
    "            stime = str(int(df0['udate'].iloc[k]))\n",
    "            df0_1['udate'].iloc[k] = datetime(year=year0, month=int(stime[-8:-6]), day=int(stime[-6:-4]), hour=int(stime[-4:-2]), minute=int(stime[-2:]), second=0)\n",
    "        else:\n",
    "            error_row.append(k)\n",
    "    df0_1.drop(df0_1.index[error_row], inplace=True)\n",
    "    df0_1.udate = pd.to_datetime(df0_1.udate)\n",
    "    df0_1.index = pd.to_datetime(df0_1.udate)\n",
    "    \n",
    "    # 1.0.1 數據有效性檢查\n",
    "    for k, v in types2.items():\n",
    "        if (df0_1[k].isin([np.nan]).any().any()):\n",
    "            print(k+' obtains nan')\n",
    "        if (df0_1[k].isin([0]).any().any()):\n",
    "            print(k+' obtains 0')\n",
    "    is_contain_null = df0_1.isnull().sum()\n",
    "\n",
    "    return df0_1\n",
    "\n",
    "# 1.2.1 year 2020\n",
    "path_files_1 = [os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201105.csv')),\n",
    "                os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201105_Aug_Sep.csv')),\n",
    "                os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201110.csv')),\n",
    "                os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201111.csv'))]\n",
    "path_files_2 = []\n",
    "for j in range(1, 13):\n",
    "    month1 = str(j).zfill(2)\n",
    "    file1 = 'nq-20-'+month1+'.csv'\n",
    "    path_files_1.append(os.path.abspath(os.path.join('data', 'nq', 'data', file1)))\n",
    "    file2 = 'nq-19-'+month1+'.csv'\n",
    "    path_files_2.append(os.path.abspath(os.path.join('data', 'nq', 'data', file2)))\n",
    "    \n",
    "# 1.3\n",
    "def data_worker1(m_list1_2, path1_2, year_2):\n",
    "    try:\n",
    "        df1_2 = reshape_dataframe(pd.read_csv(path1_2), year_2)\n",
    "        m_list1_2.append(df1_2)\n",
    "    except:\n",
    "        print('No file', path1_2)\n",
    "\n",
    "# 1.4\n",
    "manager1 = mp.Manager()\n",
    "m_list1 = manager1.list()\n",
    "pool1 = mp.Pool(processes=2, maxtasksperchild=2)\n",
    "for path1 in path_files_1:\n",
    "    pool1.apply_async(func=data_worker1, args=(m_list1, path1, 2020,))\n",
    "for path2 in path_files_2:\n",
    "    pool1.apply_async(func=data_worker1, args=(m_list1, path2, 2019,))\n",
    "pool1.close()\n",
    "pool1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:00:00</th>\n",
       "      <td>2019-01-13 17:00:00</td>\n",
       "      <td>6599.00</td>\n",
       "      <td>6602.50</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:01:00</th>\n",
       "      <td>2019-01-13 17:01:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6598.75</td>\n",
       "      <td>6591.50</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:02:00</th>\n",
       "      <td>2019-01-13 17:02:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6596.75</td>\n",
       "      <td>6589.00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:03:00</th>\n",
       "      <td>2019-01-13 17:03:00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>6592.75</td>\n",
       "      <td>6588.00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:04:00</th>\n",
       "      <td>2019-01-13 17:04:00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6586.50</td>\n",
       "      <td>6588.75</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:25:00</th>\n",
       "      <td>2020-11-19 02:25:00</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11871.50</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:26:00</th>\n",
       "      <td>2020-11-19 02:26:00</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11871.25</td>\n",
       "      <td>11868.00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:27:00</th>\n",
       "      <td>2020-11-19 02:27:00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>11872.25</td>\n",
       "      <td>11868.25</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:28:00</th>\n",
       "      <td>2020-11-19 02:28:00</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>11873.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:29:00</th>\n",
       "      <td>2020-11-19 02:29:00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11871.00</td>\n",
       "      <td>11871.75</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441321 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2019-01-13 17:00:00 2019-01-13 17:00:00   6599.00   6602.50   6590.25   \n",
       "2019-01-13 17:01:00 2019-01-13 17:01:00   6595.75   6598.75   6591.50   \n",
       "2019-01-13 17:02:00 2019-01-13 17:02:00   6595.75   6596.75   6589.00   \n",
       "2019-01-13 17:03:00 2019-01-13 17:03:00   6591.00   6592.75   6588.00   \n",
       "2019-01-13 17:04:00 2019-01-13 17:04:00   6588.25   6590.25   6586.50   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2020-11-19 02:25:00 2020-11-19 02:25:00  11864.25  11871.50  11864.25   \n",
       "2020-11-19 02:26:00 2020-11-19 02:26:00  11869.25  11871.25  11868.00   \n",
       "2020-11-19 02:27:00 2020-11-19 02:27:00  11868.50  11872.25  11868.25   \n",
       "2020-11-19 02:28:00 2020-11-19 02:28:00  11870.50  11873.25  11869.25   \n",
       "2020-11-19 02:29:00 2020-11-19 02:29:00  11873.00  11873.00  11871.00   \n",
       "\n",
       "                        Close  Volume  \n",
       "udate                                  \n",
       "2019-01-13 17:00:00   6595.75   567.0  \n",
       "2019-01-13 17:01:00   6595.75   269.0  \n",
       "2019-01-13 17:02:00   6591.00   225.0  \n",
       "2019-01-13 17:03:00   6588.25   142.0  \n",
       "2019-01-13 17:04:00   6588.75   214.0  \n",
       "...                       ...     ...  \n",
       "2020-11-19 02:25:00  11869.25   155.0  \n",
       "2020-11-19 02:26:00  11868.50   114.0  \n",
       "2020-11-19 02:27:00  11870.50    85.0  \n",
       "2020-11-19 02:28:00  11873.00    80.0  \n",
       "2020-11-19 02:29:00  11871.75    48.0  \n",
       "\n",
       "[441321 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.5\n",
    "df2 = pd.concat(m_list1, ignore_index=False)\n",
    "\n",
    "# 1.6 刪除重覆index\n",
    "df2 = df2.groupby(df2.index).first()\n",
    "\n",
    "# 1.7 排序\n",
    "df2.sort_index(axis=0, ascending=True, inplace=True)\n",
    "# df2 = df2.loc[(df2.udate >= datetime(2019, 3, 1, 16, 0, 0))]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:00:00</th>\n",
       "      <td>2019-01-13 17:00:00</td>\n",
       "      <td>6599.00</td>\n",
       "      <td>6602.50</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:01:00</th>\n",
       "      <td>2019-01-13 17:01:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6598.75</td>\n",
       "      <td>6591.50</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:02:00</th>\n",
       "      <td>2019-01-13 17:02:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6596.75</td>\n",
       "      <td>6589.00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:03:00</th>\n",
       "      <td>2019-01-13 17:03:00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>6592.75</td>\n",
       "      <td>6588.00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:04:00</th>\n",
       "      <td>2019-01-13 17:04:00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6586.50</td>\n",
       "      <td>6588.75</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:25:00</th>\n",
       "      <td>2020-11-19 02:25:00</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11871.50</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:26:00</th>\n",
       "      <td>2020-11-19 02:26:00</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11871.25</td>\n",
       "      <td>11868.00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:27:00</th>\n",
       "      <td>2020-11-19 02:27:00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>11872.25</td>\n",
       "      <td>11868.25</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:28:00</th>\n",
       "      <td>2020-11-19 02:28:00</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>11873.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:29:00</th>\n",
       "      <td>2020-11-19 02:29:00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11871.00</td>\n",
       "      <td>11871.75</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426066 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2019-01-13 17:00:00 2019-01-13 17:00:00   6599.00   6602.50   6590.25   \n",
       "2019-01-13 17:01:00 2019-01-13 17:01:00   6595.75   6598.75   6591.50   \n",
       "2019-01-13 17:02:00 2019-01-13 17:02:00   6595.75   6596.75   6589.00   \n",
       "2019-01-13 17:03:00 2019-01-13 17:03:00   6591.00   6592.75   6588.00   \n",
       "2019-01-13 17:04:00 2019-01-13 17:04:00   6588.25   6590.25   6586.50   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2020-11-19 02:25:00 2020-11-19 02:25:00  11864.25  11871.50  11864.25   \n",
       "2020-11-19 02:26:00 2020-11-19 02:26:00  11869.25  11871.25  11868.00   \n",
       "2020-11-19 02:27:00 2020-11-19 02:27:00  11868.50  11872.25  11868.25   \n",
       "2020-11-19 02:28:00 2020-11-19 02:28:00  11870.50  11873.25  11869.25   \n",
       "2020-11-19 02:29:00 2020-11-19 02:29:00  11873.00  11873.00  11871.00   \n",
       "\n",
       "                        Close  Volume  \n",
       "udate                                  \n",
       "2019-01-13 17:00:00   6595.75   567.0  \n",
       "2019-01-13 17:01:00   6595.75   269.0  \n",
       "2019-01-13 17:02:00   6591.00   225.0  \n",
       "2019-01-13 17:03:00   6588.25   142.0  \n",
       "2019-01-13 17:04:00   6588.75   214.0  \n",
       "...                       ...     ...  \n",
       "2020-11-19 02:25:00  11869.25   155.0  \n",
       "2020-11-19 02:26:00  11868.50   114.0  \n",
       "2020-11-19 02:27:00  11870.50    85.0  \n",
       "2020-11-19 02:28:00  11873.00    80.0  \n",
       "2020-11-19 02:29:00  11871.75    48.0  \n",
       "\n",
       "[426066 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.0 分包 (日子)\n",
    "def separate_daily(df2_1, return_type):\n",
    "    data1 = {}\n",
    "    # 2.1交易日\n",
    "    days1 = list(dict.fromkeys([v.date() for v in df2_1['udate']]))\n",
    "    for day in days1:\n",
    "        # 2.2 交易時間\n",
    "        day_start = datetime(day.year, day.month, day.day, 17, 0, 0)\n",
    "        day2 = day + timedelta(days=1)\n",
    "        day_end = datetime(day2.year, day2.month, day2.day, 16, 0, 0)\n",
    "        mask = ((df2_1['udate'] >= day_start) & (df2_1['udate'] <= day_end))\n",
    "        df2_2 = df2_1.loc[mask]\n",
    "        if (df2_2.shape[0] > 1):\n",
    "            data1[day] = df2_2\n",
    "    # 2.3 合併\n",
    "    df2_3 = pd.DataFrame()\n",
    "    for k, df2_4 in data1.items():\n",
    "        df2_3 = pd.concat([df2_3, df2_4], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "    # 2.4 返回類型\n",
    "    if return_type=='df':\n",
    "        return df2_3\n",
    "    elif return_type=='dict':\n",
    "        return data1\n",
    "\n",
    "df2_5 = df2.copy(deep=True)\n",
    "df3 = separate_daily(df2_5, 'df')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>upper-band</th>\n",
       "      <th>middle-band</th>\n",
       "      <th>lower-band</th>\n",
       "      <th>%b</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi</th>\n",
       "      <th>k-kdj</th>\n",
       "      <th>d-kdj</th>\n",
       "      <th>j-kdj</th>\n",
       "      <th>diff-kdj</th>\n",
       "      <th>sma-15</th>\n",
       "      <th>sma-50</th>\n",
       "      <th>sma-100</th>\n",
       "      <th>sma-200</th>\n",
       "      <th>vol-ema5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:00:00</th>\n",
       "      <td>2019-01-13 17:00:00</td>\n",
       "      <td>6599.00</td>\n",
       "      <td>6602.50</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>567.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:01:00</th>\n",
       "      <td>2019-01-13 17:01:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6598.75</td>\n",
       "      <td>6591.50</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>269.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:02:00</th>\n",
       "      <td>2019-01-13 17:02:00</td>\n",
       "      <td>6595.75</td>\n",
       "      <td>6596.75</td>\n",
       "      <td>6589.00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:03:00</th>\n",
       "      <td>2019-01-13 17:03:00</td>\n",
       "      <td>6591.00</td>\n",
       "      <td>6592.75</td>\n",
       "      <td>6588.00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-13 17:04:00</th>\n",
       "      <td>2019-01-13 17:04:00</td>\n",
       "      <td>6588.25</td>\n",
       "      <td>6590.25</td>\n",
       "      <td>6586.50</td>\n",
       "      <td>6588.75</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:25:00</th>\n",
       "      <td>2020-11-19 02:25:00</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11871.50</td>\n",
       "      <td>11864.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>155.0</td>\n",
       "      <td>11874.155992</td>\n",
       "      <td>11863.1625</td>\n",
       "      <td>11852.169008</td>\n",
       "      <td>77.686834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.187728</td>\n",
       "      <td>-6.309339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.497067</td>\n",
       "      <td>11861.100000</td>\n",
       "      <td>11871.445</td>\n",
       "      <td>11879.9425</td>\n",
       "      <td>11876.64375</td>\n",
       "      <td>102.712294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:26:00</th>\n",
       "      <td>2020-11-19 02:26:00</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11871.25</td>\n",
       "      <td>11868.00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>114.0</td>\n",
       "      <td>11873.673826</td>\n",
       "      <td>11863.0250</td>\n",
       "      <td>11852.376174</td>\n",
       "      <td>75.707059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.651780</td>\n",
       "      <td>-5.427407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.079187</td>\n",
       "      <td>11861.250000</td>\n",
       "      <td>11871.220</td>\n",
       "      <td>11879.7725</td>\n",
       "      <td>11876.69750</td>\n",
       "      <td>106.474863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:27:00</th>\n",
       "      <td>2020-11-19 02:27:00</td>\n",
       "      <td>11868.50</td>\n",
       "      <td>11872.25</td>\n",
       "      <td>11868.25</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11873.189021</td>\n",
       "      <td>11862.9125</td>\n",
       "      <td>11852.635979</td>\n",
       "      <td>86.916678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.416898</td>\n",
       "      <td>-4.204812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.621709</td>\n",
       "      <td>11861.583333</td>\n",
       "      <td>11871.160</td>\n",
       "      <td>11879.6075</td>\n",
       "      <td>11876.76500</td>\n",
       "      <td>99.316575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:28:00</th>\n",
       "      <td>2020-11-19 02:28:00</td>\n",
       "      <td>11870.50</td>\n",
       "      <td>11873.25</td>\n",
       "      <td>11869.25</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11873.423469</td>\n",
       "      <td>11862.9625</td>\n",
       "      <td>11852.501531</td>\n",
       "      <td>97.975957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.860676</td>\n",
       "      <td>-2.121068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.981743</td>\n",
       "      <td>11862.366667</td>\n",
       "      <td>11871.110</td>\n",
       "      <td>11879.4700</td>\n",
       "      <td>11876.84000</td>\n",
       "      <td>92.877717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19 02:29:00</th>\n",
       "      <td>2020-11-19 02:29:00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11873.00</td>\n",
       "      <td>11871.00</td>\n",
       "      <td>11871.75</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11874.455027</td>\n",
       "      <td>11863.3250</td>\n",
       "      <td>11852.194973</td>\n",
       "      <td>87.848066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.156105</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.123673</td>\n",
       "      <td>11863.166667</td>\n",
       "      <td>11871.020</td>\n",
       "      <td>11879.3200</td>\n",
       "      <td>11876.90000</td>\n",
       "      <td>77.918478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426066 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2019-01-13 17:00:00 2019-01-13 17:00:00   6599.00   6602.50   6590.25   \n",
       "2019-01-13 17:01:00 2019-01-13 17:01:00   6595.75   6598.75   6591.50   \n",
       "2019-01-13 17:02:00 2019-01-13 17:02:00   6595.75   6596.75   6589.00   \n",
       "2019-01-13 17:03:00 2019-01-13 17:03:00   6591.00   6592.75   6588.00   \n",
       "2019-01-13 17:04:00 2019-01-13 17:04:00   6588.25   6590.25   6586.50   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2020-11-19 02:25:00 2020-11-19 02:25:00  11864.25  11871.50  11864.25   \n",
       "2020-11-19 02:26:00 2020-11-19 02:26:00  11869.25  11871.25  11868.00   \n",
       "2020-11-19 02:27:00 2020-11-19 02:27:00  11868.50  11872.25  11868.25   \n",
       "2020-11-19 02:28:00 2020-11-19 02:28:00  11870.50  11873.25  11869.25   \n",
       "2020-11-19 02:29:00 2020-11-19 02:29:00  11873.00  11873.00  11871.00   \n",
       "\n",
       "                        Close  Volume    upper-band  middle-band  \\\n",
       "udate                                                              \n",
       "2019-01-13 17:00:00   6595.75   567.0           NaN          NaN   \n",
       "2019-01-13 17:01:00   6595.75   269.0           NaN          NaN   \n",
       "2019-01-13 17:02:00   6591.00   225.0           NaN          NaN   \n",
       "2019-01-13 17:03:00   6588.25   142.0           NaN          NaN   \n",
       "2019-01-13 17:04:00   6588.75   214.0           NaN          NaN   \n",
       "...                       ...     ...           ...          ...   \n",
       "2020-11-19 02:25:00  11869.25   155.0  11874.155992   11863.1625   \n",
       "2020-11-19 02:26:00  11868.50   114.0  11873.673826   11863.0250   \n",
       "2020-11-19 02:27:00  11870.50    85.0  11873.189021   11862.9125   \n",
       "2020-11-19 02:28:00  11873.00    80.0  11873.423469   11862.9625   \n",
       "2020-11-19 02:29:00  11871.75    48.0  11874.455027   11863.3250   \n",
       "\n",
       "                       lower-band         %b  ...  rsi      k-kdj     d-kdj  \\\n",
       "udate                                         ...                             \n",
       "2019-01-13 17:00:00           NaN        NaN  ...  NaN        NaN       NaN   \n",
       "2019-01-13 17:01:00           NaN        NaN  ...  NaN        NaN       NaN   \n",
       "2019-01-13 17:02:00           NaN        NaN  ...  NaN        NaN       NaN   \n",
       "2019-01-13 17:03:00           NaN        NaN  ...  NaN        NaN       NaN   \n",
       "2019-01-13 17:04:00           NaN        NaN  ...  NaN        NaN       NaN   \n",
       "...                           ...        ...  ...  ...        ...       ...   \n",
       "2020-11-19 02:25:00  11852.169008  77.686834  ...  0.0   9.187728 -6.309339   \n",
       "2020-11-19 02:26:00  11852.376174  75.707059  ...  0.0  12.651780 -5.427407   \n",
       "2020-11-19 02:27:00  11852.635979  86.916678  ...  0.0  17.416898 -4.204812   \n",
       "2020-11-19 02:28:00  11852.501531  97.975957  ...  0.0  24.860676 -2.121068   \n",
       "2020-11-19 02:29:00  11852.194973  87.848066  ...  0.0  30.156105  0.032432   \n",
       "\n",
       "                     j-kdj   diff-kdj        sma-15     sma-50     sma-100  \\\n",
       "udate                                                                        \n",
       "2019-01-13 17:00:00    NaN        NaN           NaN        NaN         NaN   \n",
       "2019-01-13 17:01:00    NaN        NaN           NaN        NaN         NaN   \n",
       "2019-01-13 17:02:00    NaN        NaN           NaN        NaN         NaN   \n",
       "2019-01-13 17:03:00    NaN        NaN           NaN        NaN         NaN   \n",
       "2019-01-13 17:04:00    NaN        NaN           NaN        NaN         NaN   \n",
       "...                    ...        ...           ...        ...         ...   \n",
       "2020-11-19 02:25:00    0.0  15.497067  11861.100000  11871.445  11879.9425   \n",
       "2020-11-19 02:26:00    0.0  18.079187  11861.250000  11871.220  11879.7725   \n",
       "2020-11-19 02:27:00    0.0  21.621709  11861.583333  11871.160  11879.6075   \n",
       "2020-11-19 02:28:00    0.0  26.981743  11862.366667  11871.110  11879.4700   \n",
       "2020-11-19 02:29:00    0.0  30.123673  11863.166667  11871.020  11879.3200   \n",
       "\n",
       "                         sma-200    vol-ema5  \n",
       "udate                                         \n",
       "2019-01-13 17:00:00          NaN         NaN  \n",
       "2019-01-13 17:01:00          NaN         NaN  \n",
       "2019-01-13 17:02:00          NaN         NaN  \n",
       "2019-01-13 17:03:00          NaN         NaN  \n",
       "2019-01-13 17:04:00          NaN  283.400000  \n",
       "...                          ...         ...  \n",
       "2020-11-19 02:25:00  11876.64375  102.712294  \n",
       "2020-11-19 02:26:00  11876.69750  106.474863  \n",
       "2020-11-19 02:27:00  11876.76500   99.316575  \n",
       "2020-11-19 02:28:00  11876.84000   92.877717  \n",
       "2020-11-19 02:29:00  11876.90000   77.918478  \n",
       "\n",
       "[426066 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.0 技術指標\n",
    "highs = np.array(df3['High'], dtype='float')\n",
    "lows = np.array(df3['Low'], dtype='float')\n",
    "opens = np.array(df3['Open'], dtype='float')\n",
    "closes = np.array(df3['Close'], dtype='float')\n",
    "vols = np.array(df3['Volume'], dtype='float')\n",
    "# 3.1 Bollinger 保力加\n",
    "df3['upper-band'], df3['middle-band'], df3['lower-band'] = talib.BBANDS(closes, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "# 3.2 %B %保力加\n",
    "df3['%b'] = (df3['Close']-df3['lower-band'])/(df3['upper-band']-df3['lower-band'])*100\n",
    "df3['%b-high']  = common.percentB_belowzero(df3['%b'], df3['Close']) \n",
    "df3['%b-low'] = common.percentB_aboveone(df3['%b'], df3['Close'])\n",
    "# 2.3 MACD\n",
    "weight = 1.5\n",
    "df3['macd'], df3['macdsignal'], df3['macdhist'] = talib.MACD(closes, fastperiod=12*weight, slowperiod=26*weight, signalperiod=9*weight)\n",
    "# 2.4 RSI\n",
    "df3['rsi-2'] = talib.RSI(closes, timeperiod=14*weight)\n",
    "df3['rsi'] = df3['rsi-2']\n",
    "df3['rsi'].loc[((df3['rsi'] < 85) & (df3['rsi'] > 25))] = 0\n",
    "# 2.5 KDJ\n",
    "df3['k-kdj'], df3['d-kdj'], df3['j-kdj'] = common.kdj(highs, lows, closes, window_size=5)\n",
    "df3['diff-kdj'] = df3['k-kdj']-df3['d-kdj']\n",
    "df3['j-kdj'].loc[((df3['j-kdj'] > 20) & (df3['j-kdj'] < 100))] = 0\n",
    "# 3.6 VWAP 成交量加權平均價格\n",
    "period = []\n",
    "for v in period:\n",
    "    df3['typical-price'] = (df3['High'] + df3['Low'] + df3['Close']) / 3\n",
    "    df3['turnover'] = df3['typical-price'] * df3['Volume']\n",
    "    df3['cum-turnover-'+str(v)] = df3['turnover'].rolling(window=v).sum()\n",
    "    df3['cum-volume-'+str(v)] = df3['Volume'].rolling(window=v).sum()\n",
    "    df3['vwap-'+str(v)] = df3['cum-turnover-'+str(v)] / df3['cum-volume-'+str(v)]\n",
    "    df3['vwap-'+str(v)] = df3['vwap-'+str(v)].replace([np.inf, -np.inf], 0)\n",
    "    df3['vwap-'+str(v)].fillna(0, inplace=True)\n",
    "    drop_list_1 = ['turnover', 'typical-price', 'cum-turnover-'+str(v), 'cum-volume-'+str(v)]\n",
    "    df3.drop(drop_list_1, axis=1, inplace=True)\n",
    "# 3.7 SMA 均線\n",
    "for v in [15, 50, 100, 200]:\n",
    "    df3['sma-'+str(v)]= talib.SMA(closes, timeperiod=v)\n",
    "# 3.8 VOL EMA\n",
    "df3['vol-ema5'] = talib.EMA(vols, timeperiod=5)\n",
    "# 3.9 P-SAR 抛物线\n",
    "#df3['p-sar'] = talib.SAR(highs, lows, acceleration=0.02, maximum=0.2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excpet & delete:  2019-01-13\n",
      "excpet & delete:  2019-01-20\n",
      "excpet & delete:  2019-01-27\n",
      "excpet & delete:  2019-02-10\n",
      "excpet & delete:  2019-02-17\n",
      "excpet & delete:  2019-02-24\n",
      "excpet & delete:  2019-03-03\n",
      "excpet & delete:  2019-03-10\n",
      "excpet & delete:  2019-03-17\n",
      "excpet & delete:  2019-03-24\n",
      "excpet & delete:  2019-04-21\n",
      "excpet & delete:  2019-04-28\n",
      "excpet & delete:  2019-05-12\n",
      "excpet & delete:  2019-05-19\n",
      "excpet & delete:  2019-05-26\n",
      "excpet & delete:  2019-06-02\n",
      "excpet & delete:  2019-06-09\n",
      "excpet & delete:  2019-06-16\n",
      "excpet & delete:  2019-06-23\n",
      "excpet & delete:  2019-07-21\n",
      "excpet & delete:  2019-07-28\n",
      "excpet & delete:  2019-08-04\n",
      "excpet & delete:  2019-08-11\n",
      "excpet & delete:  2019-08-18\n",
      "excpet & delete:  2019-08-25\n",
      "excpet & delete:  2019-09-08\n",
      "excpet & delete:  2019-09-15\n",
      "excpet & delete:  2019-09-22\n",
      "excpet & delete:  2019-09-29\n",
      "excpet & delete:  2019-10-13\n",
      "excpet & delete:  2019-10-27\n",
      "excpet & delete:  2019-11-10\n",
      "excpet & delete:  2019-11-17\n",
      "excpet & delete:  2019-11-24\n",
      "excpet & delete:  2019-12-01\n",
      "excpet & delete:  2019-12-08\n",
      "excpet & delete:  2020-02-16\n",
      "excpet & delete:  2020-02-16\n",
      "excpet & delete:  2020-02-18\n",
      "excpet & delete:  2020-02-19\n",
      "excpet & delete:  2020-02-20\n",
      "excpet & delete:  2020-02-23\n",
      "excpet & delete:  2020-04-05\n",
      "excpet & delete:  2020-04-12\n",
      "excpet & delete:  2020-04-19\n",
      "excpet & delete:  2020-04-26\n",
      "excpet & delete:  2020-05-03\n",
      "excpet & delete:  2020-05-10\n",
      "excpet & delete:  2020-05-17\n",
      "excpet & delete:  2020-05-24\n",
      "excpet & delete:  2020-05-31\n",
      "excpet & delete:  2020-06-07\n",
      "excpet & delete:  2020-06-14\n",
      "excpet & delete:  2020-06-21\n",
      "excpet & delete:  2020-06-28\n",
      "excpet & delete:  2020-08-02\n",
      "excpet & delete:  2020-08-09\n",
      "excpet & delete:  2020-08-16\n",
      "excpet & delete:  2020-08-23\n",
      "excpet & delete:  2020-08-30\n",
      "excpet & delete:  2020-09-06\n",
      "excpet & delete:  2020-09-13\n",
      "excpet & delete:  2020-09-17\n",
      "excpet & delete:  2020-09-20\n",
      "excpet & delete:  2020-09-27\n",
      "excpet & delete:  2020-10-04\n",
      "excpet & delete:  2020-10-11\n",
      "excpet & delete:  2020-10-18\n",
      "excpet & delete:  2020-10-25\n",
      "excpet & delete:  2020-10-29\n",
      "excpet & delete:  2020-11-01\n",
      "excpet & delete:  2020-11-08\n",
      "excpet & delete:  2020-11-15\n",
      "excpet & delete:  2019-01-13\n",
      "excpet & delete:  2019-01-20\n",
      "excpet & delete:  2019-03-08\n",
      "excpet & delete:  2019-03-15\n",
      "excpet & delete:  2019-03-16\n",
      "excpet & delete:  2019-03-17\n",
      "excpet & delete:  2019-05-24\n",
      "excpet & delete:  2019-05-25\n",
      "excpet & delete:  2019-05-26\n",
      "excpet & delete:  2020-03-08\n",
      "excpet & delete:  2020-03-15\n",
      "excpet & delete:  2020-03-17\n",
      "excpet & delete:  2020-05-24\n",
      "excpet & delete:  2020-09-06\n"
     ]
    }
   ],
   "source": [
    "# 4.0 draw chart\n",
    "drop_list_2 = []\n",
    "is_render_chart = False\n",
    "\n",
    "def draw_worker(df4_2, day):\n",
    "    try:\n",
    "        # 4.1 style\n",
    "        style = mpf.make_mpf_style(base_mpf_style='charles', rc={'font.size':6})\n",
    "        # 4.2 addplot\n",
    "        apds = [mpf.make_addplot(df4_2['lower-band'],panel=0,color='orange',linestyle='solid'),\n",
    "                mpf.make_addplot(df4_2['upper-band'],panel=0,color='bisque',linestyle='solid'),\n",
    "                # mpf.make_addplot(df4_2['vwap-50'].replace(0, np.nan),panel=0,color='aqua',linestyle='solid'),\n",
    "                mpf.make_addplot(df4_2['%b-low'],type='scatter',markersize=20,marker='v',panel=0),\n",
    "                mpf.make_addplot(df4_2['%b-high'],type='scatter',markersize=20,marker='^',panel=0),\n",
    "                # mpf.make_addplot(df4_2['p-sar'],scatter=True,markersize=1,marker='*',panel=0,color='blueviolet'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['vol-ema5'],panel=1,color='orange'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['macd'],panel=2,color='orange'),\n",
    "                mpf.make_addplot(df4_2['macdsignal'],panel=2,color='violet'),\n",
    "                mpf.make_addplot(df4_2['macdhist'],panel=2,type='bar',color='dimgray'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['k-kdj'],panel=3,color='orange'),\n",
    "                mpf.make_addplot(df4_2['d-kdj'],panel=3,color='violet'),\n",
    "                mpf.make_addplot(df4_2['j-kdj'],panel=3,color='aqua'),\n",
    "                mpf.make_addplot(df4_2['diff-kdj'],panel=3,type='bar',color='dimgray'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['rsi-2'],panel=4,color='orange'),\n",
    "                mpf.make_addplot(df4_2['rsi'],panel=4,color='violet')]\n",
    "        # 4.3 draw\n",
    "        mpf.plot(df4_2, type='candle', addplot=apds, style=style, ylabel='', ylabel_lower='', volume=True, figscale=0.85, xrotation=0, datetime_format=\"%H:%M\", \n",
    "                 show_nontrading=False, tight_layout=True, savefig='./data/img-nq/features/'+day.strftime('%Y-%m-%d'))\n",
    "        print('finish draw:', df4_2.shape, df4_2['udate'].iloc[0], df4_2['udate'].iloc[-1])\n",
    "    except:\n",
    "        print('do not draw:', k, '\\n')\n",
    "\n",
    "# 4.5 multi processing\n",
    "pool = mp.Pool(processes=4, maxtasksperchild=4)\n",
    "# 4.6 draw\n",
    "df4 = df3.copy(deep=True)\n",
    "data2 = separate_daily(df4, 'dict')\n",
    "for k, df4_1 in data2.items():\n",
    "    # 4.7 drop error day\n",
    "    if df4_1['Volume'].shape[0] == df4_1['Volume'].isin([0]).sum() or df4_1['Volume'].shape[0] <= 100:\n",
    "        drop_list_2.append(k)\n",
    "    # 4.8 draw chart\n",
    "    elif (is_render_chart):\n",
    "        pool.apply_async(draw_worker, args=(df4_1, k))\n",
    "    if k.weekday() == 6:\n",
    "        drop_list_2.append(k)\n",
    "# 4.9 kill multi processing\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "drop_list_2.append(date(2019, 1, 13))\n",
    "drop_list_2.append(date(2019, 1, 20))\n",
    "drop_list_2.append(date(2019, 3, 8))\n",
    "drop_list_2.append(date(2019, 3, 15))\n",
    "drop_list_2.append(date(2019, 3, 16))\n",
    "drop_list_2.append(date(2019, 3, 17))\n",
    "drop_list_2.append(date(2019, 5, 24))\n",
    "drop_list_2.append(date(2019, 5, 25))\n",
    "drop_list_2.append(date(2019, 5, 26))\n",
    "\n",
    "drop_list_2.append(date(2020, 3, 8))\n",
    "drop_list_2.append(date(2020, 3, 15))\n",
    "drop_list_2.append(date(2020, 3, 17))\n",
    "drop_list_2.append(date(2020, 5, 24))\n",
    "drop_list_2.append(date(2020, 9, 6))\n",
    "for k in drop_list_2:\n",
    "    data2.pop(k, None)\n",
    "    print('excpet & delete: ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集: Total dataset has 336211 samples, and 13 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>%b</th>\n",
       "      <th>%b-high</th>\n",
       "      <th>%b-low</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>rsi</th>\n",
       "      <th>j-kdj</th>\n",
       "      <th>diff-kdj</th>\n",
       "      <th>sma-15</th>\n",
       "      <th>sma-50</th>\n",
       "      <th>sma-100</th>\n",
       "      <th>sma-200</th>\n",
       "      <th>udate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-14 17:00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138131</td>\n",
       "      <td>0.959914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420826</td>\n",
       "      <td>0.374474</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>2019-01-14 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 17:01:00</th>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.229229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420826</td>\n",
       "      <td>0.319732</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.032302</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>2019-01-14 17:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 17:02:00</th>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.283814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.959777</td>\n",
       "      <td>0.400855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420826</td>\n",
       "      <td>0.278038</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>2019-01-14 17:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 17:03:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430506</td>\n",
       "      <td>0.232548</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>2019-01-14 17:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 17:04:00</th>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.406376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405650</td>\n",
       "      <td>0.210130</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.029631</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>2019-01-14 17:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18 15:56:00</th>\n",
       "      <td>0.045597</td>\n",
       "      <td>0.333628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.830818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.048337</td>\n",
       "      <td>0.047991</td>\n",
       "      <td>2020-11-18 15:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18 15:57:00</th>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.333732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.617392</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>2020-11-18 15:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18 15:58:00</th>\n",
       "      <td>0.055031</td>\n",
       "      <td>0.445374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.808578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.620631</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>2020-11-18 15:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18 15:59:00</th>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.331654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.795870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>2020-11-18 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18 16:00:00</th>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.343446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.784750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.585389</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-11-18 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335641 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Close        %b   %b-high    %b-low  macdhist  rsi  \\\n",
       "udate                                                                        \n",
       "2019-01-14 17:00:00  0.000000  0.138131  0.959914  0.000000  0.421368  0.0   \n",
       "2019-01-14 17:01:00  0.000829  0.229229  0.000000  0.000000  0.408547  0.0   \n",
       "2019-01-14 17:02:00  0.001658  0.283814  0.000000  0.959777  0.400855  0.0   \n",
       "2019-01-14 17:03:00  0.000000  0.285066  0.000000  0.000000  0.394017  0.0   \n",
       "2019-01-14 17:04:00  0.005804  0.406376  0.000000  0.000000  0.396581  0.0   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2020-11-18 15:56:00  0.045597  0.333628  0.000000  0.000000  0.830818  0.0   \n",
       "2020-11-18 15:57:00  0.044025  0.333732  0.000000  0.000000  0.814932  0.0   \n",
       "2020-11-18 15:58:00  0.055031  0.445374  0.000000  0.000000  0.808578  0.0   \n",
       "2020-11-18 15:59:00  0.042453  0.331654  0.000000  0.000000  0.795870  0.0   \n",
       "2020-11-18 16:00:00  0.042453  0.343446  0.000000  0.000000  0.784750  0.0   \n",
       "\n",
       "                        j-kdj  diff-kdj    sma-15    sma-50   sma-100  \\\n",
       "udate                                                                   \n",
       "2019-01-14 17:00:00  0.420826  0.374474  0.007473  0.002671  0.033107   \n",
       "2019-01-14 17:01:00  0.420826  0.319732  0.006733  0.002214  0.032302   \n",
       "2019-01-14 17:02:00  0.420826  0.278038  0.006026  0.001335  0.031460   \n",
       "2019-01-14 17:03:00  0.430506  0.232548  0.005016  0.000703  0.030509   \n",
       "2019-01-14 17:04:00  0.405650  0.210130  0.004511  0.000808  0.029631   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2020-11-18 15:56:00  0.374900  0.626155  0.003812  0.019202  0.048337   \n",
       "2020-11-18 15:57:00  0.374900  0.617392  0.003465  0.014290  0.036372   \n",
       "2020-11-18 15:58:00  0.374900  0.620631  0.003951  0.010420  0.024288   \n",
       "2020-11-18 15:59:00  0.374900  0.604534  0.002426  0.006029  0.012204   \n",
       "2020-11-18 16:00:00  0.374900  0.585389  0.001733  0.000000  0.000000   \n",
       "\n",
       "                      sma-200               udate  \n",
       "udate                                              \n",
       "2019-01-14 17:00:00  0.027229 2019-01-14 17:00:00  \n",
       "2019-01-14 17:01:00  0.026722 2019-01-14 17:01:00  \n",
       "2019-01-14 17:02:00  0.026254 2019-01-14 17:02:00  \n",
       "2019-01-14 17:03:00  0.025708 2019-01-14 17:03:00  \n",
       "2019-01-14 17:04:00  0.025201 2019-01-14 17:04:00  \n",
       "...                       ...                 ...  \n",
       "2020-11-18 15:56:00  0.047991 2020-11-18 15:56:00  \n",
       "2020-11-18 15:57:00  0.035528 2020-11-18 15:57:00  \n",
       "2020-11-18 15:58:00  0.023624 2020-11-18 15:58:00  \n",
       "2020-11-18 15:59:00  0.011533 2020-11-18 15:59:00  \n",
       "2020-11-18 16:00:00  0.000000 2020-11-18 16:00:00  \n",
       "\n",
       "[335641 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.0 合併\n",
    "df5 = pd.DataFrame()\n",
    "for k, df5_1 in data2.items():\n",
    "    df5 = pd.concat([df5, df5_1], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "# 5.1 清洗\n",
    "df5_3 = df5.copy(deep=True)\n",
    "drop_list_3 = ['High', 'Low', 'Open', 'Volume', 'macd', 'macdsignal', 'upper-band', 'lower-band', 'middle-band', 'k-kdj', 'd-kdj', 'vol-ema5', 'rsi-2']\n",
    "df5_3.drop(drop_list_3, axis=1, inplace=True)\n",
    "df5_3.fillna(0, inplace=True)\n",
    "df5_3 = df5_3.round(2)\n",
    "\n",
    "# 5.2 檢查\n",
    "is_contain_null = df5_3.isnull().sum()\n",
    "is_contain_nan = df5_3.isna().sum()\n",
    "is_contain_inf = df5_3.isin([np.nan]).sum()\n",
    "print('数据集: Total dataset has {} samples, and {} features.'.format(df5_3.shape[0], df5_3.shape[1])) # df5_3.info()\n",
    "\n",
    "# 5.3 儲存\n",
    "path_data = os.path.abspath(os.path.join('data', 'nq', 'clean-data', 'nq-clean-data-with-features.csv'))\n",
    "if os.path.exists(path_data):\n",
    "    os.remove(path_data)\n",
    "df5_3.to_csv(path_data)\n",
    "\n",
    "# 5.4.1 分包 (日子)\n",
    "data3 = separate_daily(df5_3, 'dict')\n",
    "# 5.3.2 正則化\n",
    "normalization_days = 10\n",
    "days2 = np.array(list(data3.keys()))\n",
    "len_days2 = (days2.shape[0]//normalization_days)+1\n",
    "data3_1 = []\n",
    "scalers = {}\n",
    "for i in range(len_days2):\n",
    "    try:\n",
    "        start1, end1 = i*normalization_days, (i+1)*normalization_days\n",
    "        if end1 >= days2.shape[0]:\n",
    "            end1 = days2.shape[0]-1\n",
    "        # 5.3.3 每X日集合\n",
    "        day_start, day_end = days2[start1], days2[end1]\n",
    "        day_start2 = datetime(day_start.year, day_start.month, day_start.day, 17, 0, 0)\n",
    "        day_end2 = datetime(day_end.year, day_end.month, day_end.day, 16, 0, 0)\n",
    "        mask = ((df5_3['udate'] >= day_start2) & (df5_3['udate'] <= day_end2))\n",
    "        df5_4 = df5_3[mask]\n",
    "        # 5.4.4 正則代集合\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        df5_5 = df5_4.drop(['udate'], axis=1)\n",
    "        min_max_scaler.fit(df5_5)\n",
    "        scalers[i] = {'scaler': min_max_scaler, 'day_start': day_start2, 'day_end': day_end2}\n",
    "        df5_6 = min_max_scaler.transform(df5_5)\n",
    "        df5_6 = pd.DataFrame(df5_6, columns=df5_5.columns, index=df5_5.index)\n",
    "        df5_6['udate'] = df5_4['udate']\n",
    "        # 5.4.5 合併\n",
    "        data3_1.append(df5_6)\n",
    "    except:\n",
    "        print('except: ', start1, end1, len(days2))\n",
    "\n",
    "# 5.4.6 合併\n",
    "df5_7 = pd.DataFrame()\n",
    "for df5_8 in data3_1:\n",
    "    df5_7 = pd.concat([df5_7, df5_8], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "df5_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 36, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.5.1 訓練集, 測試集, 數據集\n",
    "df5_8 = df5_7.copy(deep=True)\n",
    "\n",
    "is_raw_data = False\n",
    "if is_raw_data:\n",
    "    drop_list_5 = df5_8.columns.values.tolist()\n",
    "    drop_list_5.remove('Close')\n",
    "    drop_list_5.remove('udate')\n",
    "    df5_8.drop(drop_list_5, axis=1, inplace=True)\n",
    "\n",
    "data4 = separate_daily(df5_8, 'dict')\n",
    "days3 = np.array(list(data4.keys()))\n",
    "\n",
    "# train_set, test_set, valid_set = days3[0:-76], days3[-76:-33], days3[-33:-2] # 0921~1113\n",
    "# train_set, test_set, valid_set = days3[0:-63], days3[-63:-21], days3[-21:-2] # 1012-1113\n",
    "train_set, test_set, valid_set = days3[0:-110], days3[-110:-74], days3[-74:-32] # 0608~0921\n",
    "x_train, y_train, date_train = np.array([]), np.array([]), []\n",
    "x_test, y_test, date_test = np.array([]), np.array([]), []\n",
    "x_valid, y_valid, date_valid = np.array([]), np.array([]), []\n",
    "len(train_set), len(test_set), len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集: X_train Data: (177710, 50, 12), Y_train Data: (177710, 5), Date_Train: (177710, 5)\n",
      "測試集: X_Test Data: (47185, 50, 12), Y_Test Data: (47185, 5), Date_Test: (47185, 5)\n",
      "验证集: X_Valid Data: (54998, 50, 12), Y_Valid Data: (54998, 5), Date_Valid: (54998, 5)\n"
     ]
    }
   ],
   "source": [
    "# 5.5.2 窗口步長\n",
    "t_pus_no = 5\n",
    "window_size = 50\n",
    "is_y_label_m_to_n = True\n",
    "\n",
    "for day, df6 in data4.items():\n",
    "    df6.drop(['udate'], axis=1, inplace=True)\n",
    "    # 5.5.3 窗口\n",
    "    no_max = df6.shape[0]-t_pus_no\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(window_size, no_max):\n",
    "        start, end = i-window_size, i\n",
    "        # y label\n",
    "        if is_y_label_m_to_n:\n",
    "            temp_0 = df6.iloc[end: end+t_pus_no] # t1 ~ t5\n",
    "            temp_2 = df6.iloc[end-1: end+t_pus_no-1] # current time\n",
    "        else:\n",
    "            temp_0 = df6.iloc[end+t_pus_no: end+t_pus_no] # t5\n",
    "            temp_2 = df6.iloc[end-t_pus_no-1: end-t_pus_no-1] # current time\n",
    "        y_data.append(temp_0['Close'])\n",
    "        # x matrix\n",
    "        temp_1 = df6.iloc[start: end]\n",
    "        x_data.append(temp_1)\n",
    "        # date\n",
    "        days4 = temp_2.index.tolist()\n",
    "        if day in train_set:\n",
    "            date_train.append(days4)\n",
    "        elif day in test_set:\n",
    "            date_test.append(days4)\n",
    "        elif day in valid_set:\n",
    "            date_valid.append(days4)\n",
    "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "    # print(day, x_data.shape, y_data.shape)\n",
    "    # 5.5.4 分集1\n",
    "    if day in train_set and x_train.any() and y_train.any():\n",
    "        x_train = np.concatenate((x_train, x_data), axis=0)\n",
    "        y_train = np.concatenate((y_train, y_data), axis=0)\n",
    "    elif day in test_set and x_test.any() and y_test.any():\n",
    "        x_test = np.concatenate((x_test, x_data), axis=0)\n",
    "        y_test = np.concatenate((y_test, y_data), axis=0)\n",
    "    elif day in valid_set and x_valid.any() and y_valid.any():\n",
    "        x_valid = np.concatenate((x_valid, x_data), axis=0)\n",
    "        y_valid = np.concatenate((y_valid, y_data), axis=0)\n",
    "    # 5.5.5 分集2\n",
    "    if day in train_set and not x_train.any() and not y_train.any():\n",
    "        x_train, y_train = x_data, y_data\n",
    "    elif day in test_set and not x_test.any() and not y_test.any():\n",
    "        x_test, y_test = x_data, y_data\n",
    "    elif day in valid_set and not x_valid.any() and not y_valid.any():\n",
    "        x_valid, y_valid = x_data, y_data\n",
    "\n",
    "# no_batches, timesteps, no_features\n",
    "print('訓練集: X_train Data: {}, Y_train Data: {}, Date_Train: {}'.format(x_train.shape, y_train.shape, np.array(date_train).shape))\n",
    "print('測試集: X_Test Data: {}, Y_Test Data: {}, Date_Test: {}'.format(x_test.shape, y_test.shape, np.array(date_test).shape))\n",
    "print('验证集: X_Valid Data: {}, Y_Valid Data: {}, Date_Valid: {}'.format(x_valid.shape, y_valid.shape, np.array(date_valid).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 512)           1075200   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 9,474,565\n",
      "Trainable params: 9,474,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "348/348 [==============================] - 101s 290ms/step - loss: 0.0076 - accuracy: 0.2017 - val_loss: 2.5212e-04 - val_accuracy: 0.1827\n",
      "Epoch 2/6\n",
      "348/348 [==============================] - 100s 289ms/step - loss: 0.0011 - accuracy: 0.2001 - val_loss: 4.5375e-04 - val_accuracy: 0.2777\n",
      "Epoch 3/6\n",
      "348/348 [==============================] - 101s 289ms/step - loss: 8.8717e-04 - accuracy: 0.1997 - val_loss: 1.6699e-04 - val_accuracy: 0.2027\n",
      "Epoch 4/6\n",
      "348/348 [==============================] - 101s 290ms/step - loss: 8.0418e-04 - accuracy: 0.2002 - val_loss: 8.2819e-04 - val_accuracy: 0.1388\n",
      "Epoch 5/6\n",
      "348/348 [==============================] - 101s 291ms/step - loss: 6.3086e-04 - accuracy: 0.2009 - val_loss: 7.4107e-04 - val_accuracy: 0.1525\n",
      "Epoch 6/6\n",
      "348/348 [==============================] - 101s 291ms/step - loss: 5.8648e-04 - accuracy: 0.2003 - val_loss: 1.9289e-04 - val_accuracy: 0.2773\n"
     ]
    }
   ],
   "source": [
    "# 6.1.1 模型参数\n",
    "batch_size = 512\n",
    "epochs = 6\n",
    "units = 512\n",
    "verbose = 1\n",
    "no_batches = x_train.shape[0]\n",
    "timesteps = x_train.shape[1]\n",
    "no_features = x_train.shape[2]\n",
    "batch_input_shape = (timesteps, no_features)\n",
    "\n",
    "# 6.1.2 日志参数\n",
    "prefix = 'nq-lstm'\n",
    "cur_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# 6.2 模型 \n",
    "# activation=softsign/tanh\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(units=units, recurrent_activation='sigmoid', activation='tanh', unroll=False, use_bias=True, \n",
    "               recurrent_dropout=0, return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=False, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "if is_y_label_m_to_n:\n",
    "    model.add(Dense(units=t_pus_no))\n",
    "else:\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001) # 0.001\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 6.3.1 check point\n",
    "checkpoint_dir = './training_checkpoints/'+ prefix +'-' + cur_time\n",
    "os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "# 6.3.2 tensor board\n",
    "log_dir = os.path.join('./logs/fit/'+ prefix +'-') + cur_time\n",
    "os.mkdir(log_dir)\n",
    "tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# 6.4 fit model\n",
    "history_model = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True, verbose=verbose, callbacks=[checkpoint_callback, tensor_board_callback])\n",
    "\n",
    "# 6.5 save model\n",
    "model_path = \"./saved_model/\"+prefix+\"-\"+cur_time+\".h5\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.1 visualize loss\n",
    "keys = list(history_model.history.keys())\n",
    "training_loss = history_model.history['loss']\n",
    "test_loss = history_model.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('model:'+prefix+'   batch_size:'+str(batch_size)+'   epochs:'+str(epochs)+'   units:'+str(units),loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-loss')\n",
    "plt.clf()\n",
    "\n",
    "# 7.2 visualize accuracy\n",
    "training_accuracy = history_model.history['accuracy']\n",
    "test_accuracy = history_model.history['val_accuracy']\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('model:'+prefix+'   batch_size:'+str(batch_size)+'   epochs:'+str(epochs)+'   units:'+str(units),loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-accuracy')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5554/5554 [==============================] - 76s 14ms/step - loss: 2.0333e-04 - accuracy: 0.2831\n",
      "1475/1475 [==============================] - 20s 14ms/step - loss: 1.9289e-04 - accuracy: 0.2773\n",
      "1719/1719 [==============================] - 24s 14ms/step - loss: 6.2085e-04 - accuracy: 0.3833\n",
      "Train Score: 0.0002 MSE (0.0143 RMSE)\n",
      "Test Score: 0.0002 MSE (0.0139 RMSE)\n",
      "Validate Score: 0.0006 MSE (0.0249 RMSE)\n"
     ]
    }
   ],
   "source": [
    "# 8.0 model evaluate\n",
    "verbose = 1\n",
    "train_score = model.evaluate(x_train, y_train, verbose=verbose)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "valid_score = model.evaluate(x_valid, y_valid, verbose=verbose)\n",
    "\n",
    "print('Train Score: %.4f MSE (%.4f RMSE)' % (train_score[0], math.sqrt(train_score[0])))\n",
    "print('Test Score: %.4f MSE (%.4f RMSE)' % (test_score[0], math.sqrt(test_score[0])))\n",
    "print('Validate Score: %.4f MSE (%.4f RMSE)' % (valid_score[0], math.sqrt(valid_score[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>udate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:49:00</th>\n",
       "      <td>0.698075</td>\n",
       "      <td>0.694951</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.692832</td>\n",
       "      <td>0.695509</td>\n",
       "      <td>2020-06-08 17:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:50:00</th>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.696356</td>\n",
       "      <td>0.698906</td>\n",
       "      <td>0.694316</td>\n",
       "      <td>0.696892</td>\n",
       "      <td>2020-06-08 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:51:00</th>\n",
       "      <td>0.700423</td>\n",
       "      <td>0.697349</td>\n",
       "      <td>0.699969</td>\n",
       "      <td>0.695396</td>\n",
       "      <td>0.697872</td>\n",
       "      <td>2020-06-08 17:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:52:00</th>\n",
       "      <td>0.701034</td>\n",
       "      <td>0.697833</td>\n",
       "      <td>0.700483</td>\n",
       "      <td>0.695941</td>\n",
       "      <td>0.698349</td>\n",
       "      <td>2020-06-08 17:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:53:00</th>\n",
       "      <td>0.701298</td>\n",
       "      <td>0.697966</td>\n",
       "      <td>0.700613</td>\n",
       "      <td>0.696112</td>\n",
       "      <td>0.698497</td>\n",
       "      <td>2020-06-08 17:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:50:00</th>\n",
       "      <td>0.345701</td>\n",
       "      <td>0.344627</td>\n",
       "      <td>0.345452</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.344198</td>\n",
       "      <td>2020-09-22 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:51:00</th>\n",
       "      <td>0.346120</td>\n",
       "      <td>0.345191</td>\n",
       "      <td>0.346038</td>\n",
       "      <td>0.343821</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>2020-09-22 15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:52:00</th>\n",
       "      <td>0.347392</td>\n",
       "      <td>0.346564</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.345192</td>\n",
       "      <td>0.346083</td>\n",
       "      <td>2020-09-22 15:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:53:00</th>\n",
       "      <td>0.349057</td>\n",
       "      <td>0.348237</td>\n",
       "      <td>0.349148</td>\n",
       "      <td>0.346880</td>\n",
       "      <td>0.347740</td>\n",
       "      <td>2020-09-22 15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:54:00</th>\n",
       "      <td>0.350465</td>\n",
       "      <td>0.349552</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.349047</td>\n",
       "      <td>2020-09-22 15:54:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54998 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           t1        t2        t3        t4        t5  \\\n",
       "udate                                                                   \n",
       "2020-06-08 17:49:00  0.698075  0.694951  0.697406  0.692832  0.695509   \n",
       "2020-06-08 17:50:00  0.699376  0.696356  0.698906  0.694316  0.696892   \n",
       "2020-06-08 17:51:00  0.700423  0.697349  0.699969  0.695396  0.697872   \n",
       "2020-06-08 17:52:00  0.701034  0.697833  0.700483  0.695941  0.698349   \n",
       "2020-06-08 17:53:00  0.701298  0.697966  0.700613  0.696112  0.698497   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2020-09-22 15:50:00  0.345701  0.344627  0.345452  0.343284  0.344198   \n",
       "2020-09-22 15:51:00  0.346120  0.345191  0.346038  0.343821  0.344734   \n",
       "2020-09-22 15:52:00  0.347392  0.346564  0.347446  0.345192  0.346083   \n",
       "2020-09-22 15:53:00  0.349057  0.348237  0.349148  0.346880  0.347740   \n",
       "2020-09-22 15:54:00  0.350465  0.349552  0.350468  0.348214  0.349047   \n",
       "\n",
       "                                  udate  \n",
       "udate                                    \n",
       "2020-06-08 17:49:00 2020-06-08 17:49:00  \n",
       "2020-06-08 17:50:00 2020-06-08 17:50:00  \n",
       "2020-06-08 17:51:00 2020-06-08 17:51:00  \n",
       "2020-06-08 17:52:00 2020-06-08 17:52:00  \n",
       "2020-06-08 17:53:00 2020-06-08 17:53:00  \n",
       "...                                 ...  \n",
       "2020-09-22 15:50:00 2020-09-22 15:50:00  \n",
       "2020-09-22 15:51:00 2020-09-22 15:51:00  \n",
       "2020-09-22 15:52:00 2020-09-22 15:52:00  \n",
       "2020-09-22 15:53:00 2020-09-22 15:53:00  \n",
       "2020-09-22 15:54:00 2020-09-22 15:54:00  \n",
       "\n",
       "[54998 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.0 預測\n",
    "predict1 = model.predict(x_valid)\n",
    "if is_y_label_m_to_n:\n",
    "    columns1=['t1', 't2', 't3', 't4', 't5']\n",
    "else:\n",
    "    columns1=['predict_close']\n",
    "df7 = pd.DataFrame(predict1, columns=columns1)\n",
    "date_valid2 = [v[0] for v in date_valid]\n",
    "df7['udate'] = date_valid2\n",
    "df7.index = df7['udate']\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:49:00</th>\n",
       "      <td>2020-06-08 17:49:00</td>\n",
       "      <td>9847.896840</td>\n",
       "      <td>9844.890565</td>\n",
       "      <td>9847.253499</td>\n",
       "      <td>9842.851080</td>\n",
       "      <td>9845.427084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:50:00</th>\n",
       "      <td>2020-06-08 17:50:00</td>\n",
       "      <td>9849.149789</td>\n",
       "      <td>9846.242362</td>\n",
       "      <td>9848.696972</td>\n",
       "      <td>9844.279580</td>\n",
       "      <td>9846.758228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:51:00</th>\n",
       "      <td>2020-06-08 17:51:00</td>\n",
       "      <td>9850.157082</td>\n",
       "      <td>9847.198424</td>\n",
       "      <td>9849.720214</td>\n",
       "      <td>9845.318656</td>\n",
       "      <td>9847.702071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:52:00</th>\n",
       "      <td>2020-06-08 17:52:00</td>\n",
       "      <td>9850.745234</td>\n",
       "      <td>9847.664723</td>\n",
       "      <td>9850.215083</td>\n",
       "      <td>9845.843587</td>\n",
       "      <td>9848.161371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:53:00</th>\n",
       "      <td>2020-06-08 17:53:00</td>\n",
       "      <td>9850.999668</td>\n",
       "      <td>9847.792313</td>\n",
       "      <td>9850.339976</td>\n",
       "      <td>9846.008065</td>\n",
       "      <td>9848.303819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:50:00</th>\n",
       "      <td>2020-09-22 15:50:00</td>\n",
       "      <td>11145.732331</td>\n",
       "      <td>11144.619968</td>\n",
       "      <td>11145.474770</td>\n",
       "      <td>11143.228118</td>\n",
       "      <td>11144.175227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:51:00</th>\n",
       "      <td>2020-09-22 15:51:00</td>\n",
       "      <td>11146.166603</td>\n",
       "      <td>11145.204145</td>\n",
       "      <td>11146.081953</td>\n",
       "      <td>11143.784932</td>\n",
       "      <td>11144.730127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:52:00</th>\n",
       "      <td>2020-09-22 15:52:00</td>\n",
       "      <td>11147.484767</td>\n",
       "      <td>11146.626816</td>\n",
       "      <td>11147.541344</td>\n",
       "      <td>11145.205164</td>\n",
       "      <td>11146.128432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:53:00</th>\n",
       "      <td>2020-09-22 15:53:00</td>\n",
       "      <td>11149.209903</td>\n",
       "      <td>11148.360692</td>\n",
       "      <td>11149.304806</td>\n",
       "      <td>11146.954728</td>\n",
       "      <td>11147.845755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:54:00</th>\n",
       "      <td>2020-09-22 15:54:00</td>\n",
       "      <td>11150.669356</td>\n",
       "      <td>11149.723327</td>\n",
       "      <td>11150.672784</td>\n",
       "      <td>11148.336912</td>\n",
       "      <td>11149.200330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54998 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate            t1            t2  \\\n",
       "udate                                                                 \n",
       "2020-06-08 17:49:00 2020-06-08 17:49:00   9847.896840   9844.890565   \n",
       "2020-06-08 17:50:00 2020-06-08 17:50:00   9849.149789   9846.242362   \n",
       "2020-06-08 17:51:00 2020-06-08 17:51:00   9850.157082   9847.198424   \n",
       "2020-06-08 17:52:00 2020-06-08 17:52:00   9850.745234   9847.664723   \n",
       "2020-06-08 17:53:00 2020-06-08 17:53:00   9850.999668   9847.792313   \n",
       "...                                 ...           ...           ...   \n",
       "2020-09-22 15:50:00 2020-09-22 15:50:00  11145.732331  11144.619968   \n",
       "2020-09-22 15:51:00 2020-09-22 15:51:00  11146.166603  11145.204145   \n",
       "2020-09-22 15:52:00 2020-09-22 15:52:00  11147.484767  11146.626816   \n",
       "2020-09-22 15:53:00 2020-09-22 15:53:00  11149.209903  11148.360692   \n",
       "2020-09-22 15:54:00 2020-09-22 15:54:00  11150.669356  11149.723327   \n",
       "\n",
       "                               t3            t4            t5  \n",
       "udate                                                          \n",
       "2020-06-08 17:49:00   9847.253499   9842.851080   9845.427084  \n",
       "2020-06-08 17:50:00   9848.696972   9844.279580   9846.758228  \n",
       "2020-06-08 17:51:00   9849.720214   9845.318656   9847.702071  \n",
       "2020-06-08 17:52:00   9850.215083   9845.843587   9848.161371  \n",
       "2020-06-08 17:53:00   9850.339976   9846.008065   9848.303819  \n",
       "...                           ...           ...           ...  \n",
       "2020-09-22 15:50:00  11145.474770  11143.228118  11144.175227  \n",
       "2020-09-22 15:51:00  11146.081953  11143.784932  11144.730127  \n",
       "2020-09-22 15:52:00  11147.541344  11145.205164  11146.128432  \n",
       "2020-09-22 15:53:00  11149.304806  11146.954728  11147.845755  \n",
       "2020-09-22 15:54:00  11150.672784  11148.336912  11149.200330  \n",
       "\n",
       "[54998 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.0 \n",
    "len_shape_y = df5_7.shape[1]-2\n",
    "fill_list = list(repeat(0, len_shape_y))\n",
    "df8 = pd.DataFrame()\n",
    "\n",
    "# 10.1 逆向\n",
    "for k, v in scalers.items():\n",
    "    mask = ((df7['udate'] >= v['day_start']) & (df7['udate'] <= v['day_end']))\n",
    "    df8_1 = df7.loc[mask]\n",
    "    df8_2 = df8_1.drop(['udate'], axis=1)\n",
    "    # 10.2\n",
    "    data4 = []\n",
    "    for k1, v1 in df8_2.iterrows():\n",
    "        data4_1 = []\n",
    "        for v2 in v1:\n",
    "            data4_1.append([v2] + fill_list)\n",
    "        data4_2 = v['scaler'].inverse_transform(data4_1)\n",
    "        data4_3 = [v[0] for v in data4_2]\n",
    "        data4.append(data4_3)\n",
    "    # 10.3\n",
    "    df8_3 = pd.DataFrame(data4, columns=columns1)\n",
    "    df8_3.index = df8_1['udate']\n",
    "    # 10.4 合併\n",
    "    if df8_3.shape[0] > 0:\n",
    "        df8 = pd.concat([df8, df8_3], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "df8['udate'] = df8.index.values\n",
    "df8 = df8[['udate'] + columns1]\n",
    "# df8[df8.index.duplicated()]\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-0727-0731-e6-u512-w50.csv\n",
      "t5-0831-0904-e6-u512-w50.csv\n",
      "t5-0807-0911-e6-u512-w50.csv\n",
      "t5-0814-0918-e6-u512-w50.csv\n",
      "t5-0921-0925-e6-u512-w50.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:00:00</th>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:01:00</th>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>9865.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:02:00</th>\n",
       "      <td>9860.25</td>\n",
       "      <td>9860.50</td>\n",
       "      <td>9859.25</td>\n",
       "      <td>9859.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:03:00</th>\n",
       "      <td>9859.50</td>\n",
       "      <td>9860.00</td>\n",
       "      <td>9857.50</td>\n",
       "      <td>9857.50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-08 17:04:00</th>\n",
       "      <td>9857.50</td>\n",
       "      <td>9859.25</td>\n",
       "      <td>9857.50</td>\n",
       "      <td>9859.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:49:00</th>\n",
       "      <td>11149.75</td>\n",
       "      <td>11150.50</td>\n",
       "      <td>11149.50</td>\n",
       "      <td>11149.75</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11146.350355</td>\n",
       "      <td>11145.134504</td>\n",
       "      <td>11145.994092</td>\n",
       "      <td>11143.785056</td>\n",
       "      <td>11144.723086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:50:00</th>\n",
       "      <td>11149.75</td>\n",
       "      <td>11151.75</td>\n",
       "      <td>11148.50</td>\n",
       "      <td>11151.75</td>\n",
       "      <td>77.0</td>\n",
       "      <td>11145.732331</td>\n",
       "      <td>11144.619968</td>\n",
       "      <td>11145.474770</td>\n",
       "      <td>11143.228118</td>\n",
       "      <td>11144.175227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:51:00</th>\n",
       "      <td>11151.75</td>\n",
       "      <td>11152.50</td>\n",
       "      <td>11150.75</td>\n",
       "      <td>11151.25</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11146.166603</td>\n",
       "      <td>11145.204145</td>\n",
       "      <td>11146.081953</td>\n",
       "      <td>11143.784932</td>\n",
       "      <td>11144.730127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:52:00</th>\n",
       "      <td>11151.25</td>\n",
       "      <td>11152.00</td>\n",
       "      <td>11150.25</td>\n",
       "      <td>11151.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11147.484767</td>\n",
       "      <td>11146.626816</td>\n",
       "      <td>11147.541344</td>\n",
       "      <td>11145.205164</td>\n",
       "      <td>11146.128432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22 15:53:00</th>\n",
       "      <td>11151.00</td>\n",
       "      <td>11153.00</td>\n",
       "      <td>11151.00</td>\n",
       "      <td>11152.25</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11149.209903</td>\n",
       "      <td>11148.360692</td>\n",
       "      <td>11149.304806</td>\n",
       "      <td>11146.954728</td>\n",
       "      <td>11147.845755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72355 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         High       Low      Open     Close  Volume  \\\n",
       "udate                                                                 \n",
       "2020-06-08 17:00:00   9865.50   9865.50   9865.50   9865.50     0.0   \n",
       "2020-06-08 17:01:00   9865.50   9865.50   9865.50   9865.50     0.0   \n",
       "2020-06-08 17:02:00   9860.25   9860.50   9859.25   9859.50     5.0   \n",
       "2020-06-08 17:03:00   9859.50   9860.00   9857.50   9857.50    12.0   \n",
       "2020-06-08 17:04:00   9857.50   9859.25   9857.50   9859.25     1.0   \n",
       "...                       ...       ...       ...       ...     ...   \n",
       "2020-09-22 15:49:00  11149.75  11150.50  11149.50  11149.75    23.0   \n",
       "2020-09-22 15:50:00  11149.75  11151.75  11148.50  11151.75    77.0   \n",
       "2020-09-22 15:51:00  11151.75  11152.50  11150.75  11151.25    43.0   \n",
       "2020-09-22 15:52:00  11151.25  11152.00  11150.25  11151.00    17.0   \n",
       "2020-09-22 15:53:00  11151.00  11153.00  11151.00  11152.25    13.0   \n",
       "\n",
       "                               t1            t2            t3            t4  \\\n",
       "udate                                                                         \n",
       "2020-06-08 17:00:00           NaN           NaN           NaN           NaN   \n",
       "2020-06-08 17:01:00           NaN           NaN           NaN           NaN   \n",
       "2020-06-08 17:02:00           NaN           NaN           NaN           NaN   \n",
       "2020-06-08 17:03:00           NaN           NaN           NaN           NaN   \n",
       "2020-06-08 17:04:00           NaN           NaN           NaN           NaN   \n",
       "...                           ...           ...           ...           ...   \n",
       "2020-09-22 15:49:00  11146.350355  11145.134504  11145.994092  11143.785056   \n",
       "2020-09-22 15:50:00  11145.732331  11144.619968  11145.474770  11143.228118   \n",
       "2020-09-22 15:51:00  11146.166603  11145.204145  11146.081953  11143.784932   \n",
       "2020-09-22 15:52:00  11147.484767  11146.626816  11147.541344  11145.205164   \n",
       "2020-09-22 15:53:00  11149.209903  11148.360692  11149.304806  11146.954728   \n",
       "\n",
       "                               t5  \n",
       "udate                              \n",
       "2020-06-08 17:00:00           NaN  \n",
       "2020-06-08 17:01:00           NaN  \n",
       "2020-06-08 17:02:00           NaN  \n",
       "2020-06-08 17:03:00           NaN  \n",
       "2020-06-08 17:04:00           NaN  \n",
       "...                           ...  \n",
       "2020-09-22 15:49:00  11144.723086  \n",
       "2020-09-22 15:50:00  11144.175227  \n",
       "2020-09-22 15:51:00  11144.730127  \n",
       "2020-09-22 15:52:00  11146.128432  \n",
       "2020-09-22 15:53:00  11147.845755  \n",
       "\n",
       "[72355 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.1\n",
    "df9 = df3.drop(list(df3.columns)[6:], axis=1)\n",
    "df9_1 = pd.concat([df9, df8], axis=1)\n",
    "\n",
    "# 11.2 \n",
    "start2, end2 =  date_valid2[0], date_valid2[-2:-1][0]\n",
    "start3 = start2 - timedelta(minutes=t_pus_no+window_size)\n",
    "mask3 = ((df9_1.index >= start3) & (df9_1.index <= start2)) # 窗口步長\n",
    "if is_y_label_m_to_n:\n",
    "    k9 = 't1'\n",
    "else:\n",
    "    k9 = 'predict_close'\n",
    "mask4 = ((df9_1.index >= start2) & (df9_1.index <= end2)) # 預測\n",
    "df9_2 = df9_1.loc[(mask3 | mask4)]\n",
    "df9_3 = df9_2.drop(['udate'], axis=1)\n",
    "\n",
    "path_name = ''\n",
    "if is_raw_data:\n",
    "    path_name = '-raw'\n",
    "    \n",
    "if is_y_label_m_to_n:\n",
    "    path_name_2 = 't'+str(t_pus_no)\n",
    "else:\n",
    "    path_name_2 = str(t_pus_no)+'mins'\n",
    "\n",
    "# 11.3.1 save1\n",
    "mask5 = ((df9_3.index >= start3) & (df9_3.index <= start2)) # 窗口步長\n",
    "mask6 = ((df9_3.index >= start2) & (df9_3.index <= end2) & (df9_3[k9] > 0)) # 預測\n",
    "df9_4 = df9_3.loc[(mask5 | mask6)]\n",
    "\n",
    "start9, end9 = pd.to_datetime(df9_4.index.values[0]), pd.to_datetime(df9_4.index.values[-1])\n",
    "path_1_date = str(start9.month).zfill(2)+str(start9.day).zfill(2)+'-'+str(end9.month).zfill(2)+str(end9.day).zfill(2)\n",
    "path_1 = os.path.abspath(os.path.join('data', 'nq', 'prediction', path_name_2+'-'+path_1_date+'-e'+ str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + path_name+ '.csv'))\n",
    "if os.path.exists(path_1):\n",
    "    os.remove(path_1)\n",
    "df9_4.to_csv(path_1)\n",
    "\n",
    "# 11.3.2 save3\n",
    "path_3 = os.path.abspath(os.path.join('data', 'nq', 'prediction', 'nq-prediction.csv'))\n",
    "if os.path.exists(path_3):\n",
    "    os.remove(path_3)\n",
    "df9_4.to_csv(path_3)\n",
    "\n",
    "# 11.4 save2\n",
    "days9 = [[datetime(2020, 7, 6, 17, 0, 0), datetime(2020, 7, 10, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 13, 17, 0, 0), datetime(2020, 7, 17, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 20, 17, 0, 0), datetime(2020, 7, 24, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 27, 17, 0, 0), datetime(2020, 7, 31, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 8, 31, 17, 0, 0), datetime(2020, 9, 4, 16, 0, 0)],\n",
    "         [datetime(2020, 8, 7, 17, 0, 0), datetime(2020, 9, 11, 16, 0, 0)],\n",
    "         [datetime(2020, 8, 14, 17, 0, 0), datetime(2020, 9, 18, 16, 0, 0)],\n",
    "         [datetime(2020, 9, 21, 17, 0, 0), datetime(2020, 9, 25, 16, 0, 0)],\n",
    "         [datetime(2020, 9, 28, 17, 0, 0), datetime(2020, 10, 2, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 10, 5, 17, 0, 0), datetime(2020, 10, 9, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 12, 17, 0, 0), datetime(2020, 10, 16, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 19, 17, 0, 0), datetime(2020, 10, 23, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 26, 17, 0, 0), datetime(2020, 10, 30, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 11, 2, 17, 0, 0), datetime(2020, 11, 6, 16, 0, 0)],\n",
    "         [datetime(2020, 11, 9, 17, 0, 0), datetime(2020, 11, 13, 16, 0, 0)]]\n",
    "for v9 in days9:\n",
    "    df9_5 = df9_3.copy(deep=True)\n",
    "    start4 = v9[0] + timedelta(minutes=t_pus_no+window_size) # 窗口步長\n",
    "    mask7 = ((df9_5.index >= v9[0]) & (df9_5.index <= start4)) # 窗口步長\n",
    "    mask8 = ((df9_5.index >= start4) & (df9_5.index <= v9[1]) & (df9_5[k9] > 0)) # 預測\n",
    "    df9_6 = df9_5.loc[mask7 | mask8]\n",
    "    file_name_1 = path_name_2+'-'+ str(v9[0].month).zfill(2) + str(v9[0].day).zfill(2) +'-'+ str(v9[1].month).zfill(2) + str(v9[1].day).zfill(2) + '-e' + str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + path_name + '.csv'\n",
    "    path_2 = os.path.abspath(os.path.join('data', 'nq', 'prediction', file_name_1))\n",
    "    if os.path.exists(path_2):\n",
    "        os.remove(path_2)\n",
    "    if df9_6.shape[0] > 1:\n",
    "        df9_6.to_csv(path_2)\n",
    "        print(file_name_1)\n",
    "\n",
    "df9_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/user/PycharmProjects/JupyterLab01/min_max_scaler/nq-lstm-20201130-053021.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.1 save mixmax scaler\n",
    "path_name_12 = os.path.abspath(os.path.join('min_max_scaler', prefix+'-'+cur_time+'.pkl'))\n",
    "if os.path.exists(path_name_12):\n",
    "    os.remove(path_name_12)\n",
    "joblib.dump(scalers, path_name_12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>ampe</th>\n",
       "      <th>min</th>\n",
       "      <th>q25%</th>\n",
       "      <th>q50%</th>\n",
       "      <th>q75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <td>54997</td>\n",
       "      <td>10964.061772</td>\n",
       "      <td>551837.541409</td>\n",
       "      <td>-0.153347</td>\n",
       "      <td>-0.989223</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>348.655132</td>\n",
       "      <td>18.672309</td>\n",
       "      <td>12.928292</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>9490.25</td>\n",
       "      <td>10083.25</td>\n",
       "      <td>11110.25</td>\n",
       "      <td>11419.75</td>\n",
       "      <td>12444.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <td>54997</td>\n",
       "      <td>10966.971336</td>\n",
       "      <td>555623.443490</td>\n",
       "      <td>-0.182322</td>\n",
       "      <td>-1.001850</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>348.655132</td>\n",
       "      <td>18.672309</td>\n",
       "      <td>12.928292</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>9500.00</td>\n",
       "      <td>10078.06</td>\n",
       "      <td>11134.24</td>\n",
       "      <td>11420.80</td>\n",
       "      <td>12452.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          nobs          mean       variance  skewness  kurtosis        r2  \\\n",
       "real     54997  10964.061772  551837.541409 -0.153347 -0.989223  0.999368   \n",
       "predict  54997  10966.971336  555623.443490 -0.182322 -1.001850  0.999368   \n",
       "\n",
       "                mse       rmse        mae      ampe      min      q25%  \\\n",
       "real     348.655132  18.672309  12.928292  0.001172  9490.25  10083.25   \n",
       "predict  348.655132  18.672309  12.928292  0.001172  9500.00  10078.06   \n",
       "\n",
       "             q50%      q75%       max  \n",
       "real     11110.25  11419.75  12444.75  \n",
       "predict  11134.24  11420.80  12452.71  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13.1 evaluate\n",
    "if is_y_label_m_to_n:\n",
    "    predict_k12 = 't1'\n",
    "else:\n",
    "    predict_k12 = 'predict_close'\n",
    "\n",
    "df12 = df9_3.copy(deep=True)\n",
    "mask12 = ((df12[predict_k12] > 0) & (df12['Close'] > 0))\n",
    "df12 = df12.loc[mask12].round(2)\n",
    "\n",
    "# \n",
    "stats_1 = stats.describe(df12['Close'].values)\n",
    "stats_2 = stats.describe(df12['t5'].values)\n",
    "# R平方, 均方误差, 均方根误差, 平均绝对误差, 平均絕對百分比誤差\n",
    "r2 = r2_score(df12['Close'].values, df12[predict_k12].values)\n",
    "mse = mean_squared_error(df12['Close'].values, df12[predict_k12].values)\n",
    "rmse = np.sqrt(mean_squared_error(df12['Close'].values, df12[predict_k12].values))\n",
    "mae =  mean_absolute_error(df12['Close'].values, df12[predict_k12].values)\n",
    "ampe = np.mean(np.abs((df12['Close']-df12[predict_k12])/df12['Close']))\n",
    "columns2 = ['r2', 'mse', 'rmse', 'mae', 'ampe']\n",
    "result1 = [r2, mse, rmse, mae, ampe]\n",
    "# 最少值, 四分位數, 最大值\n",
    "columns3 = ['min', 'q25%', 'q50%', 'q75%', 'max']\n",
    "result2 = df12['Close'].quantile([.0, .25, .5, .75, 1]).values.tolist()\n",
    "result3 = df12[predict_k12].quantile([.0, .25, .5, .75, 1]).values.tolist()\n",
    "\n",
    "# 合併\n",
    "df12_1 = pd.DataFrame([list(stats_1)+result1+result2, list(stats_2)+result1+result3], columns=list(stats_1._fields)+columns2+columns3, index=['real', 'predict'])\n",
    "df12_1.drop(['minmax'], axis=1, inplace=True)\n",
    "\n",
    "# 13.4 save\n",
    "path_13 = os.path.abspath(os.path.join('data', 'nq', 'result-describe', path_name_2+'-'+path_1_date+'-e'+ str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + path_name+ '-' + cur_time +'.csv'))\n",
    "df12_1.to_csv(path_13)\n",
    "df12_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
