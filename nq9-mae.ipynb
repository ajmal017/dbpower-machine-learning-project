{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import talib as talib\n",
    "import numpy as np\n",
    "import data as ds\n",
    "import common as common\n",
    "import os as os\n",
    "import math as math\n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "import itertools  as itertools\n",
    "import multiprocessing as mp\n",
    "import joblib\n",
    "from os import listdir, walk\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "from datetime import datetime, timedelta, date\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, pairwise, mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "import sqlite3 as sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# 0.1 环境设定\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# 0.2 日志参数\n",
    "prefix = 'nq-lstm'\n",
    "cur_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# 0.3 不让程序占满 GPU 内存\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "# 0.4\n",
    "is_use_sqlite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 重構數據集\n",
    "def reshape_dataframe(df0, year0):\n",
    "    df0.fillna(0, inplace=True)\n",
    "    df0.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df0.columns = ['udate', 'High', 'Low', 'Open', 'Close', 'Volume']\n",
    "    types2 = {'udate': 'object', 'High': 'float64', 'Low': 'float64', 'Open': 'float64', 'Close': 'float64', 'Volume': 'int64'}\n",
    "    df0.astype(types2).dtypes\n",
    "    df0_1 = df0.copy(deep=True)\n",
    "    error_row = []\n",
    "    for k, v in df0.iterrows():\n",
    "        if not pd.isnull(df0['udate'].iloc[k]) and df0['udate'].iloc[k] > 0:\n",
    "            stime = str(int(df0['udate'].iloc[k]))\n",
    "            df0_1['udate'].iloc[k] = datetime(year=year0, month=int(stime[-8:-6]), day=int(stime[-6:-4]), hour=int(stime[-4:-2]), minute=int(stime[-2:]), second=0)\n",
    "            #df0_1['udate'].iloc[k] = datetime(year=year0, month=int(stime[-10:-8]), day=int(stime[-8:-6]), hour=int(stime[-6:-4]), minute=int(stime[-4:-2]), second=int(stime[-2:]))\n",
    "        else:\n",
    "            error_row.append(k)\n",
    "    df0_1.drop(df0_1.index[error_row], inplace=True)\n",
    "    df0_1.udate = pd.to_datetime(df0_1.udate)\n",
    "    df0_1.index = pd.to_datetime(df0_1.udate)\n",
    "    \n",
    "    # 1.0.1 數據有效性檢查\n",
    "    for k, v in types2.items():\n",
    "        if (df0_1[k].isin([np.nan]).any().any()):\n",
    "            print(k+' obtains nan')\n",
    "        if (df0_1[k].isin([0]).any().any()):\n",
    "            print(k+' obtains 0')\n",
    "    is_contain_null = df0_1.isnull().sum()\n",
    "\n",
    "    return df0_1\n",
    "# 1.2.1 year 2020\n",
    "path_files_1 = []\n",
    "# 1.2.1 year 2019\n",
    "path_files_2 = []\n",
    "# 1.2.1 year 2021\n",
    "path_files_3 = []\n",
    "for j in range(1, 13):\n",
    "    month1 = str(j).zfill(2)\n",
    "    file1 = 'nq-20-'+month1+'.csv'\n",
    "    #path_files_1.append(os.path.abspath(os.path.join('data', 'nq', 'data', file1)))\n",
    "    file2 = 'nq-18-'+month1+'.csv'\n",
    "    path_files_2.append(os.path.abspath(os.path.join('data', 'nq', 'data', file2)))\n",
    "    \n",
    "# 1.3\n",
    "def data_worker1(m_list1_2, path1_2, year_2):\n",
    "    try:\n",
    "        df1_2 = reshape_dataframe(pd.read_csv(path1_2), year_2)\n",
    "        m_list1_2.append(df1_2)\n",
    "    except:\n",
    "        print('No file', path1_2)\n",
    "\n",
    "# 1.4\n",
    "if not is_use_sqlite:\n",
    "    manager1 = mp.Manager()\n",
    "    m_list1 = manager1.list()\n",
    "    pool1 = mp.Pool(processes=8, maxtasksperchild=8)\n",
    "    for path1 in path_files_1:\n",
    "        pool1.apply_async(func=data_worker1, args=(m_list1, path1, 2020,))\n",
    "    for path2 in path_files_2:\n",
    "        pool1.apply_async(func=data_worker1, args=(m_list1, path2, 2018,))\n",
    "    for path3 in path_files_3:\n",
    "        pool1.apply_async(func=data_worker1, args=(m_list1, path3, 2021,)) \n",
    "    pool1.close()\n",
    "    pool1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_use_sqlite:\n",
    "    # 1.5\n",
    "    df2 = pd.concat(m_list1, ignore_index=False)\n",
    "\n",
    "    # 1.6 刪除重覆index\n",
    "    df2 = df2.groupby(df2.index).first()\n",
    "\n",
    "    # 1.7 排序\n",
    "    df2.sort_index(axis=0, ascending=True, inplace=True)\n",
    "    # df2 = df2.loc[(df2.udate >= datetime(2019, 3, 1, 16, 0, 0))]\n",
    "    df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_use_sqlite:\n",
    "    # 1.8 get data\n",
    "    path_db1 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-1m.db'))\n",
    "    path_db2 = os.path.abspath(os.path.join('data', 'nq', 'data-15s', 'nq-15s.db'))\n",
    "    db = sqlite3.connect(path_db1)\n",
    "    cursor = db.cursor()\n",
    "    stmt1 = \"select * from nq where strftime('%S', udate) == '00' order by udate\"\n",
    "    stmt2 = \"select * from nq where (strftime('%S', udate) == '00' or strftime('%S', udate) == '15' or strftime('%S', udate) == '30' or strftime('%S', udate) == '45') and udate>='2019-10-17' order by udate limit 1300000\"\n",
    "    df2 = pd.read_sql_query(stmt1, db)\n",
    "    db.commit()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "\n",
    "    df2.rename(columns={'high': 'High', 'low': 'Low', 'open': 'Open', 'close': 'Close', 'vol': 'Volume'}, inplace=True)\n",
    "    types3 = {'udate': 'object', 'High': 'float64', 'Low': 'float64', 'Open': 'float64', 'Close': 'float64', 'Volume': 'int64'}\n",
    "    df2.astype(types3).dtypes\n",
    "    df2.udate = pd.to_datetime(df2.udate)\n",
    "    df2.index = pd.to_datetime(df2.udate)\n",
    "    df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:01:00</th>\n",
       "      <td>2018-01-01 17:01:00</td>\n",
       "      <td>6407.75</td>\n",
       "      <td>6410.25</td>\n",
       "      <td>6407.50</td>\n",
       "      <td>6410.00</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:02:00</th>\n",
       "      <td>2018-01-01 17:02:00</td>\n",
       "      <td>6410.00</td>\n",
       "      <td>6412.00</td>\n",
       "      <td>6409.50</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:03:00</th>\n",
       "      <td>2018-01-01 17:03:00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>6412.00</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:04:00</th>\n",
       "      <td>2018-01-01 17:04:00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:05:00</th>\n",
       "      <td>2018-01-01 17:05:00</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>6413.00</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6412.75</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:39:00</th>\n",
       "      <td>2021-01-04 23:39:00</td>\n",
       "      <td>12683.75</td>\n",
       "      <td>12684.25</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:40:00</th>\n",
       "      <td>2021-01-04 23:40:00</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:41:00</th>\n",
       "      <td>2021-01-04 23:41:00</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>12686.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:42:00</th>\n",
       "      <td>2021-01-04 23:42:00</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12677.00</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:43:00</th>\n",
       "      <td>2021-01-04 23:43:00</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12678.00</td>\n",
       "      <td>12680.50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920128 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2018-01-01 17:01:00 2018-01-01 17:01:00   6407.75   6410.25   6407.50   \n",
       "2018-01-01 17:02:00 2018-01-01 17:02:00   6410.00   6412.00   6409.50   \n",
       "2018-01-01 17:03:00 2018-01-01 17:03:00   6411.25   6412.00   6411.00   \n",
       "2018-01-01 17:04:00 2018-01-01 17:04:00   6411.25   6411.50   6411.00   \n",
       "2018-01-01 17:05:00 2018-01-01 17:05:00   6411.50   6413.00   6411.00   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2021-01-04 23:39:00 2021-01-04 23:39:00  12683.75  12684.25  12680.75   \n",
       "2021-01-04 23:40:00 2021-01-04 23:40:00  12680.75  12681.25  12678.50   \n",
       "2021-01-04 23:41:00 2021-01-04 23:41:00  12681.25  12686.75  12680.75   \n",
       "2021-01-04 23:42:00 2021-01-04 23:42:00  12680.75  12680.75  12677.00   \n",
       "2021-01-04 23:43:00 2021-01-04 23:43:00  12678.50  12680.75  12678.00   \n",
       "\n",
       "                        Close  Volume  \n",
       "udate                                  \n",
       "2018-01-01 17:01:00   6410.00     375  \n",
       "2018-01-01 17:02:00   6411.25     514  \n",
       "2018-01-01 17:03:00   6411.25     203  \n",
       "2018-01-01 17:04:00   6411.50      88  \n",
       "2018-01-01 17:05:00   6412.75     153  \n",
       "...                       ...     ...  \n",
       "2021-01-04 23:39:00  12680.75      39  \n",
       "2021-01-04 23:40:00  12681.25      80  \n",
       "2021-01-04 23:41:00  12680.75      87  \n",
       "2021-01-04 23:42:00  12678.50      95  \n",
       "2021-01-04 23:43:00  12680.50      25  \n",
       "\n",
       "[920128 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.0 分包 (日子)\n",
    "def separate_daily(df2_1, return_type):\n",
    "    data1 = {}\n",
    "    # 2.1交易日\n",
    "    days1 = list(dict.fromkeys([v.date() for v in df2_1['udate']]))\n",
    "    for day in days1:\n",
    "        # 2.2 交易時間\n",
    "        day_start = datetime(day.year, day.month, day.day, 17, 0, 0)\n",
    "        day2 = day + timedelta(days=1)\n",
    "        day_end = datetime(day2.year, day2.month, day2.day, 16, 0, 0)\n",
    "        mask = ((df2_1['udate'] >= day_start) & (df2_1['udate'] <= day_end))\n",
    "        df2_2 = df2_1.loc[mask]\n",
    "        if (df2_2.shape[0] > 1):\n",
    "            data1[day] = df2_2\n",
    "    # 2.3 合併\n",
    "    df2_3 = pd.DataFrame()\n",
    "    for k, df2_4 in data1.items():\n",
    "        df2_3 = pd.concat([df2_3, df2_4], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "    # 2.4 返回類型\n",
    "    if return_type=='df':\n",
    "        return df2_3\n",
    "    elif return_type=='dict':\n",
    "        return data1\n",
    "\n",
    "df2_5 = df2.copy(deep=True)\n",
    "df3 = separate_daily(df2_5, 'df')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>upper-band</th>\n",
       "      <th>middle-band</th>\n",
       "      <th>lower-band</th>\n",
       "      <th>%b</th>\n",
       "      <th>...</th>\n",
       "      <th>k-kdj</th>\n",
       "      <th>d-kdj</th>\n",
       "      <th>j-kdj</th>\n",
       "      <th>diff-kdj</th>\n",
       "      <th>ema-10</th>\n",
       "      <th>ema-20</th>\n",
       "      <th>ema-50</th>\n",
       "      <th>ema-100</th>\n",
       "      <th>vol-ema5</th>\n",
       "      <th>p-sar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:01:00</th>\n",
       "      <td>2018-01-01 17:01:00</td>\n",
       "      <td>6407.75</td>\n",
       "      <td>6410.25</td>\n",
       "      <td>6407.50</td>\n",
       "      <td>6410.00</td>\n",
       "      <td>375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:02:00</th>\n",
       "      <td>2018-01-01 17:02:00</td>\n",
       "      <td>6410.00</td>\n",
       "      <td>6412.00</td>\n",
       "      <td>6409.50</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:03:00</th>\n",
       "      <td>2018-01-01 17:03:00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>6412.00</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:04:00</th>\n",
       "      <td>2018-01-01 17:04:00</td>\n",
       "      <td>6411.25</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 17:05:00</th>\n",
       "      <td>2018-01-01 17:05:00</td>\n",
       "      <td>6411.50</td>\n",
       "      <td>6413.00</td>\n",
       "      <td>6411.00</td>\n",
       "      <td>6412.75</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.600000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:39:00</th>\n",
       "      <td>2021-01-04 23:39:00</td>\n",
       "      <td>12683.75</td>\n",
       "      <td>12684.25</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>39</td>\n",
       "      <td>12692.557122</td>\n",
       "      <td>12682.9000</td>\n",
       "      <td>12673.242878</td>\n",
       "      <td>38.868319</td>\n",
       "      <td>...</td>\n",
       "      <td>16.963276</td>\n",
       "      <td>47.831994</td>\n",
       "      <td>-44.774159</td>\n",
       "      <td>-30.868718</td>\n",
       "      <td>12681.319229</td>\n",
       "      <td>12682.214052</td>\n",
       "      <td>12683.298771</td>\n",
       "      <td>12686.191690</td>\n",
       "      <td>72.058458</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:40:00</th>\n",
       "      <td>2021-01-04 23:40:00</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>80</td>\n",
       "      <td>12691.459522</td>\n",
       "      <td>12682.4375</td>\n",
       "      <td>12673.415478</td>\n",
       "      <td>43.418881</td>\n",
       "      <td>...</td>\n",
       "      <td>14.213950</td>\n",
       "      <td>43.154197</td>\n",
       "      <td>-43.666544</td>\n",
       "      <td>-28.940247</td>\n",
       "      <td>12681.306642</td>\n",
       "      <td>12682.122238</td>\n",
       "      <td>12683.218427</td>\n",
       "      <td>12686.093835</td>\n",
       "      <td>74.705639</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:41:00</th>\n",
       "      <td>2021-01-04 23:41:00</td>\n",
       "      <td>12681.25</td>\n",
       "      <td>12686.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>87</td>\n",
       "      <td>12690.495535</td>\n",
       "      <td>12682.0125</td>\n",
       "      <td>12673.529465</td>\n",
       "      <td>42.558677</td>\n",
       "      <td>...</td>\n",
       "      <td>12.355909</td>\n",
       "      <td>38.520150</td>\n",
       "      <td>-39.972574</td>\n",
       "      <td>-26.164241</td>\n",
       "      <td>12681.205435</td>\n",
       "      <td>12681.991548</td>\n",
       "      <td>12683.121626</td>\n",
       "      <td>12685.988016</td>\n",
       "      <td>78.803759</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:42:00</th>\n",
       "      <td>2021-01-04 23:42:00</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12677.00</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>95</td>\n",
       "      <td>12689.734742</td>\n",
       "      <td>12681.5500</td>\n",
       "      <td>12673.365258</td>\n",
       "      <td>31.367769</td>\n",
       "      <td>...</td>\n",
       "      <td>9.175316</td>\n",
       "      <td>33.802317</td>\n",
       "      <td>-40.078687</td>\n",
       "      <td>-24.627002</td>\n",
       "      <td>12680.713537</td>\n",
       "      <td>12681.659020</td>\n",
       "      <td>12682.940386</td>\n",
       "      <td>12685.839739</td>\n",
       "      <td>84.202506</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04 23:43:00</th>\n",
       "      <td>2021-01-04 23:43:00</td>\n",
       "      <td>12678.50</td>\n",
       "      <td>12680.75</td>\n",
       "      <td>12678.00</td>\n",
       "      <td>12680.50</td>\n",
       "      <td>25</td>\n",
       "      <td>12688.868442</td>\n",
       "      <td>12681.1875</td>\n",
       "      <td>12673.506558</td>\n",
       "      <td>45.524638</td>\n",
       "      <td>...</td>\n",
       "      <td>12.143869</td>\n",
       "      <td>29.780166</td>\n",
       "      <td>-23.128724</td>\n",
       "      <td>-17.636297</td>\n",
       "      <td>12680.674712</td>\n",
       "      <td>12681.548637</td>\n",
       "      <td>12682.844684</td>\n",
       "      <td>12685.734001</td>\n",
       "      <td>64.468337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920128 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2018-01-01 17:01:00 2018-01-01 17:01:00   6407.75   6410.25   6407.50   \n",
       "2018-01-01 17:02:00 2018-01-01 17:02:00   6410.00   6412.00   6409.50   \n",
       "2018-01-01 17:03:00 2018-01-01 17:03:00   6411.25   6412.00   6411.00   \n",
       "2018-01-01 17:04:00 2018-01-01 17:04:00   6411.25   6411.50   6411.00   \n",
       "2018-01-01 17:05:00 2018-01-01 17:05:00   6411.50   6413.00   6411.00   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2021-01-04 23:39:00 2021-01-04 23:39:00  12683.75  12684.25  12680.75   \n",
       "2021-01-04 23:40:00 2021-01-04 23:40:00  12680.75  12681.25  12678.50   \n",
       "2021-01-04 23:41:00 2021-01-04 23:41:00  12681.25  12686.75  12680.75   \n",
       "2021-01-04 23:42:00 2021-01-04 23:42:00  12680.75  12680.75  12677.00   \n",
       "2021-01-04 23:43:00 2021-01-04 23:43:00  12678.50  12680.75  12678.00   \n",
       "\n",
       "                        Close  Volume    upper-band  middle-band  \\\n",
       "udate                                                              \n",
       "2018-01-01 17:01:00   6410.00     375           NaN          NaN   \n",
       "2018-01-01 17:02:00   6411.25     514           NaN          NaN   \n",
       "2018-01-01 17:03:00   6411.25     203           NaN          NaN   \n",
       "2018-01-01 17:04:00   6411.50      88           NaN          NaN   \n",
       "2018-01-01 17:05:00   6412.75     153           NaN          NaN   \n",
       "...                       ...     ...           ...          ...   \n",
       "2021-01-04 23:39:00  12680.75      39  12692.557122   12682.9000   \n",
       "2021-01-04 23:40:00  12681.25      80  12691.459522   12682.4375   \n",
       "2021-01-04 23:41:00  12680.75      87  12690.495535   12682.0125   \n",
       "2021-01-04 23:42:00  12678.50      95  12689.734742   12681.5500   \n",
       "2021-01-04 23:43:00  12680.50      25  12688.868442   12681.1875   \n",
       "\n",
       "                       lower-band         %b  ...      k-kdj      d-kdj  \\\n",
       "udate                                         ...                         \n",
       "2018-01-01 17:01:00           NaN        NaN  ...        NaN        NaN   \n",
       "2018-01-01 17:02:00           NaN        NaN  ...        NaN        NaN   \n",
       "2018-01-01 17:03:00           NaN        NaN  ...        NaN        NaN   \n",
       "2018-01-01 17:04:00           NaN        NaN  ...        NaN        NaN   \n",
       "2018-01-01 17:05:00           NaN        NaN  ...        NaN        NaN   \n",
       "...                           ...        ...  ...        ...        ...   \n",
       "2021-01-04 23:39:00  12673.242878  38.868319  ...  16.963276  47.831994   \n",
       "2021-01-04 23:40:00  12673.415478  43.418881  ...  14.213950  43.154197   \n",
       "2021-01-04 23:41:00  12673.529465  42.558677  ...  12.355909  38.520150   \n",
       "2021-01-04 23:42:00  12673.365258  31.367769  ...   9.175316  33.802317   \n",
       "2021-01-04 23:43:00  12673.506558  45.524638  ...  12.143869  29.780166   \n",
       "\n",
       "                         j-kdj   diff-kdj        ema-10        ema-20  \\\n",
       "udate                                                                   \n",
       "2018-01-01 17:01:00        NaN        NaN           NaN           NaN   \n",
       "2018-01-01 17:02:00        NaN        NaN           NaN           NaN   \n",
       "2018-01-01 17:03:00        NaN        NaN           NaN           NaN   \n",
       "2018-01-01 17:04:00        NaN        NaN           NaN           NaN   \n",
       "2018-01-01 17:05:00        NaN        NaN           NaN           NaN   \n",
       "...                        ...        ...           ...           ...   \n",
       "2021-01-04 23:39:00 -44.774159 -30.868718  12681.319229  12682.214052   \n",
       "2021-01-04 23:40:00 -43.666544 -28.940247  12681.306642  12682.122238   \n",
       "2021-01-04 23:41:00 -39.972574 -26.164241  12681.205435  12681.991548   \n",
       "2021-01-04 23:42:00 -40.078687 -24.627002  12680.713537  12681.659020   \n",
       "2021-01-04 23:43:00 -23.128724 -17.636297  12680.674712  12681.548637   \n",
       "\n",
       "                           ema-50       ema-100    vol-ema5  p-sar  \n",
       "udate                                                               \n",
       "2018-01-01 17:01:00           NaN           NaN         NaN    NaN  \n",
       "2018-01-01 17:02:00           NaN           NaN         NaN    1.0  \n",
       "2018-01-01 17:03:00           NaN           NaN         NaN    1.0  \n",
       "2018-01-01 17:04:00           NaN           NaN         NaN    1.0  \n",
       "2018-01-01 17:05:00           NaN           NaN  266.600000    1.0  \n",
       "...                           ...           ...         ...    ...  \n",
       "2021-01-04 23:39:00  12683.298771  12686.191690   72.058458    1.0  \n",
       "2021-01-04 23:40:00  12683.218427  12686.093835   74.705639    1.0  \n",
       "2021-01-04 23:41:00  12683.121626  12685.988016   78.803759    1.0  \n",
       "2021-01-04 23:42:00  12682.940386  12685.839739   84.202506    1.0  \n",
       "2021-01-04 23:43:00  12682.844684  12685.734001   64.468337    1.0  \n",
       "\n",
       "[920128 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.0 技術指標\n",
    "highs = np.array(df3['High'], dtype='float')\n",
    "lows = np.array(df3['Low'], dtype='float')\n",
    "opens = np.array(df3['Open'], dtype='float')\n",
    "closes = np.array(df3['Close'], dtype='float')\n",
    "vols = np.array(df3['Volume'], dtype='float')\n",
    "# 3.1 Bollinger 保力加\n",
    "df3['upper-band'], df3['middle-band'], df3['lower-band'] = talib.BBANDS(closes, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "# 3.2 %B %保力加\n",
    "df3['%b'] = (df3['Close']-df3['lower-band'])/(df3['upper-band']-df3['lower-band'])*100\n",
    "df3['%b-high']  = common.percentB_belowzero(df3['%b'], df3['Close']) \n",
    "df3['%b-low'] = common.percentB_aboveone(df3['%b'], df3['Close'])\n",
    "# 2.3 MACD\n",
    "weight = 1\n",
    "df3['macd'], df3['macdsignal'], df3['macdhist'] = talib.MACD(closes, fastperiod=12*weight, slowperiod=26*weight, signalperiod=9*weight)\n",
    "# 2.4 RSI\n",
    "df3['rsi-2'] = talib.RSI(closes, timeperiod=14*weight)\n",
    "df3['rsi'] = df3['rsi-2']\n",
    "df3['rsi'].loc[((df3['rsi'] < 85) & (df3['rsi'] > 25))] = 0\n",
    "# 2.5 KDJ\n",
    "df3['k-kdj'], df3['d-kdj'], df3['j-kdj'] = common.kdj(highs, lows, closes, window_size=5)\n",
    "df3['diff-kdj'] = df3['k-kdj']-df3['d-kdj']\n",
    "df3['j-kdj'].loc[((df3['j-kdj'] > 20) & (df3['j-kdj'] < 100))] = 0\n",
    "# 3.6 VWAP 成交量加權平均價格\n",
    "period = []\n",
    "for v in period:\n",
    "    df3['typical-price'] = (df3['High'] + df3['Low'] + df3['Close']) / 3\n",
    "    df3['turnover'] = df3['typical-price'] * df3['Volume']\n",
    "    df3['cum-turnover-'+str(v)] = df3['turnover'].rolling(window=v).sum()\n",
    "    df3['cum-volume-'+str(v)] = df3['Volume'].rolling(window=v).sum()\n",
    "    df3['vwap-'+str(v)] = df3['cum-turnover-'+str(v)] / df3['cum-volume-'+str(v)]\n",
    "    df3['vwap-'+str(v)] = df3['vwap-'+str(v)].replace([np.inf, -np.inf], 0)\n",
    "    df3['vwap-'+str(v)].fillna(0, inplace=True)\n",
    "    drop_list_1 = ['turnover', 'typical-price', 'cum-turnover-'+str(v), 'cum-volume-'+str(v)]\n",
    "    df3.drop(drop_list_1, axis=1, inplace=True)\n",
    "# 3.7 SMA 均線\n",
    "for v in [10,20,50,100]:\n",
    "    df3['ema-'+str(v)]= talib.EMA(closes, timeperiod=v)\n",
    "# 3.8 VOL EMA\n",
    "df3['vol-ema5'] = talib.EMA(vols, timeperiod=5)\n",
    "# 3.9 HMA\n",
    "\"\"\"\n",
    "df3['hma-16']= common.HMA(closes, period=16)\n",
    "df3['hma-64']= common.HMA(closes, period=64)\n",
    "df3['hma-100']= common.HMA(closes, period=100)\n",
    "df3['hma-256']= common.HMA(closes, period=256)\n",
    "\"\"\"\n",
    "# 3.10 P-SAR 抛物线\n",
    "df3['p-sar'] = talib.SAR(highs, lows, acceleration=0.02, maximum=0.2)\n",
    "df3['p-sar'].loc[(df3['p-sar'] < df3['Close'])] = 1\n",
    "df3['p-sar'].loc[(df3['p-sar'] > df3['Close'])] = -1\n",
    "df3['p-sar'].loc[(df3['p-sar'] > 1)] = 0\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0 draw chart\n",
    "drop_list_2 = []\n",
    "is_render_chart = False\n",
    "\n",
    "def draw_worker(df4_2, day):\n",
    "    try:\n",
    "        # 4.1 style\n",
    "        style = mpf.make_mpf_style(base_mpf_style='charles', rc={'font.size':6})\n",
    "        # 4.2 addplot\n",
    "        apds = [mpf.make_addplot(df4_2['lower-band'],panel=0,color='orange',linestyle='solid'),\n",
    "                mpf.make_addplot(df4_2['upper-band'],panel=0,color='bisque',linestyle='solid'),\n",
    "                # mpf.make_addplot(df4_2['vwap-50'].replace(0, np.nan),panel=0,color='aqua',linestyle='solid'),\n",
    "                mpf.make_addplot(df4_2['%b-low'],type='scatter',markersize=20,marker='v',panel=0),\n",
    "                mpf.make_addplot(df4_2['%b-high'],type='scatter',markersize=20,marker='^',panel=0),\n",
    "                # mpf.make_addplot(df4_2['p-sar'],scatter=True,markersize=1,marker='*',panel=0,color='blueviolet'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['vol-ema5'],panel=1,color='orange'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['macd'],panel=2,color='orange'),\n",
    "                mpf.make_addplot(df4_2['macdsignal'],panel=2,color='violet'),\n",
    "                mpf.make_addplot(df4_2['macdhist'],panel=2,type='bar',color='dimgray'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['k-kdj'],panel=3,color='orange'),\n",
    "                mpf.make_addplot(df4_2['d-kdj'],panel=3,color='violet'),\n",
    "                mpf.make_addplot(df4_2['j-kdj'],panel=3,color='aqua'),\n",
    "                mpf.make_addplot(df4_2['diff-kdj'],panel=3,type='bar',color='dimgray'),\n",
    "                #\n",
    "                mpf.make_addplot(df4_2['rsi-2'],panel=4,color='orange'),\n",
    "                mpf.make_addplot(df4_2['rsi'],panel=4,color='violet')]\n",
    "        # 4.3 draw\n",
    "        mpf.plot(df4_2, type='candle', addplot=apds, style=style, ylabel='', ylabel_lower='', volume=True, figscale=0.85, xrotation=0, datetime_format=\"%H:%M\", \n",
    "                 show_nontrading=False, tight_layout=True, savefig='./data/img-nq/features/'+day.strftime('%Y-%m-%d'))\n",
    "        print('finish draw:', df4_2.shape, df4_2['udate'].iloc[0], df4_2['udate'].iloc[-1])\n",
    "    except:\n",
    "        print('do not draw:', k, '\\n')\n",
    "\n",
    "# 4.5 multi processing\n",
    "pool = mp.Pool(processes=8, maxtasksperchild=8)\n",
    "# 4.6 draw\n",
    "df4 = df3.copy(deep=True)\n",
    "data2 = separate_daily(df4, 'dict')\n",
    "for k, df4_1 in data2.items():\n",
    "    # 4.7 drop error day\n",
    "    if df4_1['Volume'].shape[0] == df4_1['Volume'].isin([0]).sum() or df4_1['Volume'].shape[0] <= 100:\n",
    "        drop_list_2.append(k)\n",
    "    # 4.8 draw chart\n",
    "    elif (is_render_chart):\n",
    "        pool.apply_async(draw_worker, args=(df4_1, k))\n",
    "    if k.weekday() == 6:\n",
    "        drop_list_2.append(k)\n",
    "# 4.9 kill multi processing\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "drop_list_2.append(date(2018, 1, 14))\n",
    "drop_list_2.append(date(2018, 2, 18))\n",
    "drop_list_2.append(date(2018, 3, 11))\n",
    "drop_list_2.append(date(2018, 5, 27))\n",
    "drop_list_2.append(date(2018, 6, 24))\n",
    "drop_list_2.append(date(2018, 7, 3))\n",
    "drop_list_2.append(date(2018, 9, 2))\n",
    "drop_list_2.append(date(2018, 11, 21))\n",
    "drop_list_2.append(date(2018, 12, 4))\n",
    "drop_list_2.append(date(2019, 1, 20))\n",
    "drop_list_2.append(date(2019, 5, 26))\n",
    "drop_list_2.append(date(2019, 7, 3))\n",
    "drop_list_2.append(date(2019, 7, 28))\n",
    "drop_list_2.append(date(2019, 8, 4))\n",
    "drop_list_2.append(date(2019, 8, 25))\n",
    "drop_list_2.append(date(2019, 11, 27))\n",
    "drop_list_2.append(date(2020, 3, 8))\n",
    "drop_list_2.append(date(2020, 3, 15))\n",
    "drop_list_2.append(date(2020, 3, 17))\n",
    "drop_list_2.append(date(2020, 5, 24))\n",
    "drop_list_2.append(date(2020, 9, 6))\n",
    "drop_list_2.append(date(2020, 11, 25))\n",
    "\n",
    "for k in drop_list_2:\n",
    "    data2.pop(k, None)\n",
    "    # print('excpet & delete: ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sqlite\n",
    "df4_3 = df4.copy(deep=True)\n",
    "df4_3['udate'] = df4_3['udate'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df4_3.drop(df4_3.columns.difference(['udate', 'High', 'Low', 'Open', 'Close', 'Volume']), 1, inplace=True)\n",
    "data4_1 = [tuple(x) for x in df4_3.values]\n",
    "\n",
    "# 储存\n",
    "path_db = os.path.abspath(os.path.join('data', 'nq', 'data-15s', 'nq-15s.db'))\n",
    "path_db = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-1m.db'))\n",
    "db = sqlite3.connect(path_db)\n",
    "cursor = db.cursor()\n",
    "#cursor.executemany('REPLACE INTO nq (udate, high, low, open, close, vol) VALUES (?, ?, ?, ?, ?, ?)', data4_1)\n",
    "db.commit()\n",
    "cursor.close()\n",
    "db.close()\n",
    "\n",
    "len(data4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集: Total dataset has 722392 samples, and 14 features.\n",
      "525 ~ 535  开始：2020-12-14 17:00:00   终结：2020-12-31 15:59:00\n",
      "515 ~ 525  开始：2020-11-24 17:00:00   终结：2020-12-11 15:59:00\n",
      "505 ~ 515  开始：2020-11-05 17:00:00   终结：2020-11-24 16:00:00\n",
      "495 ~ 505  开始：2020-10-20 17:00:00   终结：2020-11-05 16:00:00\n",
      "485 ~ 495  开始：2020-10-01 17:00:00   终结：2020-10-20 16:00:00\n",
      "475 ~ 485  开始：2020-09-14 17:00:00   终结：2020-10-01 16:00:00\n",
      "465 ~ 475  开始：2020-08-26 17:00:00   终结：2020-09-11 15:59:00\n",
      "455 ~ 465  开始：2020-08-10 17:00:00   终结：2020-08-26 16:00:00\n",
      "445 ~ 455  开始：2020-07-22 17:00:00   终结：2020-08-07 15:59:00\n",
      "435 ~ 445  开始：2020-07-06 17:00:00   终结：2020-07-22 16:00:00\n",
      "425 ~ 435  开始：2020-06-17 17:00:00   终结：2020-07-03 11:59:00\n",
      "415 ~ 425  开始：2020-06-01 17:00:00   终结：2020-06-17 16:00:00\n",
      "405 ~ 415  开始：2020-05-13 17:00:00   终结：2020-05-29 15:59:00\n",
      "395 ~ 405  开始：2020-04-27 17:00:00   终结：2020-05-13 16:00:00\n",
      "385 ~ 395  开始：2020-04-07 17:00:00   终结：2020-04-24 15:59:00\n",
      "375 ~ 385  开始：2020-03-19 17:00:00   终结：2020-04-07 16:00:00\n",
      "365 ~ 375  开始：2020-03-02 17:00:00   终结：2020-03-19 16:00:00\n",
      "355 ~ 365  开始：2019-12-10 17:00:00   终结：2020-02-28 15:59:00\n",
      "345 ~ 355  开始：2019-11-19 17:00:00   终结：2019-12-10 16:00:00\n",
      "335 ~ 345  开始：2019-10-31 17:01:00   终结：2019-11-19 16:00:00\n",
      "325 ~ 335  开始：2019-10-07 17:00:00   终结：2019-10-31 16:00:00\n",
      "315 ~ 325  开始：2019-09-16 17:00:00   终结：2019-10-03 10:51:00\n",
      "305 ~ 315  开始：2019-08-05 17:00:00   终结：2019-09-12 12:08:00\n",
      "295 ~ 305  开始：2019-07-17 17:00:00   终结：2019-08-01 19:54:00\n",
      "285 ~ 295  开始：2019-06-27 17:00:00   终结：2019-07-17 16:00:00\n",
      "275 ~ 285  开始：2019-06-11 17:00:00   终结：2019-06-27 16:00:00\n",
      "265 ~ 275  开始：2019-05-23 17:00:00   终结：2019-06-11 16:00:00\n",
      "255 ~ 265  开始：2019-05-07 17:00:00   终结：2019-05-23 16:00:00\n",
      "245 ~ 255  开始：2019-04-17 17:00:00   终结：2019-05-07 16:00:00\n",
      "235 ~ 245  开始：2019-04-01 17:00:00   终结：2019-04-17 16:00:00\n",
      "225 ~ 235  开始：2019-03-13 17:00:00   终结：2019-03-29 15:59:00\n",
      "215 ~ 225  开始：2019-02-25 17:00:00   终结：2019-03-13 16:00:00\n",
      "205 ~ 215  开始：2019-02-06 17:00:00   终结：2019-02-22 15:59:00\n",
      "195 ~ 205  开始：2019-01-21 17:00:00   终结：2019-02-06 16:00:00\n",
      "185 ~ 195  开始：2018-12-26 17:00:00   终结：2019-01-18 15:59:00\n",
      "175 ~ 185  开始：2018-12-06 17:00:00   终结：2018-12-26 16:00:00\n",
      "165 ~ 175  开始：2018-11-15 17:00:00   终结：2018-12-06 16:00:00\n",
      "155 ~ 165  开始：2018-10-30 17:00:00   终结：2018-11-15 16:00:00\n",
      "145 ~ 155  开始：2018-10-11 17:00:00   终结：2018-10-30 16:00:00\n",
      "135 ~ 145  开始：2018-09-25 17:00:00   终结：2018-10-11 16:00:00\n",
      "125 ~ 135  开始：2018-09-06 17:00:00   终结：2018-09-25 16:00:00\n",
      "115 ~ 125  开始：2018-08-21 17:00:00   终结：2018-09-06 16:00:00\n",
      "105 ~ 115  开始：2018-08-02 17:00:00   终结：2018-08-21 16:00:00\n",
      "95 ~ 105  开始：2018-07-02 17:00:00   终结：2018-08-02 16:00:00\n",
      "85 ~ 95  开始：2018-05-30 17:00:00   终结：2018-06-29 15:59:00\n",
      "75 ~ 85  开始：2018-05-14 17:00:00   终结：2018-05-30 16:00:00\n",
      "65 ~ 75  开始：2018-04-25 17:00:00   终结：2018-05-11 15:59:00\n",
      "55 ~ 65  开始：2018-04-09 17:00:00   终结：2018-04-25 16:00:00\n",
      "45 ~ 55  开始：2018-03-20 17:00:00   终结：2018-04-06 15:59:00\n",
      "35 ~ 45  开始：2018-03-01 17:00:00   终结：2018-03-20 16:00:00\n",
      "25 ~ 35  开始：2018-02-13 17:00:00   终结：2018-03-01 16:00:00\n",
      "15 ~ 25  开始：2018-01-25 17:00:00   终结：2018-02-13 16:00:00\n",
      "5 ~ 15  开始：2018-01-09 17:00:00   终结：2018-01-25 16:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>%b</th>\n",
       "      <th>%b-high</th>\n",
       "      <th>%b-low</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>rsi</th>\n",
       "      <th>j-kdj</th>\n",
       "      <th>diff-kdj</th>\n",
       "      <th>ema-10</th>\n",
       "      <th>ema-20</th>\n",
       "      <th>ema-50</th>\n",
       "      <th>ema-100</th>\n",
       "      <th>p-sar</th>\n",
       "      <th>udate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-09 17:00:00</th>\n",
       "      <td>0.127102</td>\n",
       "      <td>0.190103</td>\n",
       "      <td>0.955645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374696</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.117010</td>\n",
       "      <td>0.109494</td>\n",
       "      <td>0.106650</td>\n",
       "      <td>0.114544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-09 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 17:01:00</th>\n",
       "      <td>0.129119</td>\n",
       "      <td>0.331801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.955683</td>\n",
       "      <td>0.598561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363321</td>\n",
       "      <td>0.511189</td>\n",
       "      <td>0.116650</td>\n",
       "      <td>0.109127</td>\n",
       "      <td>0.106159</td>\n",
       "      <td>0.114075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-09 17:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 17:02:00</th>\n",
       "      <td>0.129792</td>\n",
       "      <td>0.388274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.506246</td>\n",
       "      <td>0.116511</td>\n",
       "      <td>0.108873</td>\n",
       "      <td>0.105755</td>\n",
       "      <td>0.113635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-09 17:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 17:03:00</th>\n",
       "      <td>0.128447</td>\n",
       "      <td>0.313508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343266</td>\n",
       "      <td>0.487283</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>0.108507</td>\n",
       "      <td>0.105292</td>\n",
       "      <td>0.113195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-09 17:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 17:04:00</th>\n",
       "      <td>0.129792</td>\n",
       "      <td>0.416041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342979</td>\n",
       "      <td>0.485665</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>0.108309</td>\n",
       "      <td>0.104887</td>\n",
       "      <td>0.112785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-09 17:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 15:55:00</th>\n",
       "      <td>0.933197</td>\n",
       "      <td>0.679341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684656</td>\n",
       "      <td>0.797816</td>\n",
       "      <td>0.947102</td>\n",
       "      <td>0.950307</td>\n",
       "      <td>0.950986</td>\n",
       "      <td>0.935688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 15:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 15:56:00</th>\n",
       "      <td>0.934727</td>\n",
       "      <td>0.704558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.839755</td>\n",
       "      <td>0.947698</td>\n",
       "      <td>0.950847</td>\n",
       "      <td>0.951646</td>\n",
       "      <td>0.936444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 15:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 15:57:00</th>\n",
       "      <td>0.937277</td>\n",
       "      <td>0.745818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.780932</td>\n",
       "      <td>0.883443</td>\n",
       "      <td>0.948676</td>\n",
       "      <td>0.951581</td>\n",
       "      <td>0.952372</td>\n",
       "      <td>0.937244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 15:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 15:58:00</th>\n",
       "      <td>0.938297</td>\n",
       "      <td>0.738164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816708</td>\n",
       "      <td>0.909655</td>\n",
       "      <td>0.949654</td>\n",
       "      <td>0.952358</td>\n",
       "      <td>0.953120</td>\n",
       "      <td>0.938045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 15:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 15:59:00</th>\n",
       "      <td>0.934217</td>\n",
       "      <td>0.619438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.912538</td>\n",
       "      <td>0.949697</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>0.953669</td>\n",
       "      <td>0.938734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-31 15:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715160 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Close        %b   %b-high    %b-low  macdhist  rsi  \\\n",
       "udate                                                                        \n",
       "2018-01-09 17:00:00  0.127102  0.190103  0.955645  0.000000  0.600000  0.0   \n",
       "2018-01-09 17:01:00  0.129119  0.331801  0.000000  0.955683  0.598561  0.0   \n",
       "2018-01-09 17:02:00  0.129792  0.388274  0.000000  0.000000  0.600000  0.0   \n",
       "2018-01-09 17:03:00  0.128447  0.313508  0.000000  0.000000  0.597122  0.0   \n",
       "2018-01-09 17:04:00  0.129792  0.416041  0.000000  0.000000  0.600000  0.0   \n",
       "...                       ...       ...       ...       ...       ...  ...   \n",
       "2020-12-31 15:55:00  0.933197  0.679341  0.000000  0.000000  0.466714  0.0   \n",
       "2020-12-31 15:56:00  0.934727  0.704558  0.000000  0.000000  0.465999  0.0   \n",
       "2020-12-31 15:57:00  0.937277  0.745818  0.000000  0.000000  0.470293  0.0   \n",
       "2020-12-31 15:58:00  0.938297  0.738164  0.000000  0.000000  0.473157  0.0   \n",
       "2020-12-31 15:59:00  0.934217  0.619438  0.000000  0.000000  0.464567  0.0   \n",
       "\n",
       "                        j-kdj  diff-kdj    ema-10    ema-20    ema-50  \\\n",
       "udate                                                                   \n",
       "2018-01-09 17:00:00  0.374696  0.524400  0.117010  0.109494  0.106650   \n",
       "2018-01-09 17:01:00  0.363321  0.511189  0.116650  0.109127  0.106159   \n",
       "2018-01-09 17:02:00  0.360112  0.506246  0.116511  0.108873  0.105755   \n",
       "2018-01-09 17:03:00  0.343266  0.487283  0.116123  0.108507  0.105292   \n",
       "2018-01-09 17:04:00  0.342979  0.485665  0.116068  0.108309  0.104887   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2020-12-31 15:55:00  0.684656  0.797816  0.947102  0.950307  0.950986   \n",
       "2020-12-31 15:56:00  0.730713  0.839755  0.947698  0.950847  0.951646   \n",
       "2020-12-31 15:57:00  0.780932  0.883443  0.948676  0.951581  0.952372   \n",
       "2020-12-31 15:58:00  0.816708  0.909655  0.949654  0.952358  0.953120   \n",
       "2020-12-31 15:59:00  0.831758  0.912538  0.949697  0.952639  0.953669   \n",
       "\n",
       "                      ema-100  p-sar               udate  \n",
       "udate                                                     \n",
       "2018-01-09 17:00:00  0.114544    0.0 2018-01-09 17:00:00  \n",
       "2018-01-09 17:01:00  0.114075    0.0 2018-01-09 17:01:00  \n",
       "2018-01-09 17:02:00  0.113635    0.0 2018-01-09 17:02:00  \n",
       "2018-01-09 17:03:00  0.113195    0.0 2018-01-09 17:03:00  \n",
       "2018-01-09 17:04:00  0.112785    0.0 2018-01-09 17:04:00  \n",
       "...                       ...    ...                 ...  \n",
       "2020-12-31 15:55:00  0.935688    1.0 2020-12-31 15:55:00  \n",
       "2020-12-31 15:56:00  0.936444    1.0 2020-12-31 15:56:00  \n",
       "2020-12-31 15:57:00  0.937244    1.0 2020-12-31 15:57:00  \n",
       "2020-12-31 15:58:00  0.938045    1.0 2020-12-31 15:58:00  \n",
       "2020-12-31 15:59:00  0.938734    1.0 2020-12-31 15:59:00  \n",
       "\n",
       "[715160 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.0 合併\n",
    "df5 = pd.DataFrame()\n",
    "for k, df5_1 in data2.items():\n",
    "    df5 = pd.concat([df5, df5_1], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "# 5.1 清洗\n",
    "df5_3 = df5.copy(deep=True)\n",
    "drop_list_3 = ['High', 'Low', 'Open', 'Volume', 'macd', 'macdsignal', 'upper-band', 'lower-band', 'middle-band', 'k-kdj', 'd-kdj', 'vol-ema5', 'rsi-2']\n",
    "df5_3.drop(drop_list_3, axis=1, inplace=True)\n",
    "df5_3.fillna(0, inplace=True)\n",
    "df5_3 = df5_3.round(2)\n",
    "\n",
    "# 5.2 檢查\n",
    "is_contain_null = df5_3.isnull().sum()\n",
    "is_contain_nan = df5_3.isna().sum()\n",
    "is_contain_inf = df5_3.isin([np.nan]).sum()\n",
    "print('数据集: Total dataset has {} samples, and {} features.'.format(df5_3.shape[0], df5_3.shape[1])) # df5_3.info()\n",
    "\n",
    "# 5.3 儲存\n",
    "path_data = os.path.abspath(os.path.join('data', 'nq', 'clean-data', 'nq-clean-data-with-features.csv'))\n",
    "if os.path.exists(path_data):\n",
    "    os.remove(path_data)\n",
    "df5_3.to_csv(path_data)\n",
    "\n",
    "# 5.4.1 分包 (日子)\n",
    "data3 = separate_daily(df5_3, 'dict')\n",
    "# 5.3.2 正則化\n",
    "normalization_days = 10\n",
    "days2 = np.array(list(data3.keys()))\n",
    "len_days2 = (days2.shape[0]//normalization_days)+1\n",
    "data3_1 = []\n",
    "scalers = {}\n",
    "for i in range(len_days2, 0, -1):\n",
    "    try:\n",
    "        end1 = (i*normalization_days)-(normalization_days-(days2.shape[0]%normalization_days))-1\n",
    "        start1 = end1-normalization_days\n",
    "        if start1 <= 0:\n",
    "            break # 不足够10天，退出\n",
    "        # 5.3.3 每X日集合\n",
    "        day_start, day_end = days2[start1], days2[end1]\n",
    "        day_start2 = datetime(day_start.year, day_start.month, day_start.day, 17, 0, 0)\n",
    "        day_end2 = datetime(day_end.year, day_end.month, day_end.day, 16, 0, 0)\n",
    "        mask = ((df5_3['udate'] >= day_start2) & (df5_3['udate'] <= day_end2))\n",
    "        df5_4 = df5_3[mask]\n",
    "        print('{} ~ {}  开始：{}   终结：{}'.\n",
    "              format(start1, end1, df5_4.iloc[0]['udate'].strftime('%Y-%m-%d %H:%M:%S'), df5_4.iloc[-1]['udate'].strftime('%Y-%m-%d %H:%M:%S')))\n",
    "        # 5.4.4 正則代集合\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        df5_5 = df5_4.drop(['udate'], axis=1)\n",
    "        min_max_scaler.fit(df5_5)\n",
    "        scalers[i] = {'scaler': min_max_scaler, 'day_start': day_start2, 'day_end': day_end2}\n",
    "        df5_6 = min_max_scaler.transform(df5_5)\n",
    "        df5_6 = pd.DataFrame(df5_6, columns=df5_5.columns, index=df5_5.index)\n",
    "        df5_6['udate'] = df5_4['udate']\n",
    "        # 5.4.5 合併\n",
    "        data3_1.append(df5_6)\n",
    "    except:\n",
    "        print('except: ', start1, end1, len(days2))\n",
    "        \n",
    "# 5.4.6 save mixmax scaler\n",
    "path_name_12 = os.path.abspath(os.path.join('min_max_scaler', prefix+'-'+cur_time+'.pkl'))\n",
    "if os.path.exists(path_name_12):\n",
    "    os.remove(path_name_12)\n",
    "joblib.dump(scalers, path_name_12) \n",
    "\n",
    "# 5.4.7 合併\n",
    "df5_7 = pd.DataFrame()\n",
    "for df5_8 in data3_1:\n",
    "    df5_7 = pd.concat([df5_7, df5_8], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "df5_7.sort_index(inplace=True)\n",
    "df5_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 - 时间拦截器\n",
    "df5_71 = df5_7.loc[(df5_7['udate'] >= datetime(2020, 11, 4, 5, 0, 0)) & (df5_7['udate'] <= datetime(2020, 11, 4, 7, 0, 0))]\n",
    "for k, v in df5_71.iterrows():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530, 400, 80, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.5.1 訓練集, 測試集, 數據集\n",
    "df5_8 = df5_7.copy(deep=True)\n",
    "\n",
    "is_raw_data = False\n",
    "if is_raw_data:\n",
    "    drop_list_5 = df5_8.columns.values.tolist()\n",
    "    drop_list_5.remove('Close')\n",
    "    drop_list_5.remove('udate')\n",
    "    df5_8.drop(drop_list_5, axis=1, inplace=True)\n",
    "\n",
    "data4 = separate_daily(df5_8, 'dict')\n",
    "days3 = np.array(list(data4.keys()))\n",
    "\n",
    "# train_set, test_set, valid_set = days3[0:-36], days3[-36:-11], days3[-11:-1] # for 15s\n",
    "#train_set, test_set, valid_set = days3[0:-76], days3[-76:-33], days3[-33:-1] # 0921~1113\n",
    "\n",
    "#train_set, test_set, valid_set = days3[0:-100], days3[-100:-20], days3[-20:] # 0921~1113\n",
    "#train_set, test_set, valid_set = days3[0:-120], days3[-120:-40], days3[-40:-20] # 0921~1113\n",
    "train_set, test_set, valid_set = days3[0:-130], days3[-130:-50], days3[-50:-40] # 0921~1113\n",
    "#train_set, test_set, valid_set = days3[0:-140], days3[-140:-70], days3[-70:-60] # 0921~1113\n",
    "\n",
    "# train_set, test_set, valid_set = days3[0:-63], days3[-63:-21], days3[-21:-2] # 1012-1113\n",
    "#train_set, test_set, valid_set = days3[0:-110], days3[-110:-74], days3[-74:-32] # 0608~0921\n",
    "#train_set, test_set, valid_set = days3[0:-44], days3[-44:-1], days3[-1:-1] # 0921~1113\n",
    "\n",
    "#train_set, test_set, valid_set = days3[0:-55], days3[-55:-5], days3[-5:] #1\n",
    "#train_set, test_set, valid_set = days3[0:-60], days3[-60:-10], days3[-10:-5] #2\n",
    "#train_set, test_set, valid_set = days3[0:-65], days3[-65:-15], days3[-15:-10] #3\n",
    "#train_set, test_set, valid_set = days3[0:-70], days3[-70:-20], days3[-20:-15] #4\n",
    "x_train, y_train, date_train = np.array([]), np.array([]), []\n",
    "x_test, y_test, date_test = np.array([]), np.array([]), []\n",
    "x_valid, y_valid, date_valid = np.array([]), np.array([]), []\n",
    "len(days3), len(train_set), len(test_set), len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集: X_train Data: (516262, 50, 13), Y_train Data: (516262, 5), Date_Train: (516262, 5)\n",
      "測試集: X_Test Data: (104633, 50, 13), Y_Test Data: (104633, 5), Date_Test: (104633, 5)\n",
      "验证集: X_Valid Data: (13107, 50, 13), Y_Valid Data: (13107, 5), Date_Valid: (13107, 5)\n"
     ]
    }
   ],
   "source": [
    "# 5.5.2 窗口步長\n",
    "t_pus_no = 5\n",
    "window_size = 50\n",
    "is_y_label_m_to_n = True\n",
    "\n",
    "for day, df6 in data4.items():\n",
    "    df6.drop(['udate'], axis=1, inplace=True)\n",
    "    # 5.5.3 窗口\n",
    "    no_max = df6.shape[0]-t_pus_no\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(window_size, no_max):\n",
    "        start, end = i-window_size, i\n",
    "        # y label\n",
    "        if is_y_label_m_to_n:\n",
    "            temp_0 = df6.iloc[end: end+t_pus_no] # t1 ~ t5\n",
    "            temp_2 = df6.iloc[end-1: end+t_pus_no-1] # current time\n",
    "        else:\n",
    "            temp_0 = df6.iloc[end+t_pus_no: end+t_pus_no] # t5\n",
    "            temp_2 = df6.iloc[end-t_pus_no-1: end-t_pus_no-1] # current time\n",
    "        y_data.append(temp_0['Close'])\n",
    "        # x matrix\n",
    "        temp_1 = df6.iloc[start: end]\n",
    "        x_data.append(temp_1)\n",
    "        # date\n",
    "        days4 = temp_2.index.tolist()\n",
    "        if day in train_set:\n",
    "            date_train.append(days4)\n",
    "        elif day in test_set:\n",
    "            date_test.append(days4)\n",
    "        elif day in valid_set:\n",
    "            date_valid.append(days4)\n",
    "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "    # print(day, x_data.shape, y_data.shape) \n",
    "    # 5.5.4 分集1\n",
    "    if day in train_set and x_train.any() and y_train.any():\n",
    "        x_train = np.concatenate((x_train, x_data), axis=0)\n",
    "        y_train = np.concatenate((y_train, y_data), axis=0)\n",
    "    elif day in test_set and x_test.any() and y_test.any():\n",
    "        x_test = np.concatenate((x_test, x_data), axis=0)\n",
    "        y_test = np.concatenate((y_test, y_data), axis=0)\n",
    "    elif day in valid_set and x_valid.any() and y_valid.any():\n",
    "        x_valid = np.concatenate((x_valid, x_data), axis=0)\n",
    "        y_valid = np.concatenate((y_valid, y_data), axis=0)\n",
    "    # 5.5.5 分集2\n",
    "    if day in train_set and not x_train.any() and not y_train.any():\n",
    "        x_train, y_train = x_data, y_data\n",
    "    elif day in test_set and not x_test.any() and not y_test.any():\n",
    "        x_test, y_test = x_data, y_data\n",
    "    elif day in valid_set and not x_valid.any() and not y_valid.any():\n",
    "        x_valid, y_valid = x_data, y_data\n",
    "\n",
    "# no_batches, timesteps, no_features \n",
    "print('訓練集: X_train Data: {}, Y_train Data: {}, Date_Train: {}'.format(x_train.shape, y_train.shape, np.array(date_train).shape))\n",
    "print('測試集: X_Test Data: {}, Y_Test Data: {}, Date_Test: {}'.format(x_test.shape, y_test.shape, np.array(date_test).shape))\n",
    "print('验证集: X_Valid Data: {}, Y_Valid Data: {}, Date_Valid: {}'.format(x_valid.shape, y_valid.shape, np.array(date_valid).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 512)           1077248   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 11,575,813\n",
      "Trainable params: 11,575,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/128\n",
      "2017/2017 [==============================] - 138s 66ms/step - loss: 0.0132 - mae: 0.0510 - val_loss: 0.0012 - val_mae: 0.0302\n",
      "Epoch 2/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 8.4016e-04 - mae: 0.0217 - val_loss: 2.3280e-04 - val_mae: 0.0112\n",
      "Epoch 3/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 5.2763e-04 - mae: 0.0172 - val_loss: 2.2234e-04 - val_mae: 0.0114\n",
      "Epoch 4/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 4.1178e-04 - mae: 0.0152 - val_loss: 1.8325e-04 - val_mae: 0.0102\n",
      "Epoch 5/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 3.4280e-04 - mae: 0.0139 - val_loss: 1.3243e-04 - val_mae: 0.0082\n",
      "Epoch 6/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 2.8962e-04 - mae: 0.0127 - val_loss: 2.0243e-04 - val_mae: 0.0111\n",
      "Epoch 7/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 2.5374e-04 - mae: 0.0118 - val_loss: 1.2670e-04 - val_mae: 0.0077\n",
      "Epoch 8/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 2.2846e-04 - mae: 0.0112 - val_loss: 1.4942e-04 - val_mae: 0.0092\n",
      "Epoch 9/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 2.1094e-04 - mae: 0.0107 - val_loss: 1.3958e-04 - val_mae: 0.0087\n",
      "Epoch 10/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.9933e-04 - mae: 0.0103 - val_loss: 1.1150e-04 - val_mae: 0.0071\n",
      "Epoch 11/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.9047e-04 - mae: 0.0101 - val_loss: 1.0741e-04 - val_mae: 0.0068\n",
      "Epoch 12/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.7805e-04 - mae: 0.0097 - val_loss: 1.1147e-04 - val_mae: 0.0069\n",
      "Epoch 13/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.7203e-04 - mae: 0.0095 - val_loss: 1.0524e-04 - val_mae: 0.0067\n",
      "Epoch 14/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.6915e-04 - mae: 0.0094 - val_loss: 1.0170e-04 - val_mae: 0.0064\n",
      "Epoch 15/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.6565e-04 - mae: 0.0093 - val_loss: 1.5884e-04 - val_mae: 0.0096\n",
      "Epoch 16/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.6349e-04 - mae: 0.0092 - val_loss: 1.1348e-04 - val_mae: 0.0072\n",
      "Epoch 17/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.6047e-04 - mae: 0.0091 - val_loss: 1.0720e-04 - val_mae: 0.0068\n",
      "Epoch 18/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.5793e-04 - mae: 0.0090 - val_loss: 1.0959e-04 - val_mae: 0.0070\n",
      "Epoch 19/128\n",
      "2017/2017 [==============================] - 130s 65ms/step - loss: 1.5480e-04 - mae: 0.0089 - val_loss: 1.0552e-04 - val_mae: 0.0067\n",
      "Epoch 20/128\n",
      "2017/2017 [==============================] - 130s 65ms/step - loss: 1.5604e-04 - mae: 0.0089 - val_loss: 1.0401e-04 - val_mae: 0.0066\n",
      "Epoch 21/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.5351e-04 - mae: 0.0088 - val_loss: 1.0452e-04 - val_mae: 0.0067\n",
      "Epoch 22/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.5120e-04 - mae: 0.0087 - val_loss: 1.2066e-04 - val_mae: 0.0077\n",
      "Epoch 23/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.5026e-04 - mae: 0.0088 - val_loss: 1.0099e-04 - val_mae: 0.0064\n",
      "Epoch 24/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4933e-04 - mae: 0.0087 - val_loss: 1.0987e-04 - val_mae: 0.0070\n",
      "Epoch 25/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4653e-04 - mae: 0.0086 - val_loss: 1.0794e-04 - val_mae: 0.0069\n",
      "Epoch 26/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4842e-04 - mae: 0.0086 - val_loss: 1.1896e-04 - val_mae: 0.0074\n",
      "Epoch 27/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4951e-04 - mae: 0.0087 - val_loss: 1.0006e-04 - val_mae: 0.0064\n",
      "Epoch 28/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4517e-04 - mae: 0.0085 - val_loss: 1.1775e-04 - val_mae: 0.0075\n",
      "Epoch 29/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4646e-04 - mae: 0.0086 - val_loss: 9.9108e-05 - val_mae: 0.0063\n",
      "Epoch 30/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4723e-04 - mae: 0.0086 - val_loss: 9.8177e-05 - val_mae: 0.0062\n",
      "Epoch 31/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4173e-04 - mae: 0.0084 - val_loss: 1.0581e-04 - val_mae: 0.0068\n",
      "Epoch 32/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4254e-04 - mae: 0.0085 - val_loss: 1.0602e-04 - val_mae: 0.0068\n",
      "Epoch 33/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4414e-04 - mae: 0.0085 - val_loss: 1.0338e-04 - val_mae: 0.0066\n",
      "Epoch 34/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4248e-04 - mae: 0.0085 - val_loss: 1.3527e-04 - val_mae: 0.0086\n",
      "Epoch 35/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4196e-04 - mae: 0.0084 - val_loss: 1.0655e-04 - val_mae: 0.0068\n",
      "Epoch 36/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4295e-04 - mae: 0.0084 - val_loss: 9.8520e-05 - val_mae: 0.0063\n",
      "Epoch 37/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4223e-04 - mae: 0.0084 - val_loss: 1.2061e-04 - val_mae: 0.0076\n",
      "Epoch 38/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.4158e-04 - mae: 0.0084 - val_loss: 1.1324e-04 - val_mae: 0.0073\n",
      "Epoch 39/128\n",
      "2017/2017 [==============================] - 130s 65ms/step - loss: 1.4162e-04 - mae: 0.0084 - val_loss: 1.0160e-04 - val_mae: 0.0065\n",
      "Epoch 40/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.3930e-04 - mae: 0.0083 - val_loss: 1.0185e-04 - val_mae: 0.0065\n",
      "Epoch 41/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4008e-04 - mae: 0.0084 - val_loss: 9.9985e-05 - val_mae: 0.0064\n",
      "Epoch 42/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3966e-04 - mae: 0.0083 - val_loss: 9.8092e-05 - val_mae: 0.0062\n",
      "Epoch 43/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.4005e-04 - mae: 0.0083 - val_loss: 1.0720e-04 - val_mae: 0.0069\n",
      "Epoch 44/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3845e-04 - mae: 0.0083 - val_loss: 1.1745e-04 - val_mae: 0.0074\n",
      "Epoch 45/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3958e-04 - mae: 0.0083 - val_loss: 1.2307e-04 - val_mae: 0.0078\n",
      "Epoch 46/128\n",
      "2017/2017 [==============================] - 131s 65ms/step - loss: 1.3806e-04 - mae: 0.0083 - val_loss: 1.1043e-04 - val_mae: 0.0070\n",
      "Epoch 47/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3636e-04 - mae: 0.0082 - val_loss: 9.9985e-05 - val_mae: 0.0064\n",
      "Epoch 48/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3744e-04 - mae: 0.0083 - val_loss: 1.1344e-04 - val_mae: 0.0073\n",
      "Epoch 49/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3764e-04 - mae: 0.0083 - val_loss: 1.1976e-04 - val_mae: 0.0076\n",
      "Epoch 50/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3846e-04 - mae: 0.0083 - val_loss: 1.0542e-04 - val_mae: 0.0067\n",
      "Epoch 51/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3773e-04 - mae: 0.0083 - val_loss: 1.2176e-04 - val_mae: 0.0077\n",
      "Epoch 52/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3706e-04 - mae: 0.0082 - val_loss: 9.9827e-05 - val_mae: 0.0064\n",
      "Epoch 53/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3753e-04 - mae: 0.0082 - val_loss: 9.6971e-05 - val_mae: 0.0062\n",
      "Epoch 54/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3771e-04 - mae: 0.0082 - val_loss: 9.9174e-05 - val_mae: 0.0063\n",
      "Epoch 55/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3705e-04 - mae: 0.0082 - val_loss: 1.0778e-04 - val_mae: 0.0069\n",
      "Epoch 56/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3705e-04 - mae: 0.0082 - val_loss: 9.9074e-05 - val_mae: 0.0063\n",
      "Epoch 57/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3458e-04 - mae: 0.0082 - val_loss: 1.0277e-04 - val_mae: 0.0066\n",
      "Epoch 58/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3498e-04 - mae: 0.0082 - val_loss: 1.0534e-04 - val_mae: 0.0067\n",
      "Epoch 59/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3452e-04 - mae: 0.0081 - val_loss: 1.0531e-04 - val_mae: 0.0068\n",
      "Epoch 60/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3627e-04 - mae: 0.0082 - val_loss: 1.0772e-04 - val_mae: 0.0069\n",
      "Epoch 61/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3508e-04 - mae: 0.0082 - val_loss: 9.7666e-05 - val_mae: 0.0062\n",
      "Epoch 62/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3363e-04 - mae: 0.0081 - val_loss: 1.0455e-04 - val_mae: 0.0067\n",
      "Epoch 63/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3458e-04 - mae: 0.0081 - val_loss: 9.7901e-05 - val_mae: 0.0062\n",
      "Epoch 64/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3435e-04 - mae: 0.0081 - val_loss: 1.1286e-04 - val_mae: 0.0073\n",
      "Epoch 65/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3351e-04 - mae: 0.0081 - val_loss: 1.0356e-04 - val_mae: 0.0066\n",
      "Epoch 66/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3552e-04 - mae: 0.0081 - val_loss: 9.8224e-05 - val_mae: 0.0062\n",
      "Epoch 67/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3169e-04 - mae: 0.0080 - val_loss: 1.0316e-04 - val_mae: 0.0066\n",
      "Epoch 68/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3402e-04 - mae: 0.0081 - val_loss: 9.9644e-05 - val_mae: 0.0064\n",
      "Epoch 69/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3308e-04 - mae: 0.0081 - val_loss: 1.2975e-04 - val_mae: 0.0082\n",
      "Epoch 70/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3541e-04 - mae: 0.0082 - val_loss: 1.0334e-04 - val_mae: 0.0066\n",
      "Epoch 71/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3254e-04 - mae: 0.0081 - val_loss: 9.9523e-05 - val_mae: 0.0064\n",
      "Epoch 72/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3337e-04 - mae: 0.0081 - val_loss: 1.0596e-04 - val_mae: 0.0068\n",
      "Epoch 73/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3293e-04 - mae: 0.0081 - val_loss: 1.0762e-04 - val_mae: 0.0068\n",
      "Epoch 74/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3303e-04 - mae: 0.0081 - val_loss: 1.0330e-04 - val_mae: 0.0066\n",
      "Epoch 75/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3248e-04 - mae: 0.0081 - val_loss: 9.9542e-05 - val_mae: 0.0064\n",
      "Epoch 76/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3257e-04 - mae: 0.0080 - val_loss: 1.0402e-04 - val_mae: 0.0067\n",
      "Epoch 77/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3290e-04 - mae: 0.0081 - val_loss: 1.0518e-04 - val_mae: 0.0068\n",
      "Epoch 78/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3331e-04 - mae: 0.0081 - val_loss: 1.0967e-04 - val_mae: 0.0072\n",
      "Epoch 79/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3267e-04 - mae: 0.0081 - val_loss: 1.0091e-04 - val_mae: 0.0065\n",
      "Epoch 80/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3283e-04 - mae: 0.0081 - val_loss: 1.0186e-04 - val_mae: 0.0065\n",
      "Epoch 81/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3070e-04 - mae: 0.0080 - val_loss: 9.9435e-05 - val_mae: 0.0064\n",
      "Epoch 82/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3224e-04 - mae: 0.0080 - val_loss: 9.8419e-05 - val_mae: 0.0063\n",
      "Epoch 83/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3236e-04 - mae: 0.0080 - val_loss: 9.9594e-05 - val_mae: 0.0063\n",
      "Epoch 84/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3213e-04 - mae: 0.0080 - val_loss: 1.0164e-04 - val_mae: 0.0065\n",
      "Epoch 85/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3280e-04 - mae: 0.0080 - val_loss: 9.8616e-05 - val_mae: 0.0063\n",
      "Epoch 86/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3158e-04 - mae: 0.0080 - val_loss: 9.9094e-05 - val_mae: 0.0063\n",
      "Epoch 87/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3207e-04 - mae: 0.0080 - val_loss: 9.9614e-05 - val_mae: 0.0064\n",
      "Epoch 88/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3166e-04 - mae: 0.0080 - val_loss: 9.6378e-05 - val_mae: 0.0061\n",
      "Epoch 89/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3235e-04 - mae: 0.0080 - val_loss: 1.0004e-04 - val_mae: 0.0064\n",
      "Epoch 90/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3060e-04 - mae: 0.0080 - val_loss: 1.0693e-04 - val_mae: 0.0069\n",
      "Epoch 91/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.3190e-04 - mae: 0.0080 - val_loss: 9.9052e-05 - val_mae: 0.0063\n",
      "Epoch 92/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3013e-04 - mae: 0.0080 - val_loss: 1.0527e-04 - val_mae: 0.0067\n",
      "Epoch 93/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3117e-04 - mae: 0.0080 - val_loss: 1.0140e-04 - val_mae: 0.0065\n",
      "Epoch 94/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3017e-04 - mae: 0.0080 - val_loss: 9.6286e-05 - val_mae: 0.0061\n",
      "Epoch 95/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.3074e-04 - mae: 0.0080 - val_loss: 9.6980e-05 - val_mae: 0.0062\n",
      "Epoch 96/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2864e-04 - mae: 0.0079 - val_loss: 1.0131e-04 - val_mae: 0.0066\n",
      "Epoch 97/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3125e-04 - mae: 0.0080 - val_loss: 9.9940e-05 - val_mae: 0.0064\n",
      "Epoch 98/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2932e-04 - mae: 0.0080 - val_loss: 1.0354e-04 - val_mae: 0.0067\n",
      "Epoch 99/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2884e-04 - mae: 0.0079 - val_loss: 9.9523e-05 - val_mae: 0.0063\n",
      "Epoch 100/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.3080e-04 - mae: 0.0080 - val_loss: 1.0022e-04 - val_mae: 0.0064\n",
      "Epoch 101/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.3052e-04 - mae: 0.0080 - val_loss: 9.9206e-05 - val_mae: 0.0064\n",
      "Epoch 102/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2990e-04 - mae: 0.0080 - val_loss: 9.6870e-05 - val_mae: 0.0062\n",
      "Epoch 103/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2995e-04 - mae: 0.0080 - val_loss: 1.0099e-04 - val_mae: 0.0065\n",
      "Epoch 104/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.3036e-04 - mae: 0.0080 - val_loss: 9.7287e-05 - val_mae: 0.0062\n",
      "Epoch 105/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.3089e-04 - mae: 0.0080 - val_loss: 9.9633e-05 - val_mae: 0.0064\n",
      "Epoch 106/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.2884e-04 - mae: 0.0079 - val_loss: 1.0112e-04 - val_mae: 0.0065\n",
      "Epoch 107/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.2856e-04 - mae: 0.0079 - val_loss: 1.0146e-04 - val_mae: 0.0065\n",
      "Epoch 108/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2918e-04 - mae: 0.0079 - val_loss: 1.0663e-04 - val_mae: 0.0067\n",
      "Epoch 109/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2990e-04 - mae: 0.0080 - val_loss: 9.6237e-05 - val_mae: 0.0061\n",
      "Epoch 110/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2855e-04 - mae: 0.0079 - val_loss: 9.9224e-05 - val_mae: 0.0063\n",
      "Epoch 111/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2979e-04 - mae: 0.0080 - val_loss: 9.8489e-05 - val_mae: 0.0063\n",
      "Epoch 112/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2978e-04 - mae: 0.0079 - val_loss: 1.0345e-04 - val_mae: 0.0067\n",
      "Epoch 113/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2887e-04 - mae: 0.0079 - val_loss: 1.0306e-04 - val_mae: 0.0067\n",
      "Epoch 114/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2888e-04 - mae: 0.0079 - val_loss: 9.9002e-05 - val_mae: 0.0063\n",
      "Epoch 115/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2880e-04 - mae: 0.0079 - val_loss: 1.0270e-04 - val_mae: 0.0066\n",
      "Epoch 116/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2922e-04 - mae: 0.0079 - val_loss: 1.0051e-04 - val_mae: 0.0064\n",
      "Epoch 117/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.2852e-04 - mae: 0.0079 - val_loss: 1.0006e-04 - val_mae: 0.0064\n",
      "Epoch 118/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2684e-04 - mae: 0.0079 - val_loss: 1.0400e-04 - val_mae: 0.0067\n",
      "Epoch 119/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2819e-04 - mae: 0.0079 - val_loss: 9.9264e-05 - val_mae: 0.0063\n",
      "Epoch 120/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.2752e-04 - mae: 0.0079 - val_loss: 9.9783e-05 - val_mae: 0.0064\n",
      "Epoch 121/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2841e-04 - mae: 0.0079 - val_loss: 9.6425e-05 - val_mae: 0.0061\n",
      "Epoch 122/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2890e-04 - mae: 0.0079 - val_loss: 9.9055e-05 - val_mae: 0.0063\n",
      "Epoch 123/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2844e-04 - mae: 0.0079 - val_loss: 1.0035e-04 - val_mae: 0.0064\n",
      "Epoch 124/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2740e-04 - mae: 0.0079 - val_loss: 1.0187e-04 - val_mae: 0.0066\n",
      "Epoch 125/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2894e-04 - mae: 0.0079 - val_loss: 9.9831e-05 - val_mae: 0.0064\n",
      "Epoch 126/128\n",
      "2017/2017 [==============================] - 133s 66ms/step - loss: 1.2738e-04 - mae: 0.0079 - val_loss: 9.9044e-05 - val_mae: 0.0063\n",
      "Epoch 127/128\n",
      "2017/2017 [==============================] - 132s 66ms/step - loss: 1.2818e-04 - mae: 0.0079 - val_loss: 1.0162e-04 - val_mae: 0.0065\n",
      "Epoch 128/128\n",
      "2017/2017 [==============================] - 132s 65ms/step - loss: 1.2688e-04 - mae: 0.0079 - val_loss: 9.7075e-05 - val_mae: 0.0062\n"
     ]
    }
   ],
   "source": [
    "# 6.1.1 模型参数\n",
    "batch_size = 256\n",
    "epochs = 128\n",
    "units = 512\n",
    "verbose = 1\n",
    "learning_rate = 0.0005 # 0.001\n",
    "no_batches = x_train.shape[0]\n",
    "timesteps = x_train.shape[1]\n",
    "no_features = x_train.shape[2]\n",
    "batch_input_shape = (timesteps, no_features)\n",
    "\n",
    "# 6.2 模型 \n",
    "# activation=softsign/tanh\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(units=units, recurrent_activation='sigmoid', activation='tanh', unroll=False, use_bias=True, \n",
    "               recurrent_dropout=0, return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=False, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "if is_y_label_m_to_n:\n",
    "    model.add(Dense(units=t_pus_no))\n",
    "else:\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# 6.3.1 check point\n",
    "checkpoint_dir = './training_checkpoints/'+ prefix +'-' + cur_time\n",
    "os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "# 6.3.2 tensor board\n",
    "log_dir = os.path.join('./logs/fit/'+ prefix +'-') + cur_time\n",
    "os.mkdir(log_dir)\n",
    "tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# 6.4 fit model\n",
    "history_model = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True, verbose=verbose) # callbacks=[checkpoint_callback, tensor_board_callback]\n",
    "\n",
    "# 6.5 save model\n",
    "model_path = \"./saved_model/\"+prefix+\"-\"+cur_time+\".h5\"\n",
    "model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.1 visualize loss\n",
    "keys = list(history_model.history.keys())\n",
    "training_loss = history_model.history['loss']\n",
    "test_loss = history_model.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('model:'+prefix+'   lr:'+str(learning_rate)+'   epochs:'+str(epochs)+'   units:'+str(units)+'   bs:'+str(batch_size) ,loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-loss')\n",
    "plt.clf()\n",
    "\n",
    "# 7.2 visualize accuracy\n",
    "training_accuracy = history_model.history['mae']\n",
    "test_accuracy = history_model.history['val_mae']\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('model:'+prefix+'   lr:'+str(learning_rate)+'   epochs:'+str(epochs)+'   units:'+str(units)+'   bs:'+str(batch_size), loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-accuracy')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16134/16134 [==============================] - 236s 15ms/step - loss: 8.7322e-05 - mae: 0.0058\n",
      "3270/3270 [==============================] - 48s 15ms/step - loss: 9.7087e-05 - mae: 0.0062\n",
      "410/410 [==============================] - 6s 15ms/step - loss: 6.8638e-05 - mae: 0.0053\n",
      "Train Score: 0.0001 MSE (0.0093 RMSE)\n",
      "Test Score: 0.0001 MSE (0.0099 RMSE)\n",
      "Validate Score: 0.0001 MSE (0.0083 RMSE)\n"
     ]
    }
   ],
   "source": [
    "# 8.0 model evaluate\n",
    "verbose = 1\n",
    "train_score = model.evaluate(x_train, y_train, verbose=verbose)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "valid_score = model.evaluate(x_valid, y_valid, verbose=verbose)\n",
    "\n",
    "print('Train Score: %.4f MSE (%.4f RMSE)' % (train_score[0], math.sqrt(train_score[0])))\n",
    "print('Test Score: %.4f MSE (%.4f RMSE)' % (test_score[0], math.sqrt(test_score[0])))\n",
    "print('Validate Score: %.4f MSE (%.4f RMSE)' % (valid_score[0], math.sqrt(valid_score[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>udate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:49:00</th>\n",
       "      <td>0.375037</td>\n",
       "      <td>0.374842</td>\n",
       "      <td>0.374898</td>\n",
       "      <td>0.374875</td>\n",
       "      <td>0.375196</td>\n",
       "      <td>2020-10-01 17:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:50:00</th>\n",
       "      <td>0.374424</td>\n",
       "      <td>0.374230</td>\n",
       "      <td>0.374286</td>\n",
       "      <td>0.374264</td>\n",
       "      <td>0.374587</td>\n",
       "      <td>2020-10-01 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:51:00</th>\n",
       "      <td>0.373978</td>\n",
       "      <td>0.373783</td>\n",
       "      <td>0.373839</td>\n",
       "      <td>0.373817</td>\n",
       "      <td>0.374142</td>\n",
       "      <td>2020-10-01 17:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:52:00</th>\n",
       "      <td>0.374584</td>\n",
       "      <td>0.374388</td>\n",
       "      <td>0.374443</td>\n",
       "      <td>0.374423</td>\n",
       "      <td>0.374745</td>\n",
       "      <td>2020-10-01 17:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:53:00</th>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.372087</td>\n",
       "      <td>0.372144</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>2020-10-01 17:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:50:00</th>\n",
       "      <td>0.437248</td>\n",
       "      <td>0.437114</td>\n",
       "      <td>0.437092</td>\n",
       "      <td>0.437108</td>\n",
       "      <td>0.437285</td>\n",
       "      <td>2020-10-20 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:51:00</th>\n",
       "      <td>0.441350</td>\n",
       "      <td>0.441219</td>\n",
       "      <td>0.441192</td>\n",
       "      <td>0.441215</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>2020-10-20 15:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:52:00</th>\n",
       "      <td>0.441235</td>\n",
       "      <td>0.441106</td>\n",
       "      <td>0.441079</td>\n",
       "      <td>0.441097</td>\n",
       "      <td>0.441266</td>\n",
       "      <td>2020-10-20 15:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:53:00</th>\n",
       "      <td>0.442200</td>\n",
       "      <td>0.442071</td>\n",
       "      <td>0.442043</td>\n",
       "      <td>0.442063</td>\n",
       "      <td>0.442231</td>\n",
       "      <td>2020-10-20 15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:54:00</th>\n",
       "      <td>0.441512</td>\n",
       "      <td>0.441384</td>\n",
       "      <td>0.441356</td>\n",
       "      <td>0.441373</td>\n",
       "      <td>0.441546</td>\n",
       "      <td>2020-10-20 15:54:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           t1        t2        t3        t4        t5  \\\n",
       "udate                                                                   \n",
       "2020-10-01 17:49:00  0.375037  0.374842  0.374898  0.374875  0.375196   \n",
       "2020-10-01 17:50:00  0.374424  0.374230  0.374286  0.374264  0.374587   \n",
       "2020-10-01 17:51:00  0.373978  0.373783  0.373839  0.373817  0.374142   \n",
       "2020-10-01 17:52:00  0.374584  0.374388  0.374443  0.374423  0.374745   \n",
       "2020-10-01 17:53:00  0.372285  0.372087  0.372144  0.372118  0.372449   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2020-10-20 15:50:00  0.437248  0.437114  0.437092  0.437108  0.437285   \n",
       "2020-10-20 15:51:00  0.441350  0.441219  0.441192  0.441215  0.441379   \n",
       "2020-10-20 15:52:00  0.441235  0.441106  0.441079  0.441097  0.441266   \n",
       "2020-10-20 15:53:00  0.442200  0.442071  0.442043  0.442063  0.442231   \n",
       "2020-10-20 15:54:00  0.441512  0.441384  0.441356  0.441373  0.441546   \n",
       "\n",
       "                                  udate  \n",
       "udate                                    \n",
       "2020-10-01 17:49:00 2020-10-01 17:49:00  \n",
       "2020-10-01 17:50:00 2020-10-01 17:50:00  \n",
       "2020-10-01 17:51:00 2020-10-01 17:51:00  \n",
       "2020-10-01 17:52:00 2020-10-01 17:52:00  \n",
       "2020-10-01 17:53:00 2020-10-01 17:53:00  \n",
       "...                                 ...  \n",
       "2020-10-20 15:50:00 2020-10-20 15:50:00  \n",
       "2020-10-20 15:51:00 2020-10-20 15:51:00  \n",
       "2020-10-20 15:52:00 2020-10-20 15:52:00  \n",
       "2020-10-20 15:53:00 2020-10-20 15:53:00  \n",
       "2020-10-20 15:54:00 2020-10-20 15:54:00  \n",
       "\n",
       "[13107 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.0 預測\n",
    "predict1 = model.predict(x_valid)\n",
    "if is_y_label_m_to_n:\n",
    "    columns1=['t1', 't2', 't3', 't4', 't5']\n",
    "else:\n",
    "    columns1=['predict_close']\n",
    "df7 = pd.DataFrame(predict1, columns=columns1)\n",
    "date_valid2 = [v[0] for v in date_valid]\n",
    "df7['udate'] = date_valid2\n",
    "df7.index = df7['udate']\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:49:00</th>\n",
       "      <td>2020-10-01 17:49:00</td>\n",
       "      <td>11592.819631</td>\n",
       "      <td>11592.615535</td>\n",
       "      <td>11592.673795</td>\n",
       "      <td>11592.650291</td>\n",
       "      <td>11592.986909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:50:00</th>\n",
       "      <td>2020-10-01 17:50:00</td>\n",
       "      <td>11592.177025</td>\n",
       "      <td>11591.973241</td>\n",
       "      <td>11592.032344</td>\n",
       "      <td>11592.009059</td>\n",
       "      <td>11592.348366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:51:00</th>\n",
       "      <td>2020-10-01 17:51:00</td>\n",
       "      <td>11591.709228</td>\n",
       "      <td>11591.504413</td>\n",
       "      <td>11591.563548</td>\n",
       "      <td>11591.540419</td>\n",
       "      <td>11591.880913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:52:00</th>\n",
       "      <td>2020-10-01 17:52:00</td>\n",
       "      <td>11592.344990</td>\n",
       "      <td>11592.139331</td>\n",
       "      <td>11592.197091</td>\n",
       "      <td>11592.175931</td>\n",
       "      <td>11592.513737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:53:00</th>\n",
       "      <td>2020-10-01 17:53:00</td>\n",
       "      <td>11589.934340</td>\n",
       "      <td>11589.726462</td>\n",
       "      <td>11589.786347</td>\n",
       "      <td>11589.758936</td>\n",
       "      <td>11590.105369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:50:00</th>\n",
       "      <td>2020-10-20 15:50:00</td>\n",
       "      <td>11658.063487</td>\n",
       "      <td>11657.923339</td>\n",
       "      <td>11657.900304</td>\n",
       "      <td>11657.916963</td>\n",
       "      <td>11658.102619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:51:00</th>\n",
       "      <td>2020-10-20 15:51:00</td>\n",
       "      <td>11662.365826</td>\n",
       "      <td>11662.228116</td>\n",
       "      <td>11662.199955</td>\n",
       "      <td>11662.223865</td>\n",
       "      <td>11662.396425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:52:00</th>\n",
       "      <td>2020-10-20 15:52:00</td>\n",
       "      <td>11662.245650</td>\n",
       "      <td>11662.109627</td>\n",
       "      <td>11662.081654</td>\n",
       "      <td>11662.100876</td>\n",
       "      <td>11662.278187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:53:00</th>\n",
       "      <td>2020-10-20 15:53:00</td>\n",
       "      <td>11663.257255</td>\n",
       "      <td>11663.122358</td>\n",
       "      <td>11663.092791</td>\n",
       "      <td>11663.113481</td>\n",
       "      <td>11663.289573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:54:00</th>\n",
       "      <td>2020-10-20 15:54:00</td>\n",
       "      <td>11662.535823</td>\n",
       "      <td>11662.400988</td>\n",
       "      <td>11662.371640</td>\n",
       "      <td>11662.390236</td>\n",
       "      <td>11662.570860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13107 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate            t1            t2  \\\n",
       "udate                                                                 \n",
       "2020-10-01 17:49:00 2020-10-01 17:49:00  11592.819631  11592.615535   \n",
       "2020-10-01 17:50:00 2020-10-01 17:50:00  11592.177025  11591.973241   \n",
       "2020-10-01 17:51:00 2020-10-01 17:51:00  11591.709228  11591.504413   \n",
       "2020-10-01 17:52:00 2020-10-01 17:52:00  11592.344990  11592.139331   \n",
       "2020-10-01 17:53:00 2020-10-01 17:53:00  11589.934340  11589.726462   \n",
       "...                                 ...           ...           ...   \n",
       "2020-10-20 15:50:00 2020-10-20 15:50:00  11658.063487  11657.923339   \n",
       "2020-10-20 15:51:00 2020-10-20 15:51:00  11662.365826  11662.228116   \n",
       "2020-10-20 15:52:00 2020-10-20 15:52:00  11662.245650  11662.109627   \n",
       "2020-10-20 15:53:00 2020-10-20 15:53:00  11663.257255  11663.122358   \n",
       "2020-10-20 15:54:00 2020-10-20 15:54:00  11662.535823  11662.400988   \n",
       "\n",
       "                               t3            t4            t5  \n",
       "udate                                                          \n",
       "2020-10-01 17:49:00  11592.673795  11592.650291  11592.986909  \n",
       "2020-10-01 17:50:00  11592.032344  11592.009059  11592.348366  \n",
       "2020-10-01 17:51:00  11591.563548  11591.540419  11591.880913  \n",
       "2020-10-01 17:52:00  11592.197091  11592.175931  11592.513737  \n",
       "2020-10-01 17:53:00  11589.786347  11589.758936  11590.105369  \n",
       "...                           ...           ...           ...  \n",
       "2020-10-20 15:50:00  11657.900304  11657.916963  11658.102619  \n",
       "2020-10-20 15:51:00  11662.199955  11662.223865  11662.396425  \n",
       "2020-10-20 15:52:00  11662.081654  11662.100876  11662.278187  \n",
       "2020-10-20 15:53:00  11663.092791  11663.113481  11663.289573  \n",
       "2020-10-20 15:54:00  11662.371640  11662.390236  11662.570860  \n",
       "\n",
       "[13107 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.0 \n",
    "len_shape_y = df5_7.shape[1]-2\n",
    "fill_list = list(repeat(0, len_shape_y))\n",
    "df8 = pd.DataFrame()\n",
    "\n",
    "# 10.1 逆向\n",
    "for k, v in scalers.items():\n",
    "    mask = ((df7['udate'] >= v['day_start']) & (df7['udate'] <= v['day_end']))\n",
    "    df8_1 = df7.loc[mask]\n",
    "    df8_2 = df8_1.drop(['udate'], axis=1)\n",
    "    # 10.2\n",
    "    data4 = []\n",
    "    for k1, v1 in df8_2.iterrows():\n",
    "        data4_1 = []\n",
    "        for v2 in v1:\n",
    "            data4_1.append([v2] + fill_list)\n",
    "        data4_2 = v['scaler'].inverse_transform(data4_1)\n",
    "        data4_3 = [v[0] for v in data4_2]\n",
    "        data4.append(data4_3)\n",
    "    # 10.3\n",
    "    df8_3 = pd.DataFrame(data4, columns=columns1)\n",
    "    df8_3.index = df8_1['udate']\n",
    "    # 10.4 合併\n",
    "    if df8_3.shape[0] > 0:\n",
    "        df8 = pd.concat([df8, df8_3], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "df8['udate'] = df8.index.values\n",
    "df8 = df8[['udate'] + columns1]\n",
    "# df8[df8.index.duplicated()]\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-0928-1002-e128-u512-w50-lr0.0005.csv\n",
      "t5-1005-1009-e128-u512-w50-lr0.0005.csv\n",
      "t5-1012-1016-e128-u512-w50-lr0.0005.csv\n",
      "t5-1019-1023-e128-u512-w50-lr0.0005.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:00:00</th>\n",
       "      <td>11566.75</td>\n",
       "      <td>11575.75</td>\n",
       "      <td>11565.75</td>\n",
       "      <td>11568.50</td>\n",
       "      <td>239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:01:00</th>\n",
       "      <td>11568.50</td>\n",
       "      <td>11578.00</td>\n",
       "      <td>11568.50</td>\n",
       "      <td>11574.00</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:02:00</th>\n",
       "      <td>11574.00</td>\n",
       "      <td>11574.00</td>\n",
       "      <td>11571.75</td>\n",
       "      <td>11573.25</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:03:00</th>\n",
       "      <td>11573.25</td>\n",
       "      <td>11573.25</td>\n",
       "      <td>11566.75</td>\n",
       "      <td>11568.25</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01 17:04:00</th>\n",
       "      <td>11568.25</td>\n",
       "      <td>11573.50</td>\n",
       "      <td>11567.75</td>\n",
       "      <td>11571.50</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:49:00</th>\n",
       "      <td>11657.25</td>\n",
       "      <td>11658.75</td>\n",
       "      <td>11654.00</td>\n",
       "      <td>11655.50</td>\n",
       "      <td>86</td>\n",
       "      <td>11657.464732</td>\n",
       "      <td>11657.322864</td>\n",
       "      <td>11657.300830</td>\n",
       "      <td>11657.315895</td>\n",
       "      <td>11657.501238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:50:00</th>\n",
       "      <td>11655.50</td>\n",
       "      <td>11658.75</td>\n",
       "      <td>11655.00</td>\n",
       "      <td>11656.00</td>\n",
       "      <td>36</td>\n",
       "      <td>11658.063487</td>\n",
       "      <td>11657.923339</td>\n",
       "      <td>11657.900304</td>\n",
       "      <td>11657.916963</td>\n",
       "      <td>11658.102619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:51:00</th>\n",
       "      <td>11656.00</td>\n",
       "      <td>11662.50</td>\n",
       "      <td>11655.75</td>\n",
       "      <td>11661.00</td>\n",
       "      <td>68</td>\n",
       "      <td>11662.365826</td>\n",
       "      <td>11662.228116</td>\n",
       "      <td>11662.199955</td>\n",
       "      <td>11662.223865</td>\n",
       "      <td>11662.396425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:52:00</th>\n",
       "      <td>11661.00</td>\n",
       "      <td>11663.25</td>\n",
       "      <td>11660.25</td>\n",
       "      <td>11660.50</td>\n",
       "      <td>46</td>\n",
       "      <td>11662.245650</td>\n",
       "      <td>11662.109627</td>\n",
       "      <td>11662.081654</td>\n",
       "      <td>11662.100876</td>\n",
       "      <td>11662.278187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-20 15:53:00</th>\n",
       "      <td>11660.50</td>\n",
       "      <td>11661.75</td>\n",
       "      <td>11659.00</td>\n",
       "      <td>11661.25</td>\n",
       "      <td>28</td>\n",
       "      <td>11663.257255</td>\n",
       "      <td>11663.122358</td>\n",
       "      <td>11663.092791</td>\n",
       "      <td>11663.113481</td>\n",
       "      <td>11663.289573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13155 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         High       Low      Open     Close  Volume  \\\n",
       "udate                                                                 \n",
       "2020-10-01 17:00:00  11566.75  11575.75  11565.75  11568.50     239   \n",
       "2020-10-01 17:01:00  11568.50  11578.00  11568.50  11574.00     138   \n",
       "2020-10-01 17:02:00  11574.00  11574.00  11571.75  11573.25      67   \n",
       "2020-10-01 17:03:00  11573.25  11573.25  11566.75  11568.25      82   \n",
       "2020-10-01 17:04:00  11568.25  11573.50  11567.75  11571.50      83   \n",
       "...                       ...       ...       ...       ...     ...   \n",
       "2020-10-20 15:49:00  11657.25  11658.75  11654.00  11655.50      86   \n",
       "2020-10-20 15:50:00  11655.50  11658.75  11655.00  11656.00      36   \n",
       "2020-10-20 15:51:00  11656.00  11662.50  11655.75  11661.00      68   \n",
       "2020-10-20 15:52:00  11661.00  11663.25  11660.25  11660.50      46   \n",
       "2020-10-20 15:53:00  11660.50  11661.75  11659.00  11661.25      28   \n",
       "\n",
       "                               t1            t2            t3            t4  \\\n",
       "udate                                                                         \n",
       "2020-10-01 17:00:00           NaN           NaN           NaN           NaN   \n",
       "2020-10-01 17:01:00           NaN           NaN           NaN           NaN   \n",
       "2020-10-01 17:02:00           NaN           NaN           NaN           NaN   \n",
       "2020-10-01 17:03:00           NaN           NaN           NaN           NaN   \n",
       "2020-10-01 17:04:00           NaN           NaN           NaN           NaN   \n",
       "...                           ...           ...           ...           ...   \n",
       "2020-10-20 15:49:00  11657.464732  11657.322864  11657.300830  11657.315895   \n",
       "2020-10-20 15:50:00  11658.063487  11657.923339  11657.900304  11657.916963   \n",
       "2020-10-20 15:51:00  11662.365826  11662.228116  11662.199955  11662.223865   \n",
       "2020-10-20 15:52:00  11662.245650  11662.109627  11662.081654  11662.100876   \n",
       "2020-10-20 15:53:00  11663.257255  11663.122358  11663.092791  11663.113481   \n",
       "\n",
       "                               t5  \n",
       "udate                              \n",
       "2020-10-01 17:00:00           NaN  \n",
       "2020-10-01 17:01:00           NaN  \n",
       "2020-10-01 17:02:00           NaN  \n",
       "2020-10-01 17:03:00           NaN  \n",
       "2020-10-01 17:04:00           NaN  \n",
       "...                           ...  \n",
       "2020-10-20 15:49:00  11657.501238  \n",
       "2020-10-20 15:50:00  11658.102619  \n",
       "2020-10-20 15:51:00  11662.396425  \n",
       "2020-10-20 15:52:00  11662.278187  \n",
       "2020-10-20 15:53:00  11663.289573  \n",
       "\n",
       "[13155 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11.1\n",
    "df9 = df3.drop(list(df3.columns)[6:], axis=1)\n",
    "df9_1 = pd.concat([df9, df8], axis=1)\n",
    "\n",
    "# 11.2 \n",
    "start2, end2 =  date_valid2[0], date_valid2[-2:-1][0]\n",
    "start3 = start2 - timedelta(minutes=t_pus_no+window_size)\n",
    "mask3 = ((df9_1.index >= start3) & (df9_1.index <= start2)) # 窗口步長\n",
    "if is_y_label_m_to_n:\n",
    "    k9 = 't1'\n",
    "else:\n",
    "    k9 = 'predict_close'\n",
    "mask4 = ((df9_1.index >= start2) & (df9_1.index <= end2)) # 預測\n",
    "df9_2 = df9_1.loc[(mask3 | mask4)]\n",
    "df9_3 = df9_2.drop(['udate'], axis=1)\n",
    "\n",
    "path_name = ''\n",
    "if is_raw_data:\n",
    "    path_name = '-raw'\n",
    "    \n",
    "if is_y_label_m_to_n:\n",
    "    path_name_2 = 't'+str(t_pus_no)\n",
    "else:\n",
    "    path_name_2 = str(t_pus_no)+'mins'\n",
    "\n",
    "# 11.3.1 save1\n",
    "mask5 = ((df9_3.index >= start3) & (df9_3.index <= start2)) # 窗口步長\n",
    "mask6 = ((df9_3.index >= start2) & (df9_3.index <= end2) & (df9_3[k9] > 0)) # 預測\n",
    "df9_4 = df9_3.loc[(mask5 | mask6)]\n",
    "\n",
    "path_4 = os.path.abspath(os.path.join('data', 'nq', 'prediction', cur_time))\n",
    "if not os.path.exists(path_4):\n",
    "    os.mkdir(path_4)\n",
    "\n",
    "start9, end9 = pd.to_datetime(df9_4.index.values[0]), pd.to_datetime(df9_4.index.values[-1])\n",
    "path_1_date = str(start9.month).zfill(2)+str(start9.day).zfill(2)+'-'+str(end9.month).zfill(2)+str(end9.day).zfill(2)\n",
    "path_1 = os.path.abspath(os.path.join('data', 'nq', 'prediction', cur_time, path_name_2+'-'+path_1_date+'-e'+ str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + '-lr' + str(learning_rate) + path_name+ '.csv'))\n",
    "if os.path.exists(path_1):\n",
    "    os.remove(path_1)\n",
    "df9_4.to_csv(path_1)\n",
    "\n",
    "# 11.3.2 save3\n",
    "path_3 = os.path.abspath(os.path.join('data', 'nq', 'prediction', 'nq-prediction.csv'))\n",
    "if os.path.exists(path_3):\n",
    "    os.remove(path_3)\n",
    "df9_4.to_csv(path_3)\n",
    "\n",
    "# 11.4 save2\n",
    "days9 = [[datetime(2020, 7, 6, 17, 0, 0), datetime(2020, 7, 10, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 13, 17, 0, 0), datetime(2020, 7, 17, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 20, 17, 0, 0), datetime(2020, 7, 24, 16, 0, 0)],\n",
    "         [datetime(2020, 7, 27, 17, 0, 0), datetime(2020, 7, 31, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 8, 31, 17, 0, 0), datetime(2020, 9, 4, 16, 0, 0)],\n",
    "         [datetime(2020, 8, 7, 17, 0, 0), datetime(2020, 9, 11, 16, 0, 0)],\n",
    "         [datetime(2020, 8, 14, 17, 0, 0), datetime(2020, 9, 18, 16, 0, 0)],\n",
    "         [datetime(2020, 9, 21, 17, 0, 0), datetime(2020, 9, 25, 16, 0, 0)],\n",
    "         [datetime(2020, 9, 28, 17, 0, 0), datetime(2020, 10, 2, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 10, 5, 17, 0, 0), datetime(2020, 10, 9, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 12, 17, 0, 0), datetime(2020, 10, 16, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 19, 17, 0, 0), datetime(2020, 10, 23, 16, 0, 0)],\n",
    "         [datetime(2020, 10, 26, 17, 0, 0), datetime(2020, 10, 30, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 11, 2, 17, 0, 0), datetime(2020, 11, 6, 16, 0, 0)],\n",
    "         [datetime(2020, 11, 9, 17, 0, 0), datetime(2020, 11, 13, 16, 0, 0)],\n",
    "         [datetime(2020, 11, 16, 17, 0, 0), datetime(2020, 11, 20, 16, 0, 0)],\n",
    "         [datetime(2020, 11, 23, 17, 0, 0), datetime(2020, 11, 27, 16, 0, 0)],\n",
    "         #\n",
    "         [datetime(2020, 11, 30, 17, 0, 0), datetime(2020, 12, 1, 16, 0, 0)],\n",
    "         [datetime(2020, 12, 4, 17, 0, 0), datetime(2020, 12, 8, 16, 0, 0)],\n",
    "         [datetime(2020, 12, 11, 17, 0, 0), datetime(2020, 12, 15, 16, 0, 0)],\n",
    "         [datetime(2020, 12, 18, 17, 0, 0), datetime(2020, 12, 22, 16, 0, 0)],\n",
    "         [datetime(2020, 12, 28, 17, 0, 0), datetime(2021, 1, 1, 16, 0, 0)]]\n",
    "for v9 in days9:\n",
    "    df9_5 = df9_3.copy(deep=True)\n",
    "    start4 = v9[0] + timedelta(minutes=t_pus_no+window_size) # 窗口步長\n",
    "    mask7 = ((df9_5.index >= v9[0]) & (df9_5.index <= start4)) # 窗口步長\n",
    "    mask8 = ((df9_5.index >= start4) & (df9_5.index <= v9[1]) & (df9_5[k9] > 0)) # 預測\n",
    "    df9_6 = df9_5.loc[mask7 | mask8]\n",
    "    file_name_1 = path_name_2+'-'+ str(v9[0].month).zfill(2) + str(v9[0].day).zfill(2) +'-'+ str(v9[1].month).zfill(2) + str(v9[1].day).zfill(2) + '-e' + str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + '-lr' + str(learning_rate) + path_name + '.csv'\n",
    "    path_2 = os.path.abspath(os.path.join('data', 'nq', 'prediction', cur_time, file_name_1))\n",
    "    if os.path.exists(path_2):\n",
    "        os.remove(path_2)\n",
    "    if df9_6.shape[0] > 1:\n",
    "        df9_6.to_csv(path_2)\n",
    "        print(file_name_1)\n",
    "\n",
    "df9_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nobs</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>sd</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>ampe</th>\n",
       "      <th>min</th>\n",
       "      <th>q25%</th>\n",
       "      <th>q50%</th>\n",
       "      <th>q75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <td>13106</td>\n",
       "      <td>11699.148024</td>\n",
       "      <td>73923.664467</td>\n",
       "      <td>0.205552</td>\n",
       "      <td>-1.153277</td>\n",
       "      <td>271.878694</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>4.315462</td>\n",
       "      <td>2.077369</td>\n",
       "      <td>1.594107</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>11203.50</td>\n",
       "      <td>11470.8125</td>\n",
       "      <td>11679.500</td>\n",
       "      <td>11916.0000</td>\n",
       "      <td>12248.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <td>13106</td>\n",
       "      <td>11699.715311</td>\n",
       "      <td>73347.007032</td>\n",
       "      <td>0.211861</td>\n",
       "      <td>-1.145783</td>\n",
       "      <td>270.816193</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>4.315462</td>\n",
       "      <td>2.077369</td>\n",
       "      <td>1.594107</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>11216.15</td>\n",
       "      <td>11471.9650</td>\n",
       "      <td>11680.625</td>\n",
       "      <td>11914.2225</td>\n",
       "      <td>12243.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          nobs          mean      variance  skewness  kurtosis          sd  \\\n",
       "real     13106  11699.148024  73923.664467  0.205552 -1.153277  271.878694   \n",
       "predict  13106  11699.715311  73347.007032  0.211861 -1.145783  270.816193   \n",
       "\n",
       "               r2       mse      rmse       mae      ampe       min  \\\n",
       "real     0.999942  4.315462  2.077369  1.594107  0.000137  11203.50   \n",
       "predict  0.999942  4.315462  2.077369  1.594107  0.000137  11216.15   \n",
       "\n",
       "               q25%       q50%        q75%       max  \n",
       "real     11470.8125  11679.500  11916.0000  12248.25  \n",
       "predict  11471.9650  11680.625  11914.2225  12243.97  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12.1 evaluate\n",
    "if is_y_label_m_to_n:\n",
    "    predict_k12 = 't1'\n",
    "else:\n",
    "    predict_k12 = 'predict_close'\n",
    "\n",
    "df12 = df9_3.copy(deep=True)\n",
    "mask12 = ((df12[predict_k12] > 0) & (df12['Close'] > 0))\n",
    "df12 = df12.loc[mask12].round(2)\n",
    "\n",
    "# \n",
    "stats_1 = stats.describe(df12['Close'].values)\n",
    "stats_2 = stats.describe(df12[predict_k12].values)\n",
    "# R平方, 均方误差, 均方根误差, 平均绝对误差, 平均絕對百分比誤差\n",
    "r2 = r2_score(df12['Close'].values, df12[predict_k12].values)\n",
    "mse = mean_squared_error(df12['Close'].values, df12[predict_k12].values)\n",
    "rmse = np.sqrt(mean_squared_error(df12['Close'].values, df12[predict_k12].values))\n",
    "mae =  mean_absolute_error(df12['Close'].values, df12[predict_k12].values)\n",
    "ampe = np.mean(np.abs((df12['Close']-df12[predict_k12])/df12['Close']))\n",
    "columns2 = ['sd', 'r2', 'mse', 'rmse', 'mae', 'ampe']\n",
    "result1 = [r2, mse, rmse, mae, ampe]\n",
    "# 標準差\n",
    "std_1, std_2 = [np.std(df12['Close'].values)], [np.std(df12[predict_k12].values)]\n",
    "# 最少值, 四分位數, 最大值\n",
    "columns3 = ['min', 'q25%', 'q50%', 'q75%', 'max']\n",
    "result2 = df12['Close'].quantile([.0, .25, .5, .75, 1]).values.tolist()\n",
    "result3 = df12[predict_k12].quantile([.0, .25, .5, .75, 1]).values.tolist()\n",
    "\n",
    "# 合併\n",
    "df12_1 = pd.DataFrame([list(stats_1)+std_1+result1+result2, list(stats_2)+std_2+result1+result3], columns=list(stats_1._fields)+columns2+columns3, index=['real', 'predict'])\n",
    "df12_1.drop(['minmax'], axis=1, inplace=True)\n",
    "\n",
    "# 13.4 save\n",
    "path_13 = os.path.abspath(os.path.join('data', 'nq', 'result-describe', path_name_2+'-'+path_1_date+'-e'+ str(epochs) +'-u'+ str(units) + '-w' + str(window_size) + '-lr' + str(learning_rate) + path_name+ '-' + cur_time +'.csv'))\n",
    "df12_1.to_csv(path_13)\n",
    "df12_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
