{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import talib as talib\n",
    "import numpy as np\n",
    "import data as ds\n",
    "import common as common\n",
    "import os as os\n",
    "import math as math\n",
    "import datetime as datetime\n",
    "import scipy as sp\n",
    "import itertools  as itertools\n",
    "import multiprocessing as mp\n",
    "from os import listdir, walk\n",
    "from itertools import repeat\n",
    "from mplfinance.original_flavor import candlestick_ohlc\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, pairwise, mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 环境设定\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# 0.2 不让程序占满 GPU 内存\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n",
      "Volume obtains 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:01:00</th>\n",
       "      <td>2020-02-16 17:01:00</td>\n",
       "      <td>9650.00</td>\n",
       "      <td>9657.00</td>\n",
       "      <td>9649.00</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:02:00</th>\n",
       "      <td>2020-02-16 17:02:00</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>9656.75</td>\n",
       "      <td>9653.00</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:03:00</th>\n",
       "      <td>2020-02-16 17:03:00</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>9653.00</td>\n",
       "      <td>9653.50</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:04:00</th>\n",
       "      <td>2020-02-16 17:04:00</td>\n",
       "      <td>9653.50</td>\n",
       "      <td>9657.50</td>\n",
       "      <td>9653.25</td>\n",
       "      <td>9656.50</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:05:00</th>\n",
       "      <td>2020-02-16 17:05:00</td>\n",
       "      <td>9656.50</td>\n",
       "      <td>9658.25</td>\n",
       "      <td>9655.50</td>\n",
       "      <td>9657.25</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:55:00</th>\n",
       "      <td>2020-11-10 16:55:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:56:00</th>\n",
       "      <td>2020-11-10 16:56:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:57:00</th>\n",
       "      <td>2020-11-10 16:57:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:58:00</th>\n",
       "      <td>2020-11-10 16:58:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:59:00</th>\n",
       "      <td>2020-11-10 16:59:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261345 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2020-02-16 17:01:00 2020-02-16 17:01:00   9650.00   9657.00   9649.00   \n",
       "2020-02-16 17:02:00 2020-02-16 17:02:00   9654.00   9656.75   9653.00   \n",
       "2020-02-16 17:03:00 2020-02-16 17:03:00   9653.75   9654.00   9653.00   \n",
       "2020-02-16 17:04:00 2020-02-16 17:04:00   9653.50   9657.50   9653.25   \n",
       "2020-02-16 17:05:00 2020-02-16 17:05:00   9656.50   9658.25   9655.50   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2020-11-10 16:55:00 2020-11-10 16:55:00  11624.00  11624.00  11624.00   \n",
       "2020-11-10 16:56:00 2020-11-10 16:56:00  11624.00  11624.00  11624.00   \n",
       "2020-11-10 16:57:00 2020-11-10 16:57:00  11624.00  11624.00  11624.00   \n",
       "2020-11-10 16:58:00 2020-11-10 16:58:00  11624.00  11624.00  11624.00   \n",
       "2020-11-10 16:59:00 2020-11-10 16:59:00  11624.00  11624.00  11624.00   \n",
       "\n",
       "                        Close  Volume  \n",
       "udate                                  \n",
       "2020-02-16 17:01:00   9654.00   459.0  \n",
       "2020-02-16 17:02:00   9653.75   468.0  \n",
       "2020-02-16 17:03:00   9653.50   168.0  \n",
       "2020-02-16 17:04:00   9656.50   356.0  \n",
       "2020-02-16 17:05:00   9657.25   260.0  \n",
       "...                       ...     ...  \n",
       "2020-11-10 16:55:00  11624.00     0.0  \n",
       "2020-11-10 16:56:00  11624.00     0.0  \n",
       "2020-11-10 16:57:00  11624.00     0.0  \n",
       "2020-11-10 16:58:00  11624.00     0.0  \n",
       "2020-11-10 16:59:00  11624.00     0.0  \n",
       "\n",
       "[261345 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.0 重構數據集\n",
    "def reshape_dataframe(df0):\n",
    "    df0.fillna(0, inplace=True)\n",
    "    df0.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df0.columns = ['udate', 'High', 'Low', 'Open', 'Close', 'Volume']\n",
    "    types2 = {'udate': 'object', 'High': 'float64', 'Low': 'float64', 'Open': 'float64', 'Close': 'float64', 'Volume': 'int64'}\n",
    "    df0.astype(types2).dtypes\n",
    "    df0_1 = df0.copy(deep=True)\n",
    "    error_row = []\n",
    "    for k, v in df0.iterrows():\n",
    "        if not pd.isnull(df0['udate'].iloc[k]) and df0['udate'].iloc[k] > 0:\n",
    "            stime = str(int(df0['udate'].iloc[k]))\n",
    "            df0_1['udate'].iloc[k] = datetime(year=2020, month=int(stime[-8:-6]), day=int(stime[-6:-4]), hour=int(stime[-4:-2]), minute=int(stime[-2:]), second=0)\n",
    "        else:\n",
    "            error_row.append(k)\n",
    "    df0_1.drop(df0_1.index[error_row], inplace=True)\n",
    "    df0_1.udate = pd.to_datetime(df0_1.udate)\n",
    "    df0_1.index = pd.to_datetime(df0_1.udate)\n",
    "    \n",
    "    # 1.0.1 數據有效性檢查\n",
    "    for k, v in types2.items():\n",
    "        if (df0_1[k].isin([np.nan]).any().any()):\n",
    "            print(k+' obtains nan')\n",
    "        if (df0_1[k].isin([0]).any().any()):\n",
    "            print(k+' obtains 0')\n",
    "    is_contain_null = df0_1.isnull().sum()\n",
    "\n",
    "    return df0_1\n",
    "\n",
    "# 1.1 数据源\n",
    "files = []\n",
    "file_1 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201105.csv'))\n",
    "df1_1 = reshape_dataframe(pd.read_csv(file_1))\n",
    "files.append(df1_1)\n",
    "\n",
    "file_2 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201105_Aug_Sep.csv'))\n",
    "df1_2 = reshape_dataframe(pd.read_csv(file_2))\n",
    "files.append(df1_2)\n",
    "\n",
    "file_3 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201110.csv'))\n",
    "df1_3 = reshape_dataframe(pd.read_csv(file_3))\n",
    "files.append(df1_3)\n",
    "\n",
    "file_4 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20201111.csv'))\n",
    "df1_4 = reshape_dataframe(pd.read_csv(file_4))\n",
    "files.append(df1_4)\n",
    "\n",
    "for i in range(2, 10):\n",
    "    month1 = str(i).zfill(2)\n",
    "    file_5 = os.path.abspath(os.path.join('data', 'nq', 'data', 'nq-20-'+month1+'.csv'))\n",
    "    df1_5 = reshape_dataframe(pd.read_csv(file_5))\n",
    "    files.append(df1_5)\n",
    "\n",
    "df2 = pd.concat(files, ignore_index=False)\n",
    "\n",
    "# 1.2 刪除重覆index\n",
    "df2 = df2.groupby(df2.index).first()\n",
    "\n",
    "# 1.3 排序\n",
    "df2.sort_index(axis=0, ascending=True, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udate</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:01:00</th>\n",
       "      <td>2020-02-16 17:01:00</td>\n",
       "      <td>9650.00</td>\n",
       "      <td>9657.00</td>\n",
       "      <td>9649.00</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:02:00</th>\n",
       "      <td>2020-02-16 17:02:00</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>9656.75</td>\n",
       "      <td>9653.00</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:03:00</th>\n",
       "      <td>2020-02-16 17:03:00</td>\n",
       "      <td>9653.75</td>\n",
       "      <td>9654.00</td>\n",
       "      <td>9653.00</td>\n",
       "      <td>9653.50</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:04:00</th>\n",
       "      <td>2020-02-16 17:04:00</td>\n",
       "      <td>9653.50</td>\n",
       "      <td>9657.50</td>\n",
       "      <td>9653.25</td>\n",
       "      <td>9656.50</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 17:05:00</th>\n",
       "      <td>2020-02-16 17:05:00</td>\n",
       "      <td>9656.50</td>\n",
       "      <td>9658.25</td>\n",
       "      <td>9655.50</td>\n",
       "      <td>9657.25</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 15:56:00</th>\n",
       "      <td>2020-11-10 15:56:00</td>\n",
       "      <td>11619.25</td>\n",
       "      <td>11619.75</td>\n",
       "      <td>11617.50</td>\n",
       "      <td>11619.50</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 15:57:00</th>\n",
       "      <td>2020-11-10 15:57:00</td>\n",
       "      <td>11619.50</td>\n",
       "      <td>11619.50</td>\n",
       "      <td>11613.75</td>\n",
       "      <td>11615.00</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 15:58:00</th>\n",
       "      <td>2020-11-10 15:58:00</td>\n",
       "      <td>11615.00</td>\n",
       "      <td>11618.25</td>\n",
       "      <td>11614.00</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 15:59:00</th>\n",
       "      <td>2020-11-10 15:59:00</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>11625.00</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10 16:00:00</th>\n",
       "      <td>2020-11-10 16:00:00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>11624.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252672 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  udate      High       Low      Open  \\\n",
       "udate                                                                   \n",
       "2020-02-16 17:01:00 2020-02-16 17:01:00   9650.00   9657.00   9649.00   \n",
       "2020-02-16 17:02:00 2020-02-16 17:02:00   9654.00   9656.75   9653.00   \n",
       "2020-02-16 17:03:00 2020-02-16 17:03:00   9653.75   9654.00   9653.00   \n",
       "2020-02-16 17:04:00 2020-02-16 17:04:00   9653.50   9657.50   9653.25   \n",
       "2020-02-16 17:05:00 2020-02-16 17:05:00   9656.50   9658.25   9655.50   \n",
       "...                                 ...       ...       ...       ...   \n",
       "2020-11-10 15:56:00 2020-11-10 15:56:00  11619.25  11619.75  11617.50   \n",
       "2020-11-10 15:57:00 2020-11-10 15:57:00  11619.50  11619.50  11613.75   \n",
       "2020-11-10 15:58:00 2020-11-10 15:58:00  11615.00  11618.25  11614.00   \n",
       "2020-11-10 15:59:00 2020-11-10 15:59:00  11617.75  11625.00  11617.75   \n",
       "2020-11-10 16:00:00 2020-11-10 16:00:00  11624.00  11624.00  11624.00   \n",
       "\n",
       "                        Close  Volume  \n",
       "udate                                  \n",
       "2020-02-16 17:01:00   9654.00   459.0  \n",
       "2020-02-16 17:02:00   9653.75   468.0  \n",
       "2020-02-16 17:03:00   9653.50   168.0  \n",
       "2020-02-16 17:04:00   9656.50   356.0  \n",
       "2020-02-16 17:05:00   9657.25   260.0  \n",
       "...                       ...     ...  \n",
       "2020-11-10 15:56:00  11619.50    46.0  \n",
       "2020-11-10 15:57:00  11615.00   116.0  \n",
       "2020-11-10 15:58:00  11617.75    26.0  \n",
       "2020-11-10 15:59:00  11624.00   134.0  \n",
       "2020-11-10 16:00:00  11624.00     0.0  \n",
       "\n",
       "[252672 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.0 分包 (日子)\n",
    "def separate_daily(df4, return_type):\n",
    "    data1 = {}\n",
    "    # 交易日\n",
    "    days1 = list(dict.fromkeys([v.date() for v in df4['udate']]))\n",
    "    for day in days1:\n",
    "        # 交易時間\n",
    "        day_start = datetime(day.year, day.month, day.day, 17, 0, 0)\n",
    "        day2 = day + timedelta(days=1)\n",
    "        day_end = datetime(day2.year, day2.month, day2.day, 16, 0, 0)\n",
    "        mask = ((df4['udate'] >= day_start) & (df4['udate'] <= day_end))\n",
    "        df4_1 = df4.loc[mask]\n",
    "        if (df4_1.shape[0] > 1):\n",
    "            data1[day] = df4_1\n",
    "    # 3.1 合併\n",
    "    _df10 = pd.DataFrame()\n",
    "    for k, _df11 in data1.items():\n",
    "        _df10 = pd.concat([_df10, _df11], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "    # 3.2 返回類型\n",
    "    if return_type=='df':\n",
    "        return _df10\n",
    "    elif return_type=='dict':\n",
    "        return data1\n",
    "\n",
    "df3 = df2.copy(deep=True)\n",
    "df3 = separate_daily(df3, 'df')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 技術指標\n",
    "highs = np.array(df3['High'], dtype='float')\n",
    "lows = np.array(df3['Low'], dtype='float')\n",
    "opens = np.array(df3['Open'], dtype='float')\n",
    "closes = np.array(df3['Close'], dtype='float')\n",
    "vols = np.array(df3['Volume'], dtype='float')\n",
    "# 2.1 SMA 均線\n",
    "for v in [5, 10, 20, 50, 100]:\n",
    "    df3['sma-'+str(v)]= talib.SMA(closes, timeperiod=v)\n",
    "# 2.2 Bollinger 保力加\n",
    "df3['upper-band'], df3['middle-band'], df3['lower-band'] = talib.BBANDS(closes, timeperiod=20*1.5, nbdevup=2, nbdevdn=2, matype=0)\n",
    "# 2.3 %B %保力加\n",
    "df3['%b'] = (df3['Close']-df3['lower-band'])/(df3['upper-band']-df3['lower-band'])*100\n",
    "df3['%b-high']  = common.percentB_belowzero(df3['%b'], df3['Close']) \n",
    "df3['%b-low'] = common.percentB_aboveone(df3['%b'], df3['Close'])\n",
    "# 2.4 VOL EMA\n",
    "df3['vol-ema5'] = talib.EMA(vols, timeperiod=5*4)\n",
    "# 2.5 P-SAR 抛物线\n",
    "df3['p-sar'] = talib.SAR(highs, lows, acceleration=0.02, maximum=0.2)\n",
    "# 2.6 VWAP 成交量加權平均價格\n",
    "period = [5, 10, 20, 50, 100]\n",
    "for v in period:\n",
    "    df3['typical-price'] = (df3['High'] + df3['Low'] + df3['Close']) / 3\n",
    "    df3['turnover'] = df3['typical-price'] * df3['Volume']\n",
    "    df3['cum-turnover-'+str(v)] = df3['turnover'].rolling(window=v).sum()\n",
    "    df3['cum-volume-'+str(v)] = df3['Volume'].rolling(window=v).sum()\n",
    "    df3['vwap-'+str(v)] = df3['cum-turnover-'+str(v)] / df3['cum-volume-'+str(v)]\n",
    "    df3['vwap-'+str(v)] = df3['vwap-'+str(v)].replace([np.inf, -np.inf], 0)\n",
    "    df3['vwap-'+str(v)].fillna(0, inplace=True)\n",
    "    drop_list_1 = ['turnover', 'typical-price', 'cum-turnover-'+str(v), 'cum-volume-'+str(v)]\n",
    "    df3.drop(drop_list_1, axis=1, inplace=True)\n",
    "# 2.7 MACD\n",
    "df3['macd'], df3['macdsignal'], df3['macdhist'] = talib.MACD(closes, fastperiod=12, slowperiod=26, signalperiod=9*40)\n",
    "# 2.8 KDJ\n",
    "df3['k-kdj'], df3['d-kdj'], df3['j-kdj'] = common.kdj(highs, lows, closes, window_size=20)\n",
    "df3['diff-kdj'] = df3['k-kdj']-df3['d-kdj']\n",
    "df3['j-kdj'].loc[((df3['j-kdj'] > 20) & (df3['j-kdj'] < 100))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excpet & delete:  2020-02-16\n",
      "excpet & delete:  2020-02-18\n",
      "excpet & delete:  2020-02-19\n",
      "excpet & delete:  2020-02-20\n",
      "excpet & delete:  2020-09-17\n",
      "excpet & delete:  2020-10-29\n"
     ]
    }
   ],
   "source": [
    "# 4.0 draw chart\n",
    "drop_list_2 = []\n",
    "is_render_chart = False\n",
    "\n",
    "def draw_worker(df5, day):\n",
    "    try:\n",
    "        # 4.1 style\n",
    "        style = mpf.make_mpf_style(base_mpf_style='charles', rc={'font.size':6})\n",
    "        # 4.2 addplot\n",
    "        apds = [mpf.make_addplot(df5['lower-band'],panel=0,color='orange',linestyle='solid'),\n",
    "                mpf.make_addplot(df5['upper-band'],panel=0,color='bisque',linestyle='solid'),\n",
    "                mpf.make_addplot(df5['vwap-50'].replace(0, np.nan),panel=0,color='aqua',linestyle='solid'),\n",
    "                mpf.make_addplot(df5['%b-low'],type='scatter',markersize=20,marker='v',panel=0),\n",
    "                mpf.make_addplot(df5['%b-high'],type='scatter',markersize=20,marker='^',panel=0),\n",
    "                mpf.make_addplot(df5['p-sar'],scatter=True,markersize=1,marker='*',panel=0,color='blueviolet'),\n",
    "                #\n",
    "                mpf.make_addplot(df5['vol-ema5'],panel=1,color='orange'),\n",
    "                #\n",
    "                mpf.make_addplot(df5['macd'],panel=2,color='orange'),\n",
    "                mpf.make_addplot(df5['macdsignal'],panel=2,color='violet'),\n",
    "                mpf.make_addplot(df5['macdhist'],panel=2,type='bar',color='dimgray'),\n",
    "                #\n",
    "                mpf.make_addplot(df5['k-kdj'],panel=3,color='orange'),\n",
    "                mpf.make_addplot(df5['d-kdj'],panel=3,color='violet'),\n",
    "                mpf.make_addplot(df5['j-kdj'],panel=3,color='aqua'),\n",
    "                mpf.make_addplot(df5['diff-kdj'],panel=3,type='bar',color='dimgray')]\n",
    "        # 4.3 draw\n",
    "        mpf.plot(df5, type='candle', addplot=apds, style=style, ylabel='', ylabel_lower='', volume=True, figscale=0.5, xrotation=0, datetime_format=\"%H:%M\", show_nontrading=False, tight_layout=True, savefig='./data/img-nq/features/'+day.strftime('%m-%d-%Y'))\n",
    "        print('finish draw:', df5.shape, df5['udate'].iloc[0], df5['udate'].iloc[-1])\n",
    "    except:\n",
    "        print('do not draw:', k, '\\n')\n",
    "\n",
    "# 4.5 multi processing\n",
    "pool = mp.Pool(processes=4, maxtasksperchild=4)\n",
    "# 4.6 draw\n",
    "df6 = df3.copy(deep=True)\n",
    "data1 = separate_daily(df6, 'dict')\n",
    "for k, _df6 in data1.items():\n",
    "    df6 = _df6.copy(deep=True)\n",
    "    # 4.7 drop error day\n",
    "    if df6['Volume'].shape[0] == df6['Volume'].isin([0]).sum() or df6['Volume'].shape[0] <= 100:\n",
    "        drop_list_2.append(k)\n",
    "    # 4.8 draw chart\n",
    "    elif (is_render_chart):\n",
    "        pool.apply_async(draw_worker, args=(df6, k))\n",
    "# 4.9 kill multi processing\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for k in drop_list_2:\n",
    "    data1.pop(k, None)\n",
    "    print('excpet & delete: ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集: Total dataset has 251077 samples, and 19 features.\n",
      "0 2020-02-23 2020-03-08\n",
      "1 2020-03-08 2020-03-22\n",
      "2 2020-03-22 2020-04-05\n",
      "3 2020-04-05 2020-04-20\n",
      "4 2020-04-20 2020-05-04\n",
      "5 2020-05-04 2020-05-18\n",
      "6 2020-05-18 2020-06-01\n",
      "7 2020-06-01 2020-06-15\n",
      "8 2020-06-15 2020-06-29\n",
      "9 2020-06-29 2020-07-13\n",
      "10 2020-07-13 2020-07-27\n",
      "11 2020-07-27 2020-08-10\n",
      "12 2020-08-10 2020-08-24\n",
      "13 2020-08-24 2020-09-07\n",
      "14 2020-09-07 2020-09-22\n",
      "15 2020-09-22 2020-10-06\n",
      "16 2020-10-06 2020-10-20\n",
      "17 2020-10-20 2020-11-04\n",
      "18 2020-11-04 2020-11-09\n"
     ]
    }
   ],
   "source": [
    "# 5.0 合併\n",
    "df7 = pd.DataFrame()\n",
    "for k, df6 in data1.items():\n",
    "    df7 = pd.concat([df7, df6], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "# 5.1 清洗\n",
    "df8 = df7.copy(deep=True)\n",
    "drop_list_3 = ['High', 'Low', 'Open', 'Volume', 'macd', 'macdsignal', 'middle-band', 'k-kdj', 'd-kdj', 'vol-ema5', 'sma-10', 'vwap-10']\n",
    "df8.drop(drop_list_3, axis=1, inplace=True)\n",
    "df8.fillna(0, inplace=True)\n",
    "df8 = df8.round(2)\n",
    "\n",
    "# 5.2 檢查\n",
    "is_contain_null = df8.isnull().sum()\n",
    "is_contain_nan = df8.isna().sum()\n",
    "is_contain_inf = df8.isin([np.nan]).sum()\n",
    "print('数据集: Total dataset has {} samples, and {} features.'.format(df8.shape[0], df8.shape[1])) # df8.info()\n",
    "\n",
    "# 5.3 儲存\n",
    "path_data = os.path.abspath(os.path.join('data', 'nq', 'clean-data', 'nq-clean-data-with-features.csv'))\n",
    "if os.path.exists(path_data):\n",
    "    os.remove(path_data)\n",
    "df8.to_csv(path_data)\n",
    "\n",
    "# 5.4.1 分包 (日子)\n",
    "data2 = separate_daily(df8, 'dict')\n",
    "# 5.3.2 正則化\n",
    "normalization_days = 10\n",
    "_days2 = np.array(list(data2.keys()))\n",
    "len_days2 = (_days2.shape[0]//normalization_days)+1\n",
    "data3 = []\n",
    "scalers = {}\n",
    "for i in range(len_days2):\n",
    "    try:\n",
    "        start1, end1 = i*normalization_days, (i+1)*normalization_days\n",
    "        if end1 >= _days2.shape[0]:\n",
    "            end1 = _days2.shape[0]-1\n",
    "        # 5.3.3 每X日集合\n",
    "        day_start, day_end = _days2[start1], _days2[end1]\n",
    "        mask = ((df8['udate'].dt.date >= day_start) & (df8['udate'].dt.date <= day_end))\n",
    "        _df8 = df8[mask]\n",
    "        # 5.4.4 正則代集合\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(-0.99, 0.99))\n",
    "        df10 = _df8.drop(['udate'], axis=1)\n",
    "        min_max_scaler.fit(df10)\n",
    "        scalers[i] = {'scaler': min_max_scaler, 'day_start': day_start, 'day_end': day_end}\n",
    "        df11 = min_max_scaler.transform(df10)\n",
    "        df11 = pd.DataFrame(df11, columns=df10.columns, index=df10.index)\n",
    "        df11['udate'] = _df8['udate']\n",
    "        # 5.4.5 合併\n",
    "        data3.append(df11)\n",
    "    except:\n",
    "        print('except: ', start1, end1, len(_days2))\n",
    "\n",
    "# 5.4.6 合併\n",
    "df12 = pd.DataFrame()\n",
    "for df13 in data3:\n",
    "    df12 = pd.concat([df12, df13], axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集: X_train Data: (175966, 100, 18), Y_train Data: (175966, 5), Date_Train: 175966\n",
      "測試集: X_Test Data: (55896, 100, 18), Y_Test Data: (55896, 5), Date_Test: 55896\n",
      "验证集: X_Valid Data: (20384, 100, 18), Y_Valid Data: (20384, 5), Date_Valid: 20384\n"
     ]
    }
   ],
   "source": [
    "# 5.5.1 訓練集, 測試集, 數據集\n",
    "data3 = separate_daily(df12, 'dict')\n",
    "days3 = np.array(list(data3.keys()))\n",
    "train_set, test_set, valid_set = days3[0:-55], days3[-55:-15], days3[-15:-1]\n",
    "x_train, y_train, date_train = np.array([]), np.array([]), []\n",
    "x_test, y_test, date_test = np.array([]), np.array([]), []\n",
    "x_valid, y_valid, date_valid = np.array([]), np.array([]), []\n",
    "# 5.5.2 窗口步長\n",
    "t_pus_no = 5\n",
    "window_size = 100\n",
    "\n",
    "for day, _df8 in data3.items():\n",
    "    _df8.drop(['udate'], axis=1, inplace=True)\n",
    "    # 5.5.3 窗口\n",
    "    no_max = _df8.shape[0]-t_pus_no\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(window_size, no_max):\n",
    "        start, end = i-window_size, i\n",
    "        # y label\n",
    "        temp_0 = _df8.iloc[end: end+t_pus_no]\n",
    "        y_data.append(temp_0['Close'])\n",
    "        # x matrix\n",
    "        temp_1 = _df8.iloc[start: end]\n",
    "        x_data.append(temp_1)\n",
    "        # date\n",
    "        date1 = temp_0.index.tolist()\n",
    "        if day in train_set:\n",
    "            date_train.append(date1)\n",
    "        elif day in test_set:\n",
    "            date_test.append(date1)\n",
    "        elif day in valid_set:\n",
    "            date_valid.append(date1)\n",
    "    x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "    # print(day, x_data.shape, y_data.shape)\n",
    "    # 5.5.4 分集1\n",
    "    if day in train_set and x_train.any() and y_train.any():\n",
    "        x_train = np.concatenate((x_train, x_data), axis=0)\n",
    "        y_train = np.concatenate((y_train, y_data), axis=0)\n",
    "    elif day in test_set and x_test.any() and y_test.any():\n",
    "        x_test = np.concatenate((x_test, x_data), axis=0)\n",
    "        y_test = np.concatenate((y_test, y_data), axis=0)\n",
    "    elif day in valid_set and x_valid.any() and y_valid.any():\n",
    "        x_valid = np.concatenate((x_valid, x_data), axis=0)\n",
    "        y_valid = np.concatenate((y_valid, y_data), axis=0)\n",
    "    \n",
    "    # 5.5.5 分集2\n",
    "    if day in train_set and not x_train.any() and not y_train.any():\n",
    "        x_train, y_train = x_data, y_data\n",
    "    elif day in test_set and not x_test.any() and not y_test.any():\n",
    "        x_test, y_test = x_data, y_data\n",
    "    elif day in valid_set and not x_valid.any() and not y_valid.any():\n",
    "        x_valid, y_valid = x_data, y_data\n",
    "\n",
    "# no_batches, timesteps, no_features\n",
    "print('訓練集: X_train Data: {}, Y_train Data: {}, Date_Train: {}'.format(x_train.shape, y_train.shape, len(date_train)))\n",
    "print('測試集: X_Test Data: {}, Y_Test Data: {}, Date_Test: {}'.format(x_test.shape, y_test.shape, len(date_test)))\n",
    "print('验证集: X_Valid Data: {}, Y_Valid Data: {}, Date_Valid: {}'.format(x_valid.shape, y_valid.shape, len(date_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100, 128)          75264     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 602,245\n",
      "Trainable params: 602,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "172/172 [==============================] - 26s 152ms/step - loss: 0.0111 - accuracy: 0.2026 - val_loss: 0.0028 - val_accuracy: 0.1525\n",
      "Epoch 2/2\n",
      "172/172 [==============================] - 25s 146ms/step - loss: 0.0044 - accuracy: 0.1990 - val_loss: 0.0024 - val_accuracy: 0.1765\n"
     ]
    }
   ],
   "source": [
    "# 6.1.1 模型参数\n",
    "batch_size = 1024\n",
    "epochs = 2\n",
    "units = 128\n",
    "verbose = 1\n",
    "no_batches = x_train.shape[0]\n",
    "timesteps = x_train.shape[1]\n",
    "no_features = x_train.shape[2]\n",
    "batch_input_shape = (timesteps, no_features)\n",
    "\n",
    "# 6.1.2 日志参数\n",
    "prefix = 'nq-lstm'\n",
    "cur_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# 6.2 模型 \n",
    "# activation=softsign/tanh\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(units=units, recurrent_activation='sigmoid', activation='tanh', unroll=False, use_bias=True, \n",
    "                               recurrent_dropout=0, return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=True, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(LSTM(units=units, activation='tanh',return_sequences=False, input_shape=batch_input_shape))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=t_pus_no))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# 6.3.1 check point\n",
    "checkpoint_dir = './training_checkpoints/'+ prefix +'-' + cur_time\n",
    "os.mkdir(checkpoint_dir)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)\n",
    "\n",
    "# 6.3.2 tensor board\n",
    "log_dir = os.path.join('./logs/fit/'+ prefix +'-') + cur_time\n",
    "os.mkdir(log_dir)\n",
    "tensor_board_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# 6.4 fit model\n",
    "history_model = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True,\n",
    "                          verbose=verbose, callbacks=[checkpoint_callback, tensor_board_callback])\n",
    "\n",
    "# 6.5 save model\n",
    "model_path = \"./saved_model/\"+prefix+\"-\"+cur_time+\".h5\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.1 visualize loss\n",
    "keys = list(history_model.history.keys())\n",
    "training_loss = history_model.history['loss']\n",
    "test_loss = history_model.history['val_loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('model:'+prefix+'   batch_size:'+str(batch_size)+'   epochs:'+str(epochs)+'   units:'+str(units),loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-loss')\n",
    "plt.clf()\n",
    "\n",
    "# 7.2 visualize accuracy\n",
    "training_accuracy = history_model.history['accuracy']\n",
    "test_accuracy = history_model.history['val_accuracy']\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('model:'+prefix+'   batch_size:'+str(batch_size)+'   epochs:'+str(epochs)+'   units:'+str(units),loc ='left')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.savefig('./data/img-nq/results/'+cur_time+'-accuracy')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5499/5499 [==============================] - 44s 8ms/step - loss: 0.0024 - accuracy: 0.1900\n",
      "1747/1747 [==============================] - 14s 8ms/step - loss: 0.0024 - accuracy: 0.1765\n",
      "637/637 [==============================] - 5s 8ms/step - loss: 0.0027 - accuracy: 0.1852\n",
      "Train Score: 0.0024 MSE (0.0485 RMSE)\n",
      "Test Score: 0.0024 MSE (0.0491 RMSE)\n",
      "Validate Score: 0.0027 MSE (0.0522 RMSE)\n"
     ]
    }
   ],
   "source": [
    "# 8.0 model evaluate\n",
    "verbose = 1\n",
    "train_score = model.evaluate(x_train, y_train, verbose=verbose)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=verbose)\n",
    "valid_score = model.evaluate(x_valid, y_valid, verbose=verbose)\n",
    "\n",
    "print('Train Score: %.4f MSE (%.4f RMSE)' % (train_score[0], math.sqrt(train_score[0])))\n",
    "print('Test Score: %.4f MSE (%.4f RMSE)' % (test_score[0], math.sqrt(test_score[0])))\n",
    "print('Validate Score: %.4f MSE (%.4f RMSE)' % (valid_score[0], math.sqrt(valid_score[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_transform(data3):\n",
    "    len_shape_y = x_valid.shape[2]-1\n",
    "    fill_list = list(repeat(0, len_shape_y))\n",
    "    data4 = []\n",
    "    for list3 in data3:\n",
    "        list4 = []\n",
    "        for val3 in list3:\n",
    "            list4.append([val3] + fill_list)\n",
    "        data5 = min_max_scaler.inverse_transform(list4)\n",
    "        data6 = [v[0] for v in data5]\n",
    "        data4.append(data6)\n",
    "    return data4\n",
    "\n",
    "# 9.0 inverse\n",
    "predict1 = model.predict(x_valid)\n",
    "predict2 = scale_transform(predict1)\n",
    "t1 = [v[0] for v in predict2]\n",
    "t2 = [v[1] for v in predict2]\n",
    "t3 = [v[2] for v in predict2]\n",
    "t4 = [v[3] for v in predict2]\n",
    "t5 = [v[4] for v in predict2]\n",
    "date8 = [v[0] for v in date_valid]\n",
    "df9 = pd.DataFrame({'udate': pd.to_datetime(date8), 't1': t1, 't2': t2, 't3': t3, 't4': t4, 't5': t5})\n",
    "df9.index = df9['udate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>udate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-19 18:40:00</th>\n",
       "      <td>11715.75</td>\n",
       "      <td>11722.25</td>\n",
       "      <td>11715.75</td>\n",
       "      <td>11719.00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>11852.385833</td>\n",
       "      <td>11853.004088</td>\n",
       "      <td>11852.284521</td>\n",
       "      <td>11852.038346</td>\n",
       "      <td>11852.804546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19 18:41:00</th>\n",
       "      <td>11719.00</td>\n",
       "      <td>11721.75</td>\n",
       "      <td>11718.75</td>\n",
       "      <td>11720.50</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11855.318874</td>\n",
       "      <td>11855.918852</td>\n",
       "      <td>11855.211566</td>\n",
       "      <td>11854.922688</td>\n",
       "      <td>11855.733203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19 18:42:00</th>\n",
       "      <td>11720.50</td>\n",
       "      <td>11720.50</td>\n",
       "      <td>11717.50</td>\n",
       "      <td>11719.50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11858.145896</td>\n",
       "      <td>11858.707310</td>\n",
       "      <td>11858.041729</td>\n",
       "      <td>11857.711985</td>\n",
       "      <td>11858.558376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19 18:43:00</th>\n",
       "      <td>11719.50</td>\n",
       "      <td>11720.00</td>\n",
       "      <td>11717.50</td>\n",
       "      <td>11719.50</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11860.143048</td>\n",
       "      <td>11860.637495</td>\n",
       "      <td>11860.053585</td>\n",
       "      <td>11859.693169</td>\n",
       "      <td>11860.560085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-19 18:44:00</th>\n",
       "      <td>11719.50</td>\n",
       "      <td>11720.25</td>\n",
       "      <td>11718.00</td>\n",
       "      <td>11719.50</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11860.783622</td>\n",
       "      <td>11861.186120</td>\n",
       "      <td>11860.716981</td>\n",
       "      <td>11860.345440</td>\n",
       "      <td>11861.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 15:51:00</th>\n",
       "      <td>11841.75</td>\n",
       "      <td>11844.00</td>\n",
       "      <td>11837.25</td>\n",
       "      <td>11837.50</td>\n",
       "      <td>106.0</td>\n",
       "      <td>11831.644511</td>\n",
       "      <td>11832.197803</td>\n",
       "      <td>11831.646874</td>\n",
       "      <td>11831.241271</td>\n",
       "      <td>11831.442612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 15:52:00</th>\n",
       "      <td>11837.50</td>\n",
       "      <td>11841.50</td>\n",
       "      <td>11837.25</td>\n",
       "      <td>11840.25</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11834.198248</td>\n",
       "      <td>11834.774372</td>\n",
       "      <td>11834.224724</td>\n",
       "      <td>11833.747126</td>\n",
       "      <td>11834.072487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 15:53:00</th>\n",
       "      <td>11840.25</td>\n",
       "      <td>11841.00</td>\n",
       "      <td>11836.50</td>\n",
       "      <td>11839.50</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11836.539757</td>\n",
       "      <td>11837.092140</td>\n",
       "      <td>11836.606330</td>\n",
       "      <td>11836.059816</td>\n",
       "      <td>11836.493046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 15:54:00</th>\n",
       "      <td>11839.50</td>\n",
       "      <td>11843.75</td>\n",
       "      <td>11835.25</td>\n",
       "      <td>11835.25</td>\n",
       "      <td>89.0</td>\n",
       "      <td>11838.229521</td>\n",
       "      <td>11838.718890</td>\n",
       "      <td>11838.343018</td>\n",
       "      <td>11837.741571</td>\n",
       "      <td>11838.255063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09 15:55:00</th>\n",
       "      <td>11835.25</td>\n",
       "      <td>11838.25</td>\n",
       "      <td>11833.25</td>\n",
       "      <td>11837.75</td>\n",
       "      <td>97.0</td>\n",
       "      <td>11838.940952</td>\n",
       "      <td>11839.340682</td>\n",
       "      <td>11839.099592</td>\n",
       "      <td>11838.467171</td>\n",
       "      <td>11839.024740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20384 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         High       Low      Open     Close  Volume  \\\n",
       "udate                                                                 \n",
       "2020-10-19 18:40:00  11715.75  11722.25  11715.75  11719.00   224.0   \n",
       "2020-10-19 18:41:00  11719.00  11721.75  11718.75  11720.50    63.0   \n",
       "2020-10-19 18:42:00  11720.50  11720.50  11717.50  11719.50    50.0   \n",
       "2020-10-19 18:43:00  11719.50  11720.00  11717.50  11719.50    46.0   \n",
       "2020-10-19 18:44:00  11719.50  11720.25  11718.00  11719.50    36.0   \n",
       "...                       ...       ...       ...       ...     ...   \n",
       "2020-11-09 15:51:00  11841.75  11844.00  11837.25  11837.50   106.0   \n",
       "2020-11-09 15:52:00  11837.50  11841.50  11837.25  11840.25    52.0   \n",
       "2020-11-09 15:53:00  11840.25  11841.00  11836.50  11839.50    34.0   \n",
       "2020-11-09 15:54:00  11839.50  11843.75  11835.25  11835.25    89.0   \n",
       "2020-11-09 15:55:00  11835.25  11838.25  11833.25  11837.75    97.0   \n",
       "\n",
       "                               t1            t2            t3            t4  \\\n",
       "udate                                                                         \n",
       "2020-10-19 18:40:00  11852.385833  11853.004088  11852.284521  11852.038346   \n",
       "2020-10-19 18:41:00  11855.318874  11855.918852  11855.211566  11854.922688   \n",
       "2020-10-19 18:42:00  11858.145896  11858.707310  11858.041729  11857.711985   \n",
       "2020-10-19 18:43:00  11860.143048  11860.637495  11860.053585  11859.693169   \n",
       "2020-10-19 18:44:00  11860.783622  11861.186120  11860.716981  11860.345440   \n",
       "...                           ...           ...           ...           ...   \n",
       "2020-11-09 15:51:00  11831.644511  11832.197803  11831.646874  11831.241271   \n",
       "2020-11-09 15:52:00  11834.198248  11834.774372  11834.224724  11833.747126   \n",
       "2020-11-09 15:53:00  11836.539757  11837.092140  11836.606330  11836.059816   \n",
       "2020-11-09 15:54:00  11838.229521  11838.718890  11838.343018  11837.741571   \n",
       "2020-11-09 15:55:00  11838.940952  11839.340682  11839.099592  11838.467171   \n",
       "\n",
       "                               t5  \n",
       "udate                              \n",
       "2020-10-19 18:40:00  11852.804546  \n",
       "2020-10-19 18:41:00  11855.733203  \n",
       "2020-10-19 18:42:00  11858.558376  \n",
       "2020-10-19 18:43:00  11860.560085  \n",
       "2020-10-19 18:44:00  11861.211735  \n",
       "...                           ...  \n",
       "2020-11-09 15:51:00  11831.442612  \n",
       "2020-11-09 15:52:00  11834.072487  \n",
       "2020-11-09 15:53:00  11836.493046  \n",
       "2020-11-09 15:54:00  11838.255063  \n",
       "2020-11-09 15:55:00  11839.024740  \n",
       "\n",
       "[20384 rows x 10 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.0 combine\n",
    "df13 = df7.drop(list(df7.columns)[6:], axis=1)\n",
    "df13 = df13.loc[df9.index]\n",
    "df14 = pd.concat([df13, df9], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "# 10.1\n",
    "start2, end2 =  date8[0], date8[-2:-1][0]\n",
    "start3 = start2 - timedelta(minutes=t_pus_no+window_size)\n",
    "mask3 = ((df14.index >= start3) & (df14.index <= start2)) # 窗口步長\n",
    "mask4 = ((df14.index >= start2) & (df14.index <= end2)  & (df14['t1'] > 0)) # 預測\n",
    "df14 = df14.loc[(mask3 | mask4)]\n",
    "\"\"\"\n",
    "\n",
    "# 10.2 save\n",
    "path_1 = os.path.abspath(os.path.join('data', 'nq', 'prediction', 'nq-prediction.csv'))\n",
    "if os.path.exists(path_1):\n",
    "    os.remove(path_1)\n",
    "df14 = df14.drop(['udate'], axis=1)\n",
    "df14.to_csv(path_1)\n",
    "\n",
    "df14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
